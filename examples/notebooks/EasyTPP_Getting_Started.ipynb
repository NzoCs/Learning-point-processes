{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "380fc504",
   "metadata": {},
   "source": [
    "# EasyTPP - Getting Started Guide\n",
    "\n",
    "This notebook presents the main features of the **EasyTPP** (Easy Temporal Point Processes) library with practical examples.\n",
    "\n",
    "## ğŸ¯ Notebook Objectives\n",
    "\n",
    "- Understand the basic concepts of temporal point processes\n",
    "- Learn to configure and train models\n",
    "- Explore the different types of data and available models\n",
    "- Visualize and analyze results\n",
    "\n",
    "## ğŸ“š Table of Contents\n",
    "\n",
    "1. [Environment Setup](#1-configuration)\n",
    "2. [Basic Concepts](#2-concepts)\n",
    "3. [Data Loading and Preparation](#3-donnees)\n",
    "4. [Model Configuration and Training](#4-entrainement)\n",
    "5. [Evaluation and Metrics](#5-evaluation)\n",
    "6. [Advanced Examples](#6-avances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09a9e71",
   "metadata": {},
   "source": [
    "## 1. Environment Setup {#1-configuration}\n",
    "\n",
    "Let's start by importing the necessary modules and setting up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d560867c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… EasyTPP imported successfully!\n",
      "ğŸ“ Project directory: c:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the project root directory to PYTHONPATH\n",
    "ROOT = Path().absolute().parent.parent\n",
    "\n",
    "CONFIGS = ROOT / \"configs\" / \"test_runner_config.yaml\"\n",
    "\n",
    "# EasyTPP imports\n",
    "from easy_tpp.config_factory import RunnerConfig\n",
    "from easy_tpp.utils.yaml_config_utils import parse_runner_yaml_config\n",
    "from easy_tpp.runners import Runner\n",
    "\n",
    "print(\"âœ… EasyTPP imported successfully!\")\n",
    "print(f\"ğŸ“ Project directory: {ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b812fe",
   "metadata": {},
   "source": [
    "## 2. Basic Concepts {#2-concepts}\n",
    "\n",
    "### What is a Temporal Point Process?\n",
    "\n",
    "A **Temporal Point Process** (TPP) is a sequence of events that occur over time. Each event is characterized by:\n",
    "\n",
    "- **Occurrence time**: When the event happens\n",
    "- **Event type**: What category of event (optional)\n",
    "\n",
    "### Application examples:\n",
    "\n",
    "- ğŸ¥ **Medical**: Patient arrivals at a hospital\n",
    "- ğŸ’° **Finance**: Stock market transactions\n",
    "- ğŸŒ **Geophysics**: Earthquakes\n",
    "- ğŸ“± **Social Networks**: User posts\n",
    "\n",
    "### Models available in EasyTPP:\n",
    "\n",
    "- **NHP** (Neural Hawkes Process): Hawkes processes with neural networks\n",
    "- **THP** (Transformer Hawkes Process): Based on Transformer architecture\n",
    "- **RMTPP** (Recurrent Marked Temporal Point Process): Based on RNNs\n",
    "- **AttNHP** (Attentive Neural Hawkes Process): With attention mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55403dc1",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preparation {#3-donnees}\n",
    "\n",
    "EasyTPP supports multiple data formats. Let's see how to load and prepare data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fc56858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easy_tpp.config_factory import DataConfig\n",
    "from easy_tpp.config_factory.data_config import DataLoadingSpecsConfig, TokenizerConfig\n",
    "from easy_tpp.data.preprocess import TPPDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f9f78f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Data configuration created:\n",
      "   Dataset: test\n",
      "   Format: json\n",
      "   Event types: 2\n",
      "   Batch size: 32\n",
      "   Number of workers: 1\n",
      "   Padding side: left\n"
     ]
    }
   ],
   "source": [
    "# Data configuration with proper nested structure\n",
    "data_config = DataConfig(\n",
    "    test_dir=\"NzoCs/test_dataset\",                  # Directory for test data\n",
    "    valid_dir=\"NzoCs/test_dataset\",                 # Directory for validation data\n",
    "    train_dir=\"NzoCs/test_dataset\",            # Source directory for data\n",
    "    dataset_id=\"test\",                          # Dataset to use\n",
    "    data_format=\"json\",                       # Data format (pickle, json, csv)\n",
    "    data_loading_specs=DataLoadingSpecsConfig(\n",
    "        batch_size=32,                          # Batch size\n",
    "        num_workers=1,                          # Number of workers for data loading\n",
    "        shuffle=True                            # Shuffle data\n",
    "    ),\n",
    "    data_specs=TokenizerConfig(\n",
    "        num_event_types=2,                      # Number of event types\n",
    "        padding_side='left',                    # Padding side\n",
    "        truncation_side='left'                  # Truncation side\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"ğŸ“Š Data configuration created:\")\n",
    "print(f\"   Dataset: {data_config.dataset_id}\")\n",
    "print(f\"   Format: {data_config.data_format}\")\n",
    "print(f\"   Event types: {data_config.data_specs.num_event_types}\")\n",
    "print(f\"   Batch size: {data_config.data_loading_specs.batch_size}\")\n",
    "print(f\"   Number of workers: {data_config.data_loading_specs.num_workers}\")\n",
    "print(f\"   Padding side: {data_config.data_specs.padding_side}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de7900d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Alternative DataConfig created from dictionary:\n",
      "   Dataset: test\n",
      "   Format: json\n",
      "   Event types: 2\n",
      "   Batch size: 32\n"
     ]
    }
   ],
   "source": [
    "# Alternative: Create DataConfig using from_dict (simpler approach)\n",
    "data_config_dict = {\n",
    "    \"train_dir\": \"NzoCs/test_dataset\",\n",
    "    \"valid_dir\": \"NzoCs/test_dataset\",\n",
    "    \"test_dir\": \"NzoCs/test_dataset\",\n",
    "    \"dataset_id\": \"test\",\n",
    "    \"data_format\": \"json\",\n",
    "    \"data_loading_specs\": {\n",
    "        \"batch_size\": 32,\n",
    "        \"num_workers\": 1,\n",
    "        \"shuffle\": True\n",
    "    },\n",
    "    \"data_specs\": {\n",
    "        \"num_event_types\": 2,\n",
    "        \"padding_side\": \"left\",\n",
    "        \"truncation_side\": \"left\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create DataConfig from dictionary\n",
    "data_config_alt = DataConfig.from_dict(data_config_dict)\n",
    "\n",
    "print(\"ğŸ“Š Alternative DataConfig created from dictionary:\")\n",
    "print(f\"   Dataset: {data_config_alt.dataset_id}\")\n",
    "print(f\"   Format: {data_config_alt.data_format}\")\n",
    "print(f\"   Event types: {data_config_alt.data_specs.num_event_types}\")\n",
    "print(f\"   Batch size: {data_config_alt.data_loading_specs.batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "839c8bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2025-09-18 02:53:53,684 - data_loader.py[pid:7980;line:140:setup] - INFO: Setting up data for stage: fit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2025-09-18 02:54:11,427 - data_loader.py[pid:7980;line:149:setup] - INFO: Train dataset created with 6 sequences\u001b[0m\n",
      "\u001b[38;20m2025-09-18 02:54:20,206 - data_loader.py[pid:7980;line:158:setup] - INFO: Validation dataset created with 2 sequences\u001b[0m\n",
      "âœ… Data loaders created successfully!\n",
      "   ğŸ“ˆ Train loader: 1 batches\n",
      "   ğŸ“Š Validation loader: 1 batches\n"
     ]
    }
   ],
   "source": [
    "# Create data module\n",
    "datamodule = TPPDataModule(data_config_alt)\n",
    "datamodule.setup(stage='fit')  # Setup for training and validation\n",
    "\n",
    "# Get data loaders\n",
    "train_loader = datamodule.train_dataloader()\n",
    "val_loader = datamodule.val_dataloader()\n",
    "\n",
    "print(\"âœ… Data loaders created successfully!\")\n",
    "print(f\"   ğŸ“ˆ Train loader: {len(train_loader)} batches\")\n",
    "print(f\"   ğŸ“Š Validation loader: {len(val_loader)} batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add42398",
   "metadata": {},
   "source": [
    "### Data Inspection\n",
    "\n",
    "Let's use the Visualizer to analyze the data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc5e9c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating visualization plots...\n",
      "Inter-event time distribution plot saved to ./analysis_plots\\inter_event_time_dist.png\n",
      "Event type distribution plot saved to ./analysis_plots\\event_type_dist.png\n",
      "Sequence length distribution plot saved to ./analysis_plots\\sequence_length_dist.png\n",
      "All plots generated successfully!\n",
      "Inter-event time distribution plot saved to ./analysis_plots\\inter_event_time_dist.png\n",
      "Event type distribution plot saved to ./analysis_plots\\event_type_dist.png\n",
      "ğŸ“ˆ Analysis plots generated!\n",
      "   Check the './analysis_plots' folder for saved graphs\n"
     ]
    }
   ],
   "source": [
    "from easy_tpp.data.preprocess.visualizer import Visualizer\n",
    "\n",
    "# Create the visualizer\n",
    "visualizer = Visualizer(\n",
    "    data_module=datamodule,\n",
    "    split=\"train\",\n",
    "    save_dir=\"./analysis_plots\"\n",
    ")\n",
    "\n",
    "# Generate visualizations\n",
    "visualizer.show_all_distributions()\n",
    "visualizer.delta_times_distribution()\n",
    "visualizer.event_type_distribution()\n",
    "\n",
    "print(\"ğŸ“ˆ Analysis plots generated!\")\n",
    "print(\"   Check the './analysis_plots' folder for saved graphs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a746ab2",
   "metadata": {},
   "source": [
    "## 4. Model Configuration and Training {#4-entrainement}\n",
    "\n",
    "Now, let's configure and train a Neural Hawkes Process (NHP) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dcd1aaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ Model configuration:\n",
      "   ğŸ§  Model: NHP\n",
      "   ğŸ“Š Dataset: test\n"
     ]
    }
   ],
   "source": [
    "# Load configuration from YAML file\n",
    "runner_dict = parse_runner_yaml_config(str(CONFIGS), \"NHP\", \"test\")\n",
    "\n",
    "# Create configuration\n",
    "config = RunnerConfig.from_dict(runner_dict)\n",
    "\n",
    "print(\"âš™ï¸ Model configuration:\")\n",
    "print(f\"   ğŸ§  Model: NHP\")\n",
    "print(f\"   ğŸ“Š Dataset: test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84658b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31;1m2025-09-18 03:16:52,747 - runner.py[pid:7980;line:39:__init__] - CRITICAL: Runner initialized for model: NHP on dataset: test\u001b[0m\n",
      "ğŸš€ Starting training...\n",
      "   This may take a few minutes depending on your configuration.\n",
      "\u001b[38;20m2025-09-18 03:16:52,757 - runner.py[pid:7980;line:129:run] - INFO: Runner executing phases: ['train']\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:16:52,762 - runner.py[pid:7980;line:72:train] - INFO: === TRAINING PHASE ===\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:16:52,784 - model_runner.py[pid:7980;line:116:__init__] - INFO: No valid checkpoint found. Starting from scratch.\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:16:52,794 - model_runner.py[pid:7980;line:221:train] - INFO: --- Starting Training for Model : NHP on dataset : test ---\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2025-09-18 03:16:53,036 - data_loader.py[pid:7980;line:140:setup] - INFO: Setting up data for stage: fit\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:17:02,152 - data_loader.py[pid:7980;line:149:setup] - INFO: Train dataset created with 6 sequences\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:17:12,738 - data_loader.py[pid:7980;line:158:setup] - INFO: Validation dataset created with 2 sequences\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | layer_type_emb  | Embedding        | 192    | train\n",
      "1 | rnn_cell        | ContTimeLSTMCell | 57.8 K | train\n",
      "2 | layer_intensity | Sequential       | 132    | train\n",
      "-------------------------------------------------------------\n",
      "58.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "58.1 K    Total params\n",
      "0.232     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:310: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=5). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.64it/s, v_num=0, train_loss=2.460]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.56it/s, v_num=0, train_loss=2.460]\n",
      "âœ… Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Create runner and start training\n",
    "runner = Runner(config=config, output_dir=\"./training_results\")\n",
    "\n",
    "print(\"ğŸš€ Starting training...\")\n",
    "print(\"   This may take a few minutes depending on your configuration.\")\n",
    "\n",
    "# Train the model\n",
    "runner.run(phase=\"train\")\n",
    "\n",
    "print(\"âœ… Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de87b8ef",
   "metadata": {},
   "source": [
    "## 5. Evaluation and Metrics {#5-evaluation}\n",
    "\n",
    "Let's now evaluate the performance of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5dcaf902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Evaluating model on test dataset...\n",
      "\u001b[38;20m2025-09-18 03:18:22,179 - runner.py[pid:7980;line:129:run] - INFO: Runner executing phases: ['test']\u001b[0m\n",
      "\u001b[31;1m2025-09-18 03:18:22,180 - runner.py[pid:7980;line:85:test] - CRITICAL: === TESTING PHASE ===\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:18:22,184 - model_runner.py[pid:7980;line:103:__init__] - INFO: Checkpoint found: loading from ./training_results\\last.ckpt\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:18:22,194 - model_runner.py[pid:7980;line:114:__init__] - INFO: Loading model from checkpoint: ./training_results\\last.ckpt.\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:18:22,197 - model_runner.py[pid:7980;line:245:test] - INFO: --- Starting Testing for Model : NHP on dataset : test ---\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2025-09-18 03:18:22,233 - data_loader.py[pid:7980;line:140:setup] - INFO: Setting up data for stage: test\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at ./training_results\\last.ckpt\n",
      "Loaded model weights from the checkpoint at ./training_results\\last.ckpt\n",
      "c:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\">        Test metric        </span>â”ƒ<span style=\"font-weight: bold\">       DataLoader 0        </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">       cross_entropy       </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.49844682216644287    </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">       macro_f1score       </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">     81.37931060791016     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         precision         </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">     81.37931060791016     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">          recall           </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">     81.37931060791016     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    2.0783979892730713     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         time_mae          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    1.7528632879257202     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         time_rmse         </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    3.0204854011535645     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">       type_accuracy       </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">     81.48148345947266     </span>â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m      cross_entropy      \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.49844682216644287   \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m      macro_f1score      \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m    81.37931060791016    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m        precision        \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m    81.37931060791016    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m         recall          \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m    81.37931060791016    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   2.0783979892730713    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m        time_mae         \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   1.7528632879257202    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m        time_rmse        \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   3.0204854011535645    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m      type_accuracy      \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m    81.48148345947266    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2025-09-18 03:18:59,164 - model_runner.py[pid:7980;line:269:test] - INFO: Test results saved to ./training_results\\test_results.json\u001b[0m\n",
      "ğŸ“Š Evaluation results:\n",
      "âœ… Evaluation completed - check logs for detailed metrics\n",
      "ğŸ“Š Evaluation results:\n",
      "âœ… Evaluation completed - check logs for detailed metrics\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on test dataset\n",
    "print(\"ğŸ§ª Evaluating model on test dataset...\")\n",
    "\n",
    "test_results = runner.run(phase=\"test\")\n",
    "\n",
    "print(\"ğŸ“Š Evaluation results:\")\n",
    "if hasattr(runner, 'test_metrics'):\n",
    "    for metric_name, value in runner.test_metrics.items():\n",
    "        print(f\"   {metric_name}: {value:.4f}\")\n",
    "else:\n",
    "    print(\"âœ… Evaluation completed - check logs for detailed metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98613a0c",
   "metadata": {},
   "source": [
    "### Comparison with Baselines\n",
    "\n",
    "Let's compare our model with simple baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "843afc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2025-09-18 03:01:33,627 - data_loader.py[pid:7980;line:140:setup] - INFO: Setting up data for stage: test\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Baseline benchmark (mean):\n",
      "\u001b[38;20m2025-09-18 03:01:37,917 - base_bench.py[pid:7980;line:147:evaluate] - INFO: Starting mean_inter_time benchmark evaluation...\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:01:37,918 - mean_bench.py[pid:7980;line:51:_prepare_benchmark] - INFO: Computing mean inter-time from training data...\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:01:37,918 - mean_bench.py[pid:7980;line:51:_prepare_benchmark] - INFO: Computing mean inter-time from training data...\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:02:08,479 - mean_bench.py[pid:7980;line:74:_prepare_benchmark] - INFO: Computed mean inter-time: 1.506245\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:02:37,831 - base_bench.py[pid:7980;line:366:_save_results] - INFO: Results saved to: ./benchmark_results\\mean_baseline\\mean_inter_time_results.json\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:02:37,833 - base_bench.py[pid:7980;line:375:_log_summary] - INFO: mean_inter_time benchmark completed successfully!\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:02:37,836 - base_bench.py[pid:7980;line:381:_log_summary] - INFO: Time RMSE: 2.772637\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:02:37,838 - base_bench.py[pid:7980;line:383:_log_summary] - INFO: Time MAE: 1.840395\u001b[0m\n",
      "   Results: {'benchmark_name': 'mean_inter_time', 'dataset_name': 'mean_baseline', 'num_event_types': 2, 'metrics': {'time_rmse_mean': 2.772637367248535, 'time_rmse_std': 0.0, 'time_rmse_min': 2.772637367248535, 'time_rmse_max': 2.772637367248535, 'time_mae_mean': 1.8403947353363037, 'time_mae_std': 0.0, 'time_mae_min': 1.8403947353363037, 'time_mae_max': 1.8403947353363037}, 'num_batches_evaluated': 1, 'mean_inter_time_used': 1.5062450681413924}\n",
      "\u001b[38;20m2025-09-18 03:02:40,267 - data_loader.py[pid:7980;line:140:setup] - INFO: Setting up data for stage: test\u001b[0m\n",
      "\n",
      "ğŸ“Š Type distribution benchmark:\n",
      "\u001b[38;20m2025-09-18 03:02:48,758 - base_bench.py[pid:7980;line:147:evaluate] - INFO: Starting mark_distribution_sampling benchmark evaluation...\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:02:48,760 - sample_distrib_mark_bench.py[pid:7980;line:55:_prepare_benchmark] - INFO: Collecting event marks from test data...\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:03:27,928 - sample_distrib_mark_bench.py[pid:7980;line:92:_prepare_benchmark] - INFO: Collected 56 event marks\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:03:27,996 - sample_distrib_mark_bench.py[pid:7980;line:93:_prepare_benchmark] - INFO: Event type distribution: {0: tensor(0.4464), 1: tensor(0.5536)}\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:04:00,896 - base_bench.py[pid:7980;line:366:_save_results] - INFO: Results saved to: ./benchmark_results\\mark_baseline\\mark_distribution_sampling_results.json\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:04:00,898 - base_bench.py[pid:7980;line:375:_log_summary] - INFO: mark_distribution_sampling benchmark completed successfully!\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:04:00,900 - base_bench.py[pid:7980;line:387:_log_summary] - INFO: Type Accuracy: 50.000000\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:04:00,902 - base_bench.py[pid:7980;line:389:_log_summary] - INFO: Macro F1 Score: 49.936143\u001b[0m\n",
      "   Results: {'benchmark_name': 'mark_distribution_sampling', 'dataset_name': 'mark_baseline', 'num_event_types': 2, 'metrics': {'type_accuracy_mean': 50.0, 'type_accuracy_std': 0.0, 'type_accuracy_min': 50.0, 'type_accuracy_max': 50.0, 'macro_f1score_mean': 49.936142563819885, 'macro_f1score_std': 0.0, 'macro_f1score_min': 49.936142563819885, 'macro_f1score_max': 49.936142563819885, 'recall_mean': 50.19354820251465, 'recall_std': 0.0, 'recall_min': 50.19354820251465, 'recall_max': 50.19354820251465, 'precision_mean': 50.191569328308105, 'precision_std': 0.0, 'precision_min': 50.191569328308105, 'precision_max': 50.191569328308105, 'cross_entropy_mean': 0.8132616877555847, 'cross_entropy_std': 0.0, 'cross_entropy_min': 0.8132616877555847, 'cross_entropy_max': 0.8132616877555847, 'confusion_matrix': [[13, 12], [16, 15]]}, 'num_batches_evaluated': 1, 'distribution_stats': {'entropy': 0.6873963475227356}}\n"
     ]
    }
   ],
   "source": [
    "from easy_tpp.evaluation.benchmarks.mean_bench import MeanInterTimeBenchmark\n",
    "from easy_tpp.evaluation.benchmarks.sample_distrib_mark_bench import MarkDistributionBenchmark\n",
    "\n",
    "# Baseline benchmark: mean prediction\n",
    "mean_benchmark = MeanInterTimeBenchmark(\n",
    "    data_config=data_config_alt,\n",
    "    experiment_id=\"mean_baseline\",\n",
    "    save_dir=\"./benchmark_results\"\n",
    ")\n",
    "\n",
    "print(\"ğŸ“Š Baseline benchmark (mean):\")\n",
    "mean_results = mean_benchmark.evaluate()\n",
    "print(f\"   Results: {mean_results}\")\n",
    "\n",
    "# Type distribution benchmark\n",
    "mark_benchmark = MarkDistributionBenchmark(\n",
    "    data_config=data_config_alt,\n",
    "    experiment_id=\"mark_baseline\",\n",
    "    save_dir=\"./benchmark_results\"\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ“Š Type distribution benchmark:\")\n",
    "mark_results = mark_benchmark.evaluate()\n",
    "print(f\"   Results: {mark_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79af9f88",
   "metadata": {},
   "source": [
    "## 6. Advanced Examples {#6-avances}\n",
    "\n",
    "### Synthetic Data Generation\n",
    "\n",
    "EasyTPP allows generating synthetic data to test models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fa8e887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ² Generating synthetic data...\n",
      "GÃ©nÃ©ration de 10 simulations 2D...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulation de 10 processus: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 33.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Division des donnÃ©es en ensembles train/test/dev...\n",
      "Sauvegarde des donnÃ©es...\n",
      "Toutes les donnÃ©es ont Ã©tÃ© sauvegardÃ©es dans ./synthetic_data\n",
      "âœ… Synthetic data generated in './synthetic_data'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from easy_tpp.data.generation import HawkesSimulator\n",
    "\n",
    "# Hawkes process configuration\n",
    "params = {\n",
    "    \"mu\": [0.1, 0.2],                    # Base intensities\n",
    "    \"alpha\": [[0.3, 0.1], [0.2, 0.4]],  # Excitation matrix\n",
    "    \"beta\": [[2, 1], [1.5, 3]]          # Decay matrix\n",
    "}\n",
    "\n",
    "# Create simulator\n",
    "simulator = HawkesSimulator(\n",
    "    mu=params[\"mu\"],\n",
    "    alpha=params[\"alpha\"],\n",
    "    beta=params[\"beta\"],\n",
    "    dim_process=2,\n",
    "    start_time=0,\n",
    "    end_time=100\n",
    ")\n",
    "\n",
    "print(\"ğŸ² Generating synthetic data...\")\n",
    "\n",
    "# Generate and save\n",
    "simulator.generate_and_save(\n",
    "    output_dir='./synthetic_data',\n",
    "    num_simulations=10,\n",
    "    splits={'train': 0.6, 'test': 0.2, 'dev': 0.2}\n",
    ")\n",
    "\n",
    "print(\"âœ… Synthetic data generated in './synthetic_data'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c842bf",
   "metadata": {},
   "source": [
    "### Multiple Model Comparison\n",
    "\n",
    "Let's compare the performance of different models on the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e7f0b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ§  Training model NHP...\n",
      "\u001b[31;1m2025-09-18 03:19:45,632 - runner.py[pid:7980;line:39:__init__] - CRITICAL: Runner initialized for model: NHP on dataset: test\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:19:45,633 - runner.py[pid:7980;line:129:run] - INFO: Runner executing phases: ['train']\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:19:45,634 - runner.py[pid:7980;line:72:train] - INFO: === TRAINING PHASE ===\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:19:45,637 - model_runner.py[pid:7980;line:116:__init__] - INFO: No valid checkpoint found. Starting from scratch.\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:19:45,638 - model_runner.py[pid:7980;line:221:train] - INFO: --- Starting Training for Model : NHP on dataset : test ---\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2025-09-18 03:19:45,665 - data_loader.py[pid:7980;line:140:setup] - INFO: Setting up data for stage: fit\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:19:49,379 - data_loader.py[pid:7980;line:149:setup] - INFO: Train dataset created with 6 sequences\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:19:54,366 - data_loader.py[pid:7980;line:158:setup] - INFO: Validation dataset created with 2 sequences\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | layer_type_emb  | Embedding        | 192    | train\n",
      "1 | rnn_cell        | ContTimeLSTMCell | 57.8 K | train\n",
      "2 | layer_intensity | Sequential       | 132    | train\n",
      "-------------------------------------------------------------\n",
      "58.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "58.1 K    Total params\n",
      "0.232     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3707: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# List of models to compare\n",
    "models_to_compare = ['NHP', 'THP', 'RMTPP']\n",
    "results_comparison = {}\n",
    "\n",
    "for model_name in models_to_compare:\n",
    "    print(f\"\\nğŸ§  Training model {model_name}...\")\n",
    "    \n",
    "    try:\n",
    "        # Configuration for this model\n",
    "        model_config_dict = parse_runner_yaml_config(str(CONFIGS), model_name, \"test\")\n",
    "\n",
    "        config = RunnerConfig.from_dict(model_config_dict)\n",
    "        runner = Runner(config=config, output_dir=f\"./comparison_results/{model_name}\")\n",
    "        \n",
    "        # Quick training (fewer epochs for demo)\n",
    "        runner.run(phase=\"train\")\n",
    "        test_results = runner.run(phase=\"test\")\n",
    "        \n",
    "        results_comparison[model_name] = \"âœ… Success\"\n",
    "        print(f\"   âœ… {model_name} trained successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        results_comparison[model_name] = f\"âŒ Error: {str(e)[:50]}...\"\n",
    "        print(f\"   âŒ Error with {model_name}: {str(e)[:50]}...\")\n",
    "\n",
    "print(\"\\nğŸ“Š Comparison summary:\")\n",
    "for model, result in results_comparison.items():\n",
    "    print(f\"   {model}: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249be884",
   "metadata": {},
   "source": [
    "## 6. Prediction Phase and Distribution Analysis\n",
    "\n",
    "**Why the prediction phase is crucial:**\n",
    "\n",
    "Temporal Point Process (TPP) models don't just serve to calculate performance metrics - their true value lies in their ability to **predict and simulate** new events. These predictions enable:\n",
    "\n",
    "1. **Distribution comparisons** - Analyze whether the model captures temporal patterns well\n",
    "2. **Realistic benchmarks** - Compare model simulations to real data  \n",
    "3. **Qualitative validation** - Visualize differences between predictions and reality\n",
    "4. **Practical applications** - Generate future scenarios for decision-making\n",
    "\n",
    "### 6.1 Complete Pipeline with Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b125ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Complete pipeline with predictions...\n",
      "\u001b[31;1m2025-09-18 03:20:21,406 - runner.py[pid:7980;line:39:__init__] - CRITICAL: Runner initialized for model: NHP on dataset: test\u001b[0m\n",
      "ğŸ“š 1. Training the model...\n",
      "\u001b[38;20m2025-09-18 03:20:21,412 - runner.py[pid:7980;line:129:run] - INFO: Runner executing phases: ['train']\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:20:21,419 - runner.py[pid:7980;line:72:train] - INFO: === TRAINING PHASE ===\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:20:21,437 - model_runner.py[pid:7980;line:116:__init__] - INFO: No valid checkpoint found. Starting from scratch.\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:20:21,440 - model_runner.py[pid:7980;line:221:train] - INFO: --- Starting Training for Model : NHP on dataset : test ---\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2025-09-18 03:20:21,592 - data_loader.py[pid:7980;line:140:setup] - INFO: Setting up data for stage: fit\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:20:30,059 - data_loader.py[pid:7980;line:149:setup] - INFO: Train dataset created with 6 sequences\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:20:38,542 - data_loader.py[pid:7980;line:158:setup] - INFO: Validation dataset created with 2 sequences\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | layer_type_emb  | Embedding        | 192    | train\n",
      "1 | rnn_cell        | ContTimeLSTMCell | 57.8 K | train\n",
      "2 | layer_intensity | Sequential       | 132    | train\n",
      "-------------------------------------------------------------\n",
      "58.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "58.1 K    Total params\n",
      "0.232     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.95it/s, v_num=3, train_loss=2.400]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.81it/s, v_num=3, train_loss=2.400]\n",
      "ğŸ§ª 2. Performance evaluation...\n",
      "\u001b[38;20m2025-09-18 03:21:48,228 - runner.py[pid:7980;line:129:run] - INFO: Runner executing phases: ['test']\u001b[0m\n",
      "\u001b[31;1m2025-09-18 03:21:48,232 - runner.py[pid:7980;line:85:test] - CRITICAL: === TESTING PHASE ===\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:21:48,258 - model_runner.py[pid:7980;line:103:__init__] - INFO: Checkpoint found: loading from ./prediction_analysis\\last.ckpt\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:21:48,267 - model_runner.py[pid:7980;line:114:__init__] - INFO: Loading model from checkpoint: ./prediction_analysis\\last.ckpt.\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:21:48,273 - model_runner.py[pid:7980;line:245:test] - INFO: --- Starting Testing for Model : NHP on dataset : test ---\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2025-09-18 03:21:48,602 - data_loader.py[pid:7980;line:140:setup] - INFO: Setting up data for stage: test\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at ./prediction_analysis\\last.ckpt\n",
      "Loaded model weights from the checkpoint at ./prediction_analysis\\last.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\">        Test metric        </span>â”ƒ<span style=\"font-weight: bold\">       DataLoader 0        </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">       cross_entropy       </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.4614097476005554     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">       macro_f1score       </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">     85.18518829345703     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         precision         </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">     85.6551742553711      </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">          recall           </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">     85.6551742553711      </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    2.1120405197143555     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         time_mae          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    1.5713568925857544     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         time_rmse         </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    2.9475600719451904     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">       type_accuracy       </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">     85.18518829345703     </span>â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m      cross_entropy      \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.4614097476005554    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m      macro_f1score      \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m    85.18518829345703    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m        precision        \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m    85.6551742553711     \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m         recall          \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m    85.6551742553711     \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   2.1120405197143555    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m        time_mae         \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   1.5713568925857544    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m        time_rmse        \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   2.9475600719451904    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m      type_accuracy      \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m    85.18518829345703    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2025-09-18 03:22:32,712 - model_runner.py[pid:7980;line:269:test] - INFO: Test results saved to ./prediction_analysis\\test_results.json\u001b[0m\n",
      "ğŸ”® 3. Generating predictions and distribution comparisons...\n",
      "\u001b[38;20m2025-09-18 03:22:32,715 - runner.py[pid:7980;line:129:run] - INFO: Runner executing phases: ['predict']\u001b[0m\n",
      "\u001b[31;1m2025-09-18 03:22:32,720 - runner.py[pid:7980;line:98:predict] - CRITICAL: === PREDICTION PHASE ===\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:22:32,741 - model_runner.py[pid:7980;line:103:__init__] - INFO: Checkpoint found: loading from ./prediction_analysis\\last.ckpt\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:22:32,749 - model_runner.py[pid:7980;line:114:__init__] - INFO: Loading model from checkpoint: ./prediction_analysis\\last.ckpt.\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:22:32,756 - model_runner.py[pid:7980;line:275:predict] - INFO: --- Starting Prediction for Model : NHP on dataset : test ---\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2025-09-18 03:22:32,940 - data_loader.py[pid:7980;line:140:setup] - INFO: Setting up data for stage: predict\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at ./prediction_analysis\\last.ckpt\n",
      "Loaded model weights from the checkpoint at ./prediction_analysis\\last.ckpt\n",
      "c:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00,  0.03it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Formatting sequences: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 1152.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to .\\distributions_comparisons\\simulations.json\n",
      "\u001b[38;20m2025-09-18 03:23:46,469 - comparator.py[pid:7980;line:142:create_comparator] - INFO: Using TPPDatasetExtractor for optimized data extraction\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:23:46,476 - comparator.py[pid:7980;line:69:run_comprehensive_evaluation] - INFO: Starting comprehensive temporal point process evaluation...\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:23:46,482 - data_extractors.py[pid:7980;line:69:_extract_all_data] - INFO: Extracting ground truth data from TPPDataset with 2 sequences...\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:23:46,496 - data_extractors.py[pid:7980;line:118:_extract_all_data] - INFO: Successfully processed 2/2 sequences, extracted 56 events\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:23:46,501 - data_extractors.py[pid:7980;line:277:_extract_all_data] - INFO: Processing simulation data...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2025-09-18 03:23:49,798 - distribution_analyzer.py[pid:7980;line:119:plot_density_comparison] - INFO: Density comparison plot successfully saved to .\\distributions_comparisons\\comparison_inter_event_time_dist.png\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:23:53,015 - plot_generators.py[pid:7980;line:165:generate_plot] - INFO: Event type distribution comparison plot saved to .\\distributions_comparisons\\comparison_event_type_dist.png\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:23:55,458 - plot_generators.py[pid:7980;line:257:generate_plot] - INFO: Sequence length distribution comparison plot saved to .\\distributions_comparisons\\comparison_sequence_length_dist.png\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:24:00,065 - plot_generators.py[pid:7980;line:342:generate_plot] - INFO: Cross-correlation comparison plot saved to .\\distributions_comparisons\\comparison_cross_correlation_moments.png\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:24:00,067 - comparator.py[pid:7980;line:97:run_comprehensive_evaluation] - INFO: Comprehensive evaluation completed successfully\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:24:00,070 - model_runner.py[pid:7980;line:303:predict] - INFO: Running comprehensive evaluation of temporal point process distributions...\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:24:00,073 - comparator.py[pid:7980;line:69:run_comprehensive_evaluation] - INFO: Starting comprehensive temporal point process evaluation...\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:24:01,810 - distribution_analyzer.py[pid:7980;line:119:plot_density_comparison] - INFO: Density comparison plot successfully saved to .\\distributions_comparisons\\comparison_inter_event_time_dist.png\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:24:02,617 - plot_generators.py[pid:7980;line:165:generate_plot] - INFO: Event type distribution comparison plot saved to .\\distributions_comparisons\\comparison_event_type_dist.png\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:24:03,882 - plot_generators.py[pid:7980;line:257:generate_plot] - INFO: Sequence length distribution comparison plot saved to .\\distributions_comparisons\\comparison_sequence_length_dist.png\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:24:06,109 - plot_generators.py[pid:7980;line:342:generate_plot] - INFO: Cross-correlation comparison plot saved to .\\distributions_comparisons\\comparison_cross_correlation_moments.png\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:24:06,116 - comparator.py[pid:7980;line:97:run_comprehensive_evaluation] - INFO: Comprehensive evaluation completed successfully\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:24:06,120 - model_runner.py[pid:7980;line:307:predict] - INFO: Simulations saved to .\\distributions_comparisons\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:24:06,129 - model_runner.py[pid:7980;line:309:predict] - INFO: Generating intensity graph...\u001b[0m\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Inference tensors cannot be saved for backward. To work around you can make a clone to get a normal tensor and use it in autograd.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Phase 3: Predictions and comparisons (CRUCIAL!)\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mğŸ”® 3. Generating predictions and distribution comparisons...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphase\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpredict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… Complete pipeline finished!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mğŸ“Š Results available in:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\easy_tpp\\runners\\runner.py:142\u001b[39m, in \u001b[36mRunner.run\u001b[39m\u001b[34m(self, phase)\u001b[39m\n\u001b[32m    139\u001b[39m     results[current_phase] = \u001b[33m\"\u001b[39m\u001b[33mcompleted\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m current_phase == \u001b[33m\"\u001b[39m\u001b[33mpredict\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m     results[current_phase] = \u001b[33m\"\u001b[39m\u001b[33mcompleted\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\easy_tpp\\runners\\runner.py:100\u001b[39m, in \u001b[36mRunner.predict\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     98\u001b[39m logger.critical(\u001b[33m\"\u001b[39m\u001b[33m=== PREDICTION PHASE ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     99\u001b[39m trainer = \u001b[38;5;28mself\u001b[39m._create_trainer(enable_logging=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# This method doesn't return predictions but saves them\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\easy_tpp\\runners\\model_runner.py:310\u001b[39m, in \u001b[36mTrainer.predict\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    307\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSimulations saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_save_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    309\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mGenerating intensity graph...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mintensity_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_save_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\easy_tpp\\models\\basemodel.py:1218\u001b[39m, in \u001b[36mBaseModel.intensity_graph\u001b[39m\u001b[34m(self, start_time, end_time, precision, plot, save_plot, save_data, save_dir, **kwargs)\u001b[39m\n\u001b[32m   1214\u001b[39m time_deltas_sample = time_deltas.unsqueeze(-\u001b[32m1\u001b[39m) * ratios\n\u001b[32m   1216\u001b[39m \u001b[38;5;66;03m# Calculate intensities on augmented intervals\u001b[39;00m\n\u001b[32m   1217\u001b[39m \u001b[38;5;66;03m# [1, seq_len, precision, num_event_types]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1218\u001b[39m intensities = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_intensities_at_sample_times\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1219\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtime_seq\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# [1, seq_len-1]\u001b[39;49;00m\n\u001b[32m   1220\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtime_delta_seq\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# [1, seq_len-1]\u001b[39;49;00m\n\u001b[32m   1221\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtype_seq\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# [1, seq_len-1]\u001b[39;49;00m\n\u001b[32m   1222\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtime_deltas_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1225\u001b[39m time_diffs = time_seq.diff()\n\u001b[32m   1227\u001b[39m \u001b[38;5;66;03m# Calculate actual time points: [1, seq_len-1, precision]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\easy_tpp\\models\\nhp.py:257\u001b[39m, in \u001b[36mNHP.compute_intensities_at_sample_times\u001b[39m\u001b[34m(self, time_seqs, time_delta_seqs, type_seqs, sample_dtimes, **kwargs)\u001b[39m\n\u001b[32m    254\u001b[39m _input = time_seqs, time_delta_seqs, type_seqs, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    256\u001b[39m \u001b[38;5;66;03m# We will need the right limit at the last given event to decay from and get the left limits for sampling\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m _, right_hiddens = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    259\u001b[39m c_i, c_bar_i, delta_i, o_i = torch.chunk(right_hiddens, \u001b[32m4\u001b[39m, dim=-\u001b[32m1\u001b[39m)\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compute_last_step_only:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\easy_tpp\\models\\nhp.py:140\u001b[39m, in \u001b[36mNHP.forward\u001b[39m\u001b[34m(self, batch)\u001b[39m\n\u001b[32m    137\u001b[39m left_hs = []\n\u001b[32m    138\u001b[39m right_states = []\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m all_event_emb_BNP = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayer_type_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarks_BN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    141\u001b[39m c_t, c_bar_t, delta_t, o_t = \u001b[38;5;28mself\u001b[39m.get_init_state(\n\u001b[32m    142\u001b[39m     B\n\u001b[32m    143\u001b[39m )  \u001b[38;5;66;03m# initialize the right limits\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N):\n\u001b[32m    145\u001b[39m     \u001b[38;5;66;03m# Take last right limit and evolve into left limit; we will discard this value for t0 because dt=0\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:192\u001b[39m, in \u001b[36mEmbedding.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:2546\u001b[39m, in \u001b[36membedding\u001b[39m\u001b[34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[39m\n\u001b[32m   2540\u001b[39m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[32m   2541\u001b[39m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[32m   2542\u001b[39m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[32m   2543\u001b[39m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[32m   2544\u001b[39m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[32m   2545\u001b[39m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[32m-> \u001b[39m\u001b[32m2546\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Inference tensors cannot be saved for backward. To work around you can make a clone to get a normal tensor and use it in autograd."
     ]
    }
   ],
   "source": [
    "# Complete example: train â†’ test â†’ predict\n",
    "print(\"ğŸ”„ Complete pipeline with predictions...\")\n",
    "\n",
    "# Configuration\n",
    "config_dict = parse_runner_yaml_config(\n",
    "    yaml_path=CONFIGS,\n",
    "    experiment_id=\"NHP\", \n",
    "    dataset_id=\"test\"\n",
    ")\n",
    "config = RunnerConfig.from_dict(config_dict)\n",
    "\n",
    "# Runner\n",
    "runner = Runner(config=config, output_dir=\"./prediction_analysis\")\n",
    "\n",
    "# Phase 1: Training\n",
    "print(\"ğŸ“š 1. Training the model...\")\n",
    "runner.run(phase=\"train\")\n",
    "\n",
    "# Phase 2: Test/Evaluation  \n",
    "print(\"ğŸ§ª 2. Performance evaluation...\")\n",
    "runner.run(phase=\"test\")\n",
    "\n",
    "# Phase 3: Predictions and comparisons (CRUCIAL!)\n",
    "print(\"ğŸ”® 3. Generating predictions and distribution comparisons...\")\n",
    "runner.run(phase=\"predict\")\n",
    "\n",
    "print(\"âœ… Complete pipeline finished!\")\n",
    "print(\"ğŸ“Š Results available in:\")\n",
    "print(\"   - Performance metrics\")\n",
    "print(\"   - Model simulations\") \n",
    "print(\"   - Distribution comparisons\")\n",
    "print(\"   - Analysis graphs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aa3b9d",
   "metadata": {},
   "source": [
    "### 6.2 Simplified Alternative: Single Command\n",
    "\n",
    "If you want the complete pipeline all at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca0febb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ultra-simple version: everything in one command\n",
    "runner = Runner(config=config, output_dir=\"./complete_pipeline\")\n",
    "\n",
    "# Automatically executes: train â†’ test â†’ predict\n",
    "runner.run(phase=\"all\")\n",
    "\n",
    "print(\"ğŸ‰ Complete pipeline executed with phase='all'!\")\n",
    "print(\"ğŸ’¡ This command is equivalent to the 3 separate phases above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004da06e",
   "metadata": {},
   "source": [
    "**ğŸ¯ Main objective:** Verify that the model has learned the correct temporal distributions.\n",
    "\n",
    "**ğŸ“Š What the `predict` phase generates:**\n",
    "- **Event simulations** based on the trained model\n",
    "- **Visual comparisons** between real and simulated data\n",
    "- **Statistical analyses** of temporal distributions\n",
    "- **Prediction quality metrics**\n",
    "\n",
    "**âš ï¸ Crucial point:** Without the prediction phase, you only have numerical metrics. With predictions, you can **see** if your model truly understands the temporal dynamics of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27e5ddb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not found: analysis_plots\n",
      "Not found: training_results\n",
      "Not found: benchmark_results\n",
      "Not found: synthetic_data\n",
      "Not found: comparison_results\n",
      "Not found: prediction_analysis\n",
      "Not found: complete_pipeline\n",
      "Deleted: lightning_logs\n",
      "Deleted: checkpoints\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "folders_to_remove = [\n",
    "    \"analysis_plots\",\n",
    "    \"training_results\",\n",
    "    \"benchmark_results\",\n",
    "    \"synthetic_data\",\n",
    "    \"comparison_results\",\n",
    "    \"prediction_analysis\",\n",
    "    \"complete_pipeline\",\n",
    "    \"lightning_logs\",\n",
    "    \"checkpoints\"\n",
    "]\n",
    "\n",
    "for folder in folders_to_remove:\n",
    "    if os.path.exists(folder):\n",
    "        shutil.rmtree(folder)\n",
    "        print(f\"Deleted: {folder}\")\n",
    "    else:\n",
    "        print(f\"Not found: {folder}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easy-tpp (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
