{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "380fc504",
   "metadata": {},
   "source": [
    "# EasyTPP - Getting Started Guide\n",
    "\n",
    "This notebook presents the main features of the **EasyTPP** (Easy Temporal Point Processes) library with practical examples.\n",
    "\n",
    "## 🎯 Notebook Objectives\n",
    "\n",
    "- Understand the basic concepts of temporal point processes\n",
    "- Learn to configure and train models\n",
    "- Explore the different types of data and available models\n",
    "- Visualize and analyze results\n",
    "\n",
    "## 📚 Table of Contents\n",
    "\n",
    "1. [Environment Setup](#1-configuration)\n",
    "2. [Basic Concepts](#2-concepts)\n",
    "3. [Data Loading and Preparation](#3-donnees)\n",
    "4. [Model Configuration and Training](#4-entrainement)\n",
    "5. [Evaluation and Metrics](#5-evaluation)\n",
    "6. [Advanced Examples](#6-avances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09a9e71",
   "metadata": {},
   "source": [
    "## 1. Environment Setup {#1-configuration}\n",
    "\n",
    "Let's start by importing the necessary modules and setting up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d560867c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m sys.path.insert(\u001b[32m0\u001b[39m, \u001b[38;5;28mstr\u001b[39m(project_root))\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# EasyTPP imports\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01measy_tpp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig_factory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RunnerConfig\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01measy_tpp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01myaml_config_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parse_runner_yaml_config\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01measy_tpp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunner\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Runner\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\easy_tpp\\config_factory\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01measy_tpp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig_factory\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      2\u001b[39m     DataConfig,\n\u001b[32m      3\u001b[39m     TokenizerConfig,\n\u001b[32m      4\u001b[39m     DataLoadingSpecsConfig,\n\u001b[32m      5\u001b[39m )\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01measy_tpp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig_factory\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhpo_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HPOConfig, HPORunnerConfig\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01measy_tpp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig_factory\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelConfig, BaseConfig\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\easy_tpp\\config_factory\\data_config.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdataclasses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dataclass, field\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Optional, Dict, Any, Union, List\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01measy_tpp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig_factory\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      4\u001b[39m     BaseConfig,\n\u001b[32m      5\u001b[39m     ConfigValidationError,\n\u001b[32m      6\u001b[39m     config_factory,\n\u001b[32m      7\u001b[39m     config_class,\n\u001b[32m      8\u001b[39m )\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01measy_tpp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlog_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m default_logger\n\u001b[32m     12\u001b[39m \u001b[38;5;129m@config_class\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mtokenizer_config\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mTokenizerConfig\u001b[39;00m(BaseConfig):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\easy_tpp\\config_factory\\base.py:16\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdataclasses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dataclass, field\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcopy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deepcopy\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01measy_tpp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Registrable\n\u001b[32m     18\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n\u001b[32m     20\u001b[39m ConfigType = TypeVar(\u001b[33m\"\u001b[39m\u001b[33mConfigType\u001b[39m\u001b[33m\"\u001b[39m, bound=\u001b[33m\"\u001b[39m\u001b[33mBaseConfig\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\easy_tpp\\utils\\__init__.py:48\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01measy_tpp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mode_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m rk4_step_method\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01measy_tpp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mregistrable\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Registrable\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01measy_tpp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtorch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     49\u001b[39m     set_device,\n\u001b[32m     50\u001b[39m     set_optimizer,\n\u001b[32m     51\u001b[39m     set_seed,\n\u001b[32m     52\u001b[39m     count_model_params,\n\u001b[32m     53\u001b[39m )\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01measy_tpp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgeneric\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_torch_device, is_numpy_array\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01measy_tpp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgen_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     56\u001b[39m     generate_and_save_json,\n\u001b[32m     57\u001b[39m     format_gen_data_to_hf,\n\u001b[32m     58\u001b[39m     format_multivariate_simulations,\n\u001b[32m     59\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\easy_tpp\\utils\\torch_utils.py:5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrandom\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01measy_tpp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimport_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_torch_mps_available\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mset_seed\u001b[39m(seed=\u001b[32m1029\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\torch\\__init__.py:2240\u001b[39m\n\u001b[32m   2236\u001b[39m sys.modules.setdefault(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.classes\u001b[39m\u001b[33m\"\u001b[39m, classes)\n\u001b[32m   2238\u001b[39m \u001b[38;5;66;03m# quantization depends on torch.fx and torch.ops\u001b[39;00m\n\u001b[32m   2239\u001b[39m \u001b[38;5;66;03m# Import quantization\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2240\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m quantization \u001b[38;5;28;01mas\u001b[39;00m quantization  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m   2242\u001b[39m \u001b[38;5;66;03m# Import the quasi random sampler\u001b[39;00m\n\u001b[32m   2243\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m quasirandom \u001b[38;5;28;01mas\u001b[39;00m quasirandom  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\torch\\quantization\\__init__.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# mypy: allow-untyped-defs\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfake_quantize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfuse_modules\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fuse_modules\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfuser_method_mappings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\torch\\quantization\\fake_quantize.py:10\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# flake8: noqa: F401\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mThis file is in the process of migration to `torch/ao/quantization`, and\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03mis kept here for compatibility while the migration process is ongoing.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      7\u001b[39m \u001b[33;03mhere.\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mao\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfake_quantize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     11\u001b[39m     _is_fake_quant_script_module,\n\u001b[32m     12\u001b[39m     _is_per_channel,\n\u001b[32m     13\u001b[39m     _is_per_tensor,\n\u001b[32m     14\u001b[39m     _is_symmetric_quant,\n\u001b[32m     15\u001b[39m     default_fake_quant,\n\u001b[32m     16\u001b[39m     default_fixed_qparams_range_0to1_fake_quant,\n\u001b[32m     17\u001b[39m     default_fixed_qparams_range_neg1to1_fake_quant,\n\u001b[32m     18\u001b[39m     default_fused_act_fake_quant,\n\u001b[32m     19\u001b[39m     default_fused_per_channel_wt_fake_quant,\n\u001b[32m     20\u001b[39m     default_fused_wt_fake_quant,\n\u001b[32m     21\u001b[39m     default_histogram_fake_quant,\n\u001b[32m     22\u001b[39m     default_per_channel_weight_fake_quant,\n\u001b[32m     23\u001b[39m     default_weight_fake_quant,\n\u001b[32m     24\u001b[39m     disable_fake_quant,\n\u001b[32m     25\u001b[39m     disable_observer,\n\u001b[32m     26\u001b[39m     enable_fake_quant,\n\u001b[32m     27\u001b[39m     enable_observer,\n\u001b[32m     28\u001b[39m     FakeQuantize,\n\u001b[32m     29\u001b[39m     FakeQuantizeBase,\n\u001b[32m     30\u001b[39m     FixedQParamsFakeQuantize,\n\u001b[32m     31\u001b[39m     FusedMovingAvgObsFakeQuantize,\n\u001b[32m     32\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\torch\\ao\\quantization\\__init__.py:12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfuser_method_mappings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mobserver\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpt2e\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_numeric_debugger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     13\u001b[39m     compare_results,\n\u001b[32m     14\u001b[39m     CUSTOM_KEY,\n\u001b[32m     15\u001b[39m     extract_results_from_loggers,\n\u001b[32m     16\u001b[39m     generate_numeric_debug_handle,\n\u001b[32m     17\u001b[39m     NUMERIC_DEBUG_HANDLE_KEY,\n\u001b[32m     18\u001b[39m     prepare_for_propagation_comparison,\n\u001b[32m     19\u001b[39m )\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpt2e\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexport_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     21\u001b[39m     _allow_exported_model_train_eval \u001b[38;5;28;01mas\u001b[39;00m allow_exported_model_train_eval,\n\u001b[32m     22\u001b[39m     _move_exported_model_to_eval \u001b[38;5;28;01mas\u001b[39;00m move_exported_model_to_eval,\n\u001b[32m     23\u001b[39m     _move_exported_model_to_train \u001b[38;5;28;01mas\u001b[39;00m move_exported_model_to_train,\n\u001b[32m     24\u001b[39m )\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mqconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\torch\\ao\\quantization\\pt2e\\_numeric_debugger.py:9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mao\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mns\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compute_sqnr\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mao\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpt2e\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m bfs_trace_with_node_process\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExportedProgram\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GraphModule, Node\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\torch\\ao\\quantization\\pt2e\\graph_utils.py:9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Optional, Union\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExportedProgram\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Node\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpasses\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msource_matcher_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     12\u001b[39m     check_subgraphs_connected,\n\u001b[32m     13\u001b[39m     get_source_partitions,\n\u001b[32m     14\u001b[39m     SourcePartition,\n\u001b[32m     15\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1322\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1262\u001b[39m, in \u001b[36m_find_spec\u001b[39m\u001b[34m(name, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1559\u001b[39m, in \u001b[36mfind_spec\u001b[39m\u001b[34m(cls, fullname, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1533\u001b[39m, in \u001b[36m_get_spec\u001b[39m\u001b[34m(cls, fullname, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1632\u001b[39m, in \u001b[36mfind_spec\u001b[39m\u001b[34m(self, fullname, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:152\u001b[39m, in \u001b[36m_path_stat\u001b[39m\u001b[34m(path)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the project root directory to PYTHONPATH\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# EasyTPP imports\n",
    "from easy_tpp.config_factory import RunnerConfig\n",
    "from easy_tpp.utils.yaml_config_utils import parse_runner_yaml_config\n",
    "from easy_tpp.runner import Runner\n",
    "\n",
    "print(\"✅ EasyTPP imported successfully!\")\n",
    "print(f\"📁 Project directory: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b812fe",
   "metadata": {},
   "source": [
    "## 2. Basic Concepts {#2-concepts}\n",
    "\n",
    "### What is a Temporal Point Process?\n",
    "\n",
    "A **Temporal Point Process** (TPP) is a sequence of events that occur over time. Each event is characterized by:\n",
    "\n",
    "- **Occurrence time**: When the event happens\n",
    "- **Event type**: What category of event (optional)\n",
    "\n",
    "### Application examples:\n",
    "\n",
    "- 🏥 **Medical**: Patient arrivals at a hospital\n",
    "- 💰 **Finance**: Stock market transactions\n",
    "- 🌍 **Geophysics**: Earthquakes\n",
    "- 📱 **Social Networks**: User posts\n",
    "\n",
    "### Models available in EasyTPP:\n",
    "\n",
    "- **NHP** (Neural Hawkes Process): Hawkes processes with neural networks\n",
    "- **THP** (Transformer Hawkes Process): Based on Transformer architecture\n",
    "- **RMTPP** (Recurrent Marked Temporal Point Process): Based on RNNs\n",
    "- **AttNHP** (Attentive Neural Hawkes Process): With attention mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55403dc1",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preparation {#3-donnees}\n",
    "\n",
    "EasyTPP supports multiple data formats. Let's see how to load and prepare data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc56858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easy_tpp.config_factory import DataConfig\n",
    "from easy_tpp.config_factory.data_config import DataLoadingSpecsConfig, TokenizerConfig\n",
    "from easy_tpp.data.preprocess import TPPDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9f78f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Data configuration created:\n",
      "   Dataset: test\n",
      "   Format: pickle\n",
      "   Event types: 2\n",
      "   Batch size: 32\n",
      "   Number of workers: 1\n",
      "   Padding side: left\n"
     ]
    }
   ],
   "source": [
    "# Data configuration with proper nested structure\n",
    "data_config = DataConfig(\n",
    "    test_dir=\"NzoCs/test_dataset\",                  # Directory for test data\n",
    "    valid_dir=\"NzoCs/test_dataset\",                 # Directory for validation data\n",
    "    train_dir=\"NzoCs/test_dataset\",            # Source directory for data\n",
    "    dataset_id=\"test\",                          # Dataset to use\n",
    "    data_format=\"json\",                       # Data format (pickle, json, csv)\n",
    "    data_loading_specs=DataLoadingSpecsConfig(\n",
    "        batch_size=32,                          # Batch size\n",
    "        num_workers=1,                          # Number of workers for data loading\n",
    "        shuffle=True                            # Shuffle data\n",
    "    ),\n",
    "    data_specs=TokenizerConfig(\n",
    "        num_event_types=2,                      # Number of event types\n",
    "        padding_side='left',                    # Padding side\n",
    "        truncation_side='left'                  # Truncation side\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"📊 Data configuration created:\")\n",
    "print(f\"   Dataset: {data_config.dataset_id}\")\n",
    "print(f\"   Format: {data_config.data_format}\")\n",
    "print(f\"   Event types: {data_config.data_specs.num_event_types}\")\n",
    "print(f\"   Batch size: {data_config.data_loading_specs.batch_size}\")\n",
    "print(f\"   Number of workers: {data_config.data_loading_specs.num_workers}\")\n",
    "print(f\"   Padding side: {data_config.data_specs.padding_side}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7900d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;20m2025-07-12 17:53:51,034 - data_config.py[pid:17904;line:214:from_dict] - WARNING: Only source_dir provided (NzoCs/test_dataset). Using it for train_dir, valid_dir, and test_dir. Consider providing separate directories for better data organization.\u001b[0m\n",
      "📊 Alternative DataConfig created from dictionary:\n",
      "   Dataset: test\n",
      "   Format: pickle\n",
      "   Event types: 2\n",
      "   Batch size: 32\n"
     ]
    }
   ],
   "source": [
    "# Alternative: Create DataConfig using from_dict (simpler approach)\n",
    "data_config_dict = {\n",
    "    \"source_dir\": \"NzoCs/test_dataset\",\n",
    "    \"dataset_id\": \"test\",\n",
    "    \"data_format\": \"json\",\n",
    "    \"data_loading_specs\": {\n",
    "        \"batch_size\": 32,\n",
    "        \"num_workers\": 1,\n",
    "        \"shuffle\": True\n",
    "    },\n",
    "    \"data_specs\": {\n",
    "        \"num_event_types\": 2,\n",
    "        \"padding_side\": \"left\",\n",
    "        \"truncation_side\": \"left\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create DataConfig from dictionary\n",
    "data_config_alt = DataConfig.from_dict(data_config_dict)\n",
    "\n",
    "print(\"📊 Alternative DataConfig created from dictionary:\")\n",
    "print(f\"   Dataset: {data_config_alt.dataset_id}\")\n",
    "print(f\"   Format: {data_config_alt.data_format}\")\n",
    "print(f\"   Event types: {data_config_alt.data_specs.num_event_types}\")\n",
    "print(f\"   Batch size: {data_config_alt.data_loading_specs.batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839c8bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2025-07-12 17:55:12,055 - data_loader.py[pid:17904;line:140:setup] - INFO: Setting up data for stage: fit\u001b[0m\n",
      "\u001b[38;20m2025-07-12 17:55:14,772 - data_loader.py[pid:17904;line:149:setup] - INFO: Train dataset created with 6 sequences\u001b[0m\n",
      "\u001b[38;20m2025-07-12 17:55:17,282 - data_loader.py[pid:17904;line:158:setup] - INFO: Validation dataset created with 2 sequences\u001b[0m\n",
      "✅ Data loaders created successfully!\n",
      "   📈 Train loader: 1 batches\n",
      "   📊 Validation loader: 1 batches\n"
     ]
    }
   ],
   "source": [
    "# Create data module\n",
    "datamodule = TPPDataModule(data_config_alt)\n",
    "datamodule.setup(stage='fit')  # Setup for training and validation\n",
    "\n",
    "# Get data loaders\n",
    "train_loader = datamodule.train_dataloader()\n",
    "val_loader = datamodule.val_dataloader()\n",
    "\n",
    "print(\"✅ Data loaders created successfully!\")\n",
    "print(f\"   📈 Train loader: {len(train_loader)} batches\")\n",
    "print(f\"   📊 Validation loader: {len(val_loader)} batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add42398",
   "metadata": {},
   "source": [
    "### Data Inspection\n",
    "\n",
    "Let's use the Visualizer to analyze the data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5e9c6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Visualizer.show_all_distributions() got an unexpected keyword argument 'save_graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      4\u001b[39m visualizer = Visualizer(\n\u001b[32m      5\u001b[39m     data_module=datamodule,\n\u001b[32m      6\u001b[39m     split=\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m     save_dir=\u001b[33m\"\u001b[39m\u001b[33m./analysis_plots\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m )\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Generate visualizations\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mvisualizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshow_all_distributions\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_graph\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_graph\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m visualizer.delta_times_distribution(save_graph=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     13\u001b[39m visualizer.event_type_distribution(save_graph=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mTypeError\u001b[39m: Visualizer.show_all_distributions() got an unexpected keyword argument 'save_graph'"
     ]
    }
   ],
   "source": [
    "from easy_tpp.data.preprocess.visualizer import Visualizer\n",
    "\n",
    "# Create the visualizer\n",
    "visualizer = Visualizer(\n",
    "    data_module=datamodule,\n",
    "    split=\"train\",\n",
    "    save_dir=\"./analysis_plots\"\n",
    ")\n",
    "\n",
    "# Generate visualizations\n",
    "visualizer.show_all_distributions(save_graph=True, show_graph=False)\n",
    "visualizer.delta_times_distribution(save_graph=True)\n",
    "visualizer.event_type_distribution(save_graph=True)\n",
    "\n",
    "print(\"📈 Analysis plots generated!\")\n",
    "print(\"   Check the './analysis_plots' folder for saved graphs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a746ab2",
   "metadata": {},
   "source": [
    "## 4. Model Configuration and Training {#4-entrainement}\n",
    "\n",
    "Now, let's configure and train a Neural Hawkes Process (NHP) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd1aaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;20m2025-07-12 17:57:00,142 - logger_config.py[pid:17904;line:232:from_dict] - WARNING: Filtered out invalid LoggerConfig keys: {'type', 'name'}\u001b[0m\n",
      "⚙️ Model configuration:\n",
      "   🧠 Model: NHP\n",
      "   📊 Dataset: test\n"
     ]
    }
   ],
   "source": [
    "# Load configuration from YAML file\n",
    "config_file = project_root / \"examples\" / \"runner_config.yaml\"\n",
    "runner_dict = parse_runner_yaml_config(str(config_file), \"NHP\", \"test\")\n",
    "\n",
    "# Create configuration\n",
    "config = RunnerConfig.from_dict(runner_dict)\n",
    "\n",
    "print(\"⚙️ Model configuration:\")\n",
    "print(f\"   🧠 Model: NHP\")\n",
    "print(f\"   📊 Dataset: test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84658b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31;1m2025-07-12 17:57:03,616 - runner.py[pid:17904;line:39:__init__] - CRITICAL: Runner initialized for model: NHP on dataset: test\u001b[0m\n",
      "🚀 Starting training...\n",
      "   This may take a few minutes depending on your configuration.\n",
      "\u001b[38;20m2025-07-12 17:57:03,621 - runner.py[pid:17904;line:129:run] - INFO: Runner executing phases: ['train']\u001b[0m\n",
      "\u001b[38;20m2025-07-12 17:57:03,623 - runner.py[pid:17904;line:72:train] - INFO: === TRAINING PHASE ===\u001b[0m\n",
      "\u001b[38;20m2025-07-12 17:57:03,640 - lightning_runner.py[pid:17904;line:117:__init__] - INFO: No valid checkpoint found. Starting from scratch.\u001b[0m\n",
      "\u001b[38;20m2025-07-12 17:57:03,643 - lightning_runner.py[pid:17904;line:222:train] - INFO: --- Starting Training for Model : NHP on dataset : test ---\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2025-07-12 17:57:03,873 - data_loader.py[pid:17904;line:140:setup] - INFO: Setting up data for stage: fit\u001b[0m\n",
      "\u001b[38;20m2025-07-12 17:57:07,141 - data_loader.py[pid:17904;line:149:setup] - INFO: Train dataset created with 6 sequences\u001b[0m\n",
      "\u001b[38;20m2025-07-12 17:57:10,435 - data_loader.py[pid:17904;line:158:setup] - INFO: Validation dataset created with 2 sequences\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | layer_type_emb  | Embedding        | 192    | train\n",
      "1 | rnn_cell        | ContTimeLSTMCell | 57.8 K | train\n",
      "2 | layer_intensity | Sequential       | 132    | train\n",
      "-------------------------------------------------------------\n",
      "58.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "58.1 K    Total params\n",
      "0.232     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:310: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=5). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss=2.300]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 2.681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  2.43it/s, v_num=0, train_loss=1.870, val_loss=2.680]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.354 >= min_delta = 0.0. New best score: 2.327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00,  2.44it/s, v_num=0, train_loss=1.640, val_loss=2.330]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.203 >= min_delta = 0.0. New best score: 2.124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s, v_num=0, train_loss=1.510, val_loss=2.120]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.139 >= min_delta = 0.0. New best score: 1.985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  2.82it/s, v_num=0, train_loss=1.430, val_loss=1.980]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.094 >= min_delta = 0.0. New best score: 1.891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00,  2.89it/s, v_num=0, train_loss=1.380, val_loss=1.890]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.062 >= min_delta = 0.0. New best score: 1.829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00,  2.41it/s, v_num=0, train_loss=1.340, val_loss=1.830]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.038 >= min_delta = 0.0. New best score: 1.791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00,  2.80it/s, v_num=0, train_loss=1.310, val_loss=1.790]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.025 >= min_delta = 0.0. New best score: 1.766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00,  2.62it/s, v_num=0, train_loss=1.280, val_loss=1.770]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.018 >= min_delta = 0.0. New best score: 1.748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  2.61it/s, v_num=0, train_loss=1.260, val_loss=1.750]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.013 >= min_delta = 0.0. New best score: 1.736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  2.46it/s, v_num=0, train_loss=1.140, val_loss=1.840]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 5 records. Best score: 1.736. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s, v_num=0, train_loss=1.140, val_loss=1.890]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Please call `iter(combined_loader)` first.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:48\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:599\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    593\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    594\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    595\u001b[39m     ckpt_path,\n\u001b[32m    596\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    597\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    598\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1018\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1017\u001b[39m log.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: trainer tearing down\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1018\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_teardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.fn == TrainerFn.FITTING:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1039\u001b[39m, in \u001b[36mTrainer._teardown\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m loop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1039\u001b[39m     \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mteardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1040\u001b[39m \u001b[38;5;28mself\u001b[39m._logger_connector.teardown()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:504\u001b[39m, in \u001b[36m_FitLoop.teardown\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    503\u001b[39m     \u001b[38;5;28mself\u001b[39m._data_fetcher = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m504\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepoch_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mteardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:414\u001b[39m, in \u001b[36m_TrainingEpochLoop.teardown\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    413\u001b[39m \u001b[38;5;28mself\u001b[39m._results.cpu()\n\u001b[32m--> \u001b[39m\u001b[32m414\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mval_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mteardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py:321\u001b[39m, in \u001b[36m_EvaluationLoop.teardown\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mteardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m     \u001b[38;5;28mself\u001b[39m._data_fetcher = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\fetchers.py:82\u001b[39m, in \u001b[36m_DataFetcher.teardown\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._combined_loader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_combined_loader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;28mself\u001b[39m.iterator = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\pytorch_lightning\\utilities\\combined_loader.py:367\u001b[39m, in \u001b[36mCombinedLoader.reset\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m iterable \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.flattened:\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m     \u001b[43m_shutdown_workers_and_reset_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterable\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\pytorch_lightning\\utilities\\combined_loader.py:400\u001b[39m, in \u001b[36m_shutdown_workers_and_reset_iterator\u001b[39m\u001b[34m(dataloader)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataloader._iterator, _MultiProcessingDataLoaderIter):\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     \u001b[43mdataloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_iterator\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_shutdown_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m dataloader._iterator = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1627\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._shutdown_workers\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1623\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._workers:\n\u001b[32m   1624\u001b[39m     \u001b[38;5;66;03m# We should be able to join here, but in case anything went\u001b[39;00m\n\u001b[32m   1625\u001b[39m     \u001b[38;5;66;03m# wrong, we set a timeout and if the workers fail to join,\u001b[39;00m\n\u001b[32m   1626\u001b[39m     \u001b[38;5;66;03m# they are killed in the `finally` block.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1627\u001b[39m     \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMP_STATUS_CHECK_INTERVAL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1628\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._index_queues:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python313\\Lib\\multiprocessing\\process.py:149\u001b[39m, in \u001b[36mBaseProcess.join\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._popen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mcan only join a started process\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_popen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python313\\Lib\\multiprocessing\\popen_spawn_win32.py:114\u001b[39m, in \u001b[36mPopen.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    112\u001b[39m     msecs = \u001b[38;5;28mmax\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mint\u001b[39m(timeout * \u001b[32m1000\u001b[39m + \u001b[32m0.5\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m res = \u001b[43m_winapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mWaitForSingleObject\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsecs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m res == _winapi.WAIT_OBJECT_0:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m   This may take a few minutes depending on your configuration.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphase\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Training completed!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\easy_tpp\\runner\\runner.py:134\u001b[39m, in \u001b[36mRunner.run\u001b[39m\u001b[34m(self, phase)\u001b[39m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m current_phase \u001b[38;5;129;01min\u001b[39;00m phases:\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m current_phase == \u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m         results[current_phase] = \u001b[33m\"\u001b[39m\u001b[33mcompleted\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m current_phase == \u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\easy_tpp\\runner\\runner.py:74\u001b[39m, in \u001b[36mRunner.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     72\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33m=== TRAINING PHASE ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     73\u001b[39m trainer = \u001b[38;5;28mself\u001b[39m._create_trainer(enable_logging=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\easy_tpp\\runner\\lightning_runner.py:233\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    230\u001b[39m train_dataloader = \u001b[38;5;28mself\u001b[39m.datamodule.train_dataloader()\n\u001b[32m    231\u001b[39m val_dataloader = \u001b[38;5;28mself\u001b[39m.datamodule.val_dataloader()\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:561\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:61\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     59\u001b[39m signal.signal(signal.SIGINT, signal.SIG_IGN)\n\u001b[32m     60\u001b[39m _interrupt(trainer, exception)\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_teardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m launcher = trainer.strategy.launcher\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1039\u001b[39m, in \u001b[36mTrainer._teardown\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1037\u001b[39m \u001b[38;5;66;03m# loop should never be `None` here but it can because we don't know the trainer stage with `ddp_spawn`\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m loop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1039\u001b[39m     \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mteardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1040\u001b[39m \u001b[38;5;28mself\u001b[39m._logger_connector.teardown()\n\u001b[32m   1041\u001b[39m \u001b[38;5;28mself\u001b[39m._signal_connector.teardown()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:504\u001b[39m, in \u001b[36m_FitLoop.teardown\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    502\u001b[39m     \u001b[38;5;28mself\u001b[39m._data_fetcher.teardown()\n\u001b[32m    503\u001b[39m     \u001b[38;5;28mself\u001b[39m._data_fetcher = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m504\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepoch_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mteardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:414\u001b[39m, in \u001b[36m_TrainingEpochLoop.teardown\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mteardown\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    413\u001b[39m     \u001b[38;5;28mself\u001b[39m._results.cpu()\n\u001b[32m--> \u001b[39m\u001b[32m414\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mval_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mteardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py:321\u001b[39m, in \u001b[36m_EvaluationLoop.teardown\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mteardown\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mteardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m         \u001b[38;5;28mself\u001b[39m._data_fetcher = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28mself\u001b[39m._results.cpu()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\fetchers.py:80\u001b[39m, in \u001b[36m_DataFetcher.teardown\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mteardown\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._combined_loader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     82\u001b[39m         \u001b[38;5;28mself\u001b[39m._combined_loader.reset()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\fetchers.py:142\u001b[39m, in \u001b[36m_PrefetchDataFetcher.reset\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m     \u001b[38;5;28mself\u001b[39m.batches = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\fetchers.py:76\u001b[39m, in \u001b[36m_DataFetcher.reset\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# teardown calls `reset()`, and if it happens early, `combined_loader` can still be None\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._combined_loader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[38;5;28mself\u001b[39m.length = \u001b[43msized_len\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcombined_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m     \u001b[38;5;28mself\u001b[39m.done = \u001b[38;5;28mself\u001b[39m.length == \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\lightning_fabric\\utilities\\data.py:52\u001b[39m, in \u001b[36msized_len\u001b[39m\u001b[34m(dataloader)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Try to get the length of an object, return ``None`` otherwise.\"\"\"\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     51\u001b[39m     \u001b[38;5;66;03m# try getting the length\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     length = \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore [arg-type]\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m):\n\u001b[32m     54\u001b[39m     length = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\pytorch_lightning\\utilities\\combined_loader.py:358\u001b[39m, in \u001b[36mCombinedLoader.__len__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    356\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute the number of batches.\"\"\"\u001b[39;00m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m358\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mPlease call `iter(combined_loader)` first.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._iterator)\n",
      "\u001b[31mRuntimeError\u001b[39m: Please call `iter(combined_loader)` first."
     ]
    }
   ],
   "source": [
    "# Create runner and start training\n",
    "runner = Runner(config=config, output_dir=\"./training_results\")\n",
    "\n",
    "print(\"🚀 Starting training...\")\n",
    "print(\"   This may take a few minutes depending on your configuration.\")\n",
    "\n",
    "# Train the model\n",
    "runner.run(phase=\"train\")\n",
    "\n",
    "print(\"✅ Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de87b8ef",
   "metadata": {},
   "source": [
    "## 5. Evaluation and Metrics {#5-evaluation}\n",
    "\n",
    "Let's now evaluate the performance of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcaf902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Evaluating model on test dataset...\n",
      "\u001b[38;20m2025-07-12 18:00:02,705 - runner.py[pid:17904;line:129:run] - INFO: Runner executing phases: ['test']\u001b[0m\n",
      "\u001b[31;1m2025-07-12 18:00:02,707 - runner.py[pid:17904;line:85:test] - CRITICAL: === TESTING PHASE ===\u001b[0m\n",
      "\u001b[38;20m2025-07-12 18:00:02,712 - lightning_runner.py[pid:17904;line:104:__init__] - INFO: Checkpoint found: loading from ./training_results\\best.ckpt\u001b[0m\n",
      "\u001b[38;20m2025-07-12 18:00:02,714 - lightning_runner.py[pid:17904;line:115:__init__] - INFO: Loading model from checkpoint: ./training_results\\best.ckpt.\u001b[0m\n",
      "\u001b[38;20m2025-07-12 18:00:02,716 - lightning_runner.py[pid:17904;line:246:test] - INFO: --- Starting Testing for Model : NHP on dataset : test ---\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2025-07-12 18:00:02,785 - data_loader.py[pid:17904;line:140:setup] - INFO: Setting up data for stage: test\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at ./training_results\\best.ckpt\n",
      "Loaded model weights from the checkpoint at ./training_results\\best.ckpt\n",
      "c:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  5.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       cross_entropy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4799283444881439     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       macro_f1score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     83.18921661376953     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         precision         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     83.33332824707031     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          recall           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     83.10344696044922     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.0598340034484863     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         time_mae          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     2.146207571029663     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         time_rmse         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     2.949763059616089     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       type_accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     83.33332824707031     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      cross_entropy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4799283444881439    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      macro_f1score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    83.18921661376953    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        precision        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    83.33332824707031    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         recall          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    83.10344696044922    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.0598340034484863    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        time_mae         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    2.146207571029663    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        time_rmse        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    2.949763059616089    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      type_accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    83.33332824707031    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2025-07-12 18:00:48,859 - lightning_runner.py[pid:17904;line:270:test] - INFO: Test results saved to ./training_results\\test_results.json\u001b[0m\n",
      "📊 Evaluation results:\n",
      "   ✅ Evaluation completed - check logs for detailed metrics\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on test dataset\n",
    "print(\"🧪 Evaluating model on test dataset...\")\n",
    "\n",
    "test_results = runner.run(phase=\"test\")\n",
    "\n",
    "print(\"📊 Evaluation results:\")\n",
    "if hasattr(runner, 'test_metrics'):\n",
    "    for metric_name, value in runner.test_metrics.items():\n",
    "        print(f\"   {metric_name}: {value:.4f}\")\n",
    "else:\n",
    "    print(\"✅ Evaluation completed - check logs for detailed metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98613a0c",
   "metadata": {},
   "source": [
    "### Comparison with Baselines\n",
    "\n",
    "Let's compare our model with simple baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843afc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2025-07-12 18:02:41,162 - data_loader.py[pid:17904;line:140:setup] - INFO: Setting up data for stage: test\u001b[0m\n",
      "📊 Baseline benchmark (mean):\n",
      "\u001b[38;20m2025-07-12 18:02:44,880 - base_bench.py[pid:17904;line:147:evaluate] - INFO: Starting mean_inter_time benchmark evaluation...\u001b[0m\n",
      "\u001b[38;20m2025-07-12 18:02:44,886 - mean_bench.py[pid:17904;line:51:_prepare_benchmark] - INFO: Computing mean inter-time from training data...\u001b[0m\n",
      "\u001b[38;20m2025-07-12 18:03:16,165 - mean_bench.py[pid:17904;line:74:_prepare_benchmark] - INFO: Computed mean inter-time: 1.506245\u001b[0m\n",
      "\u001b[38;20m2025-07-12 18:03:47,672 - base_bench.py[pid:17904;line:366:_save_results] - INFO: Results saved to: ./benchmark_results\\mean_baseline\\mean_inter_time_results.json\u001b[0m\n",
      "\u001b[38;20m2025-07-12 18:03:47,678 - base_bench.py[pid:17904;line:375:_log_summary] - INFO: mean_inter_time benchmark completed successfully!\u001b[0m\n",
      "\u001b[38;20m2025-07-12 18:03:47,683 - base_bench.py[pid:17904;line:381:_log_summary] - INFO: Time RMSE: 2.772637\u001b[0m\n",
      "\u001b[38;20m2025-07-12 18:03:47,685 - base_bench.py[pid:17904;line:383:_log_summary] - INFO: Time MAE: 1.840395\u001b[0m\n",
      "   Results: {'benchmark_name': 'mean_inter_time', 'dataset_name': 'mean_baseline', 'num_event_types': 2, 'metrics': {'time_rmse_mean': 2.772637367248535, 'time_rmse_std': 0.0, 'time_rmse_min': 2.772637367248535, 'time_rmse_max': 2.772637367248535, 'time_mae_mean': 1.8403947353363037, 'time_mae_std': 0.0, 'time_mae_min': 1.8403947353363037, 'time_mae_max': 1.8403947353363037}, 'num_batches_evaluated': 1, 'mean_inter_time_used': 1.5062450681413924}\n",
      "\u001b[38;20m2025-07-12 18:03:50,893 - data_loader.py[pid:17904;line:140:setup] - INFO: Setting up data for stage: test\u001b[0m\n",
      "\n",
      "📊 Type distribution benchmark:\n",
      "\u001b[38;20m2025-07-12 18:03:53,947 - base_bench.py[pid:17904;line:147:evaluate] - INFO: Starting mark_distribution_sampling benchmark evaluation...\u001b[0m\n",
      "\u001b[38;20m2025-07-12 18:03:53,948 - sample_distrib_mark_bench.py[pid:17904;line:55:_prepare_benchmark] - INFO: Collecting event marks from test data...\u001b[0m\n",
      "\u001b[38;20m2025-07-12 18:04:25,214 - sample_distrib_mark_bench.py[pid:17904;line:92:_prepare_benchmark] - INFO: Collected 56 event marks\u001b[0m\n",
      "\u001b[38;20m2025-07-12 18:04:25,231 - sample_distrib_mark_bench.py[pid:17904;line:93:_prepare_benchmark] - INFO: Event type distribution: {0: tensor(0.4464), 1: tensor(0.5536)}\u001b[0m\n",
      "\u001b[38;20m2025-07-12 18:04:56,277 - base_bench.py[pid:17904;line:366:_save_results] - INFO: Results saved to: ./benchmark_results\\mark_baseline\\mark_distribution_sampling_results.json\u001b[0m\n",
      "\u001b[38;20m2025-07-12 18:04:56,279 - base_bench.py[pid:17904;line:375:_log_summary] - INFO: mark_distribution_sampling benchmark completed successfully!\u001b[0m\n",
      "\u001b[38;20m2025-07-12 18:04:56,280 - base_bench.py[pid:17904;line:387:_log_summary] - INFO: Type Accuracy: 57.142860\u001b[0m\n",
      "\u001b[38;20m2025-07-12 18:04:56,281 - base_bench.py[pid:17904;line:389:_log_summary] - INFO: Macro F1 Score: 55.731225\u001b[0m\n",
      "   Results: {'benchmark_name': 'mark_distribution_sampling', 'dataset_name': 'mark_baseline', 'num_event_types': 2, 'metrics': {'type_accuracy_mean': 57.14285969734192, 'type_accuracy_std': 0.0, 'type_accuracy_min': 57.14285969734192, 'type_accuracy_max': 57.14285969734192, 'macro_f1score_mean': 55.73122501373291, 'macro_f1score_std': 0.0, 'macro_f1score_min': 55.73122501373291, 'macro_f1score_max': 55.73122501373291, 'recall_mean': 55.87096810340881, 'recall_std': 0.0, 'recall_min': 55.87096810340881, 'recall_max': 55.87096810340881, 'precision_mean': 56.190478801727295, 'precision_std': 0.0, 'precision_min': 56.190478801727295, 'precision_max': 56.190478801727295, 'cross_entropy_mean': 0.7418331503868103, 'cross_entropy_std': 0.0, 'cross_entropy_min': 0.7418331503868103, 'cross_entropy_max': 0.7418331503868103, 'confusion_matrix': [[11, 14], [10, 21]]}, 'num_batches_evaluated': 1, 'distribution_stats': {'entropy': 0.6873963475227356}}\n"
     ]
    }
   ],
   "source": [
    "from easy_tpp.evaluation.benchmarks.mean_bench import MeanInterTimeBenchmark\n",
    "from easy_tpp.evaluation.benchmarks.sample_distrib_mark_bench import MarkDistributionBenchmark\n",
    "\n",
    "# Baseline benchmark: mean prediction\n",
    "mean_benchmark = MeanInterTimeBenchmark(\n",
    "    data_config=data_config_alt,\n",
    "    experiment_id=\"mean_baseline\",\n",
    "    save_dir=\"./benchmark_results\"\n",
    ")\n",
    "\n",
    "print(\"📊 Baseline benchmark (mean):\")\n",
    "mean_results = mean_benchmark.evaluate()\n",
    "print(f\"   Results: {mean_results}\")\n",
    "\n",
    "# Type distribution benchmark\n",
    "mark_benchmark = MarkDistributionBenchmark(\n",
    "    data_config=data_config_alt,\n",
    "    experiment_id=\"mark_baseline\",\n",
    "    save_dir=\"./benchmark_results\"\n",
    ")\n",
    "\n",
    "print(\"\\n📊 Type distribution benchmark:\")\n",
    "mark_results = mark_benchmark.evaluate()\n",
    "print(f\"   Results: {mark_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79af9f88",
   "metadata": {},
   "source": [
    "## 6. Advanced Examples {#6-avances}\n",
    "\n",
    "### Synthetic Data Generation\n",
    "\n",
    "EasyTPP allows generating synthetic data to test models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fa8e887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎲 Generating synthetic data...\n",
      "Génération de 10 simulations 2D...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulation de 10 processus: 100%|██████████| 10/10 [00:00<00:00, 33.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Division des données en ensembles train/test/dev...\n",
      "Sauvegarde des données...\n",
      "Toutes les données ont été sauvegardées dans ./synthetic_data\n",
      "✅ Synthetic data generated in './synthetic_data'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from easy_tpp.data.generation import HawkesSimulator\n",
    "\n",
    "# Hawkes process configuration\n",
    "params = {\n",
    "    \"mu\": [0.1, 0.2],                    # Base intensities\n",
    "    \"alpha\": [[0.3, 0.1], [0.2, 0.4]],  # Excitation matrix\n",
    "    \"beta\": [[2, 1], [1.5, 3]]          # Decay matrix\n",
    "}\n",
    "\n",
    "# Create simulator\n",
    "simulator = HawkesSimulator(\n",
    "    mu=params[\"mu\"],\n",
    "    alpha=params[\"alpha\"],\n",
    "    beta=params[\"beta\"],\n",
    "    dim_process=2,\n",
    "    start_time=0,\n",
    "    end_time=100\n",
    ")\n",
    "\n",
    "print(\"🎲 Generating synthetic data...\")\n",
    "\n",
    "# Generate and save\n",
    "simulator.generate_and_save(\n",
    "    output_dir='./synthetic_data',\n",
    "    num_simulations=10,\n",
    "    splits={'train': 0.6, 'test': 0.2, 'dev': 0.2}\n",
    ")\n",
    "\n",
    "print(\"✅ Synthetic data generated in './synthetic_data'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c842bf",
   "metadata": {},
   "source": [
    "### Multiple Model Comparison\n",
    "\n",
    "Let's compare the performance of different models on the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e7f0b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 Training model NHP...\n",
      "   ❌ Error with NHP: name 'project_root' is not defined...\n",
      "\n",
      "🧠 Training model THP...\n",
      "   ❌ Error with THP: name 'project_root' is not defined...\n",
      "\n",
      "🧠 Training model RMTPP...\n",
      "   ❌ Error with RMTPP: name 'project_root' is not defined...\n",
      "\n",
      "📊 Comparison summary:\n",
      "   NHP: ❌ Error: name 'project_root' is not defined...\n",
      "   THP: ❌ Error: name 'project_root' is not defined...\n",
      "   RMTPP: ❌ Error: name 'project_root' is not defined...\n"
     ]
    }
   ],
   "source": [
    "# List of models to compare\n",
    "models_to_compare = ['NHP', 'THP', 'RMTPP']\n",
    "results_comparison = {}\n",
    "\n",
    "for model_name in models_to_compare:\n",
    "    print(f\"\\n🧠 Training model {model_name}...\")\n",
    "    \n",
    "    try:\n",
    "        # Configuration for this model\n",
    "        config_file = project_root / \"examples\" / \"runner_config.yaml\"\n",
    "        model_config_dict = parse_runner_yaml_config(str(config_file), model_name, \"test\")\n",
    "        \n",
    "        config = RunnerConfig.from_dict(model_config_dict)\n",
    "        runner = Runner(config=config, output_dir=f\"./comparison_results/{model_name}\")\n",
    "        \n",
    "        # Quick training (fewer epochs for demo)\n",
    "        runner.run(phase=\"train\")\n",
    "        test_results = runner.run(phase=\"test\")\n",
    "        \n",
    "        results_comparison[model_name] = \"✅ Success\"\n",
    "        print(f\"   ✅ {model_name} trained successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        results_comparison[model_name] = f\"❌ Error: {str(e)[:50]}...\"\n",
    "        print(f\"   ❌ Error with {model_name}: {str(e)[:50]}...\")\n",
    "\n",
    "print(\"\\n📊 Comparison summary:\")\n",
    "for model, result in results_comparison.items():\n",
    "    print(f\"   {model}: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea5c53f",
   "metadata": {},
   "source": [
    "## 🎉 Conclusion\n",
    "\n",
    "This notebook has covered the main features of EasyTPP:\n",
    "\n",
    "✅ **Environment setup** and imports\n",
    "\n",
    "✅ **Understanding basic concepts** of TPPs\n",
    "\n",
    "✅ **Data loading and preparation**\n",
    "\n",
    "✅ **Model configuration and training**\n",
    "\n",
    "✅ **Evaluation and comparison** with baselines\n",
    "\n",
    "✅ **Synthetic data generation**\n",
    "\n",
    "✅ **Multiple model comparison**\n",
    "\n",
    "### 🚀 Next Steps\n",
    "\n",
    "- Explore other available models (AttNHP, Transformer-based)\n",
    "- Test with your own data\n",
    "- Adjust hyperparameters to optimize performance\n",
    "- Use advanced analysis tools to understand model behavior\n",
    "\n",
    "### 📚 Useful Resources\n",
    "\n",
    "- [EasyTPP Documentation](https://github.com/your-repo/EasyTPP)\n",
    "- [Additional Examples](../examples/)\n",
    "- [Advanced Configuration](../configs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249be884",
   "metadata": {},
   "source": [
    "## 6. Prediction Phase and Distribution Analysis\n",
    "\n",
    "**Why the prediction phase is crucial:**\n",
    "\n",
    "Temporal Point Process (TPP) models don't just serve to calculate performance metrics - their true value lies in their ability to **predict and simulate** new events. These predictions enable:\n",
    "\n",
    "1. **Distribution comparisons** - Analyze whether the model captures temporal patterns well\n",
    "2. **Realistic benchmarks** - Compare model simulations to real data  \n",
    "3. **Qualitative validation** - Visualize differences between predictions and reality\n",
    "4. **Practical applications** - Generate future scenarios for decision-making\n",
    "\n",
    "### 6.1 Complete Pipeline with Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b125ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Complete pipeline with predictions...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'parse_runner_yaml_config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m🔄 Complete pipeline with predictions...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Configuration\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m config_dict = \u001b[43mparse_runner_yaml_config\u001b[49m(\n\u001b[32m      6\u001b[39m     yaml_path=\u001b[33m\"\u001b[39m\u001b[33m../examples/runner_config.yaml\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m     experiment_id=\u001b[33m\"\u001b[39m\u001b[33mNHP\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m      8\u001b[39m     dataset_id=\u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m )\n\u001b[32m     10\u001b[39m config = RunnerConfig.from_dict(config_dict)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Runner\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'parse_runner_yaml_config' is not defined"
     ]
    }
   ],
   "source": [
    "# Complete example: train → test → predict\n",
    "print(\"🔄 Complete pipeline with predictions...\")\n",
    "\n",
    "# Configuration\n",
    "config_dict = parse_runner_yaml_config(\n",
    "    yaml_path=\"../configs/runner_config.yaml\",\n",
    "    experiment_id=\"NHP\", \n",
    "    dataset_id=\"test\"\n",
    ")\n",
    "config = RunnerConfig.from_dict(config_dict)\n",
    "\n",
    "# Runner\n",
    "runner = Runner(config=config, output_dir=\"./prediction_analysis\")\n",
    "\n",
    "# Phase 1: Training\n",
    "print(\"📚 1. Training the model...\")\n",
    "runner.run(phase=\"train\")\n",
    "\n",
    "# Phase 2: Test/Evaluation  \n",
    "print(\"🧪 2. Performance evaluation...\")\n",
    "runner.run(phase=\"test\")\n",
    "\n",
    "# Phase 3: Predictions and comparisons (CRUCIAL!)\n",
    "print(\"🔮 3. Generating predictions and distribution comparisons...\")\n",
    "runner.run(phase=\"predict\")\n",
    "\n",
    "print(\"✅ Complete pipeline finished!\")\n",
    "print(\"📊 Results available in:\")\n",
    "print(\"   - Performance metrics\")\n",
    "print(\"   - Model simulations\") \n",
    "print(\"   - Distribution comparisons\")\n",
    "print(\"   - Analysis graphs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aa3b9d",
   "metadata": {},
   "source": [
    "### 6.2 Simplified Alternative: Single Command\n",
    "\n",
    "If you want the complete pipeline all at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca0febb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ultra-simple version: everything in one command\n",
    "runner = Runner(config=config, output_dir=\"./complete_pipeline\")\n",
    "\n",
    "# Automatically executes: train → test → predict\n",
    "runner.run(phase=\"all\")\n",
    "\n",
    "print(\"🎉 Complete pipeline executed with phase='all'!\")\n",
    "print(\"💡 This command is equivalent to the 3 separate phases above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004da06e",
   "metadata": {},
   "source": [
    "### 6.3 Why Predictions Are Essential\n",
    "\n",
    "**🎯 Main objective:** Verify that the model has learned the correct temporal distributions.\n",
    "\n",
    "**📊 What the `predict` phase generates:**\n",
    "- **Event simulations** based on the trained model\n",
    "- **Visual comparisons** between real and simulated data\n",
    "- **Statistical analyses** of temporal distributions\n",
    "- **Prediction quality metrics**\n",
    "\n",
    "**🔍 Practical applications:**\n",
    "- **Finance:** Predict trading volume peaks\n",
    "- **Healthcare:** Anticipate epidemics or relapses\n",
    "- **Networks:** Forecast traffic overloads\n",
    "- **Social:** Model information propagation\n",
    "\n",
    "**⚠️ Crucial point:** Without the prediction phase, you only have numerical metrics. With predictions, you can **see** if your model truly understands the temporal dynamics of your data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
