GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
INFO:datasets:PyTorch version 2.6.0 available.
Generating train split:   0%|          | 0/9000 [00:00<?, ? examples/s]Generating train split:  11%|█         | 1000/9000 [00:01<00:08, 908.02 examples/s]Generating train split: 100%|██████████| 9000/9000 [00:01<00:00, 7837.11 examples/s]
Generating test split:   0%|          | 0/3000 [00:00<?, ? examples/s]Generating test split: 100%|██████████| 3000/3000 [00:00<00:00, 185176.26 examples/s]
Generating validation split:   0%|          | 0/3000 [00:00<?, ? examples/s]Generating validation split: 100%|██████████| 3000/3000 [00:00<00:00, 196123.82 examples/s]
INFO:easy_tpp.preprocess.data_loader:Train dataset created with 9000 sequences
INFO:easy_tpp.preprocess.data_loader:Validation dataset created with 3000 sequences
/gpfs/workdir/regnaguen/LTPP/lib/python3.9/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 31 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name            | Type             | Params | Mode 
-------------------------------------------------------------
0 | layer_type_emb  | Embedding        | 64     | train
1 | event_sampler   | EventSampler     | 0      | train
2 | rnn_cell        | ContTimeLSTMCell | 14.6 K | train
3 | layer_intensity | Sequential       | 34     | train
-------------------------------------------------------------
14.7 K    Trainable params
0         Non-trainable params
14.7 K    Total params
0.059     Total estimated model params size (MB)
8         Modules in train mode
0         Modules in eval mode
SLURM auto-requeueing enabled. Setting signal handlers.
`Trainer.fit` stopped: `max_epochs=400` reached.
