GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
INFO:datasets:PyTorch version 2.6.0 available.
INFO:easy_tpp.preprocess.data_loader:Train dataset created with 9000 sequences
INFO:easy_tpp.preprocess.data_loader:Validation dataset created with 3000 sequences
/gpfs/workdir/regnaguen/LTPP/lib/python3.9/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 31 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name                       | Type         | Params | Mode 
--------------------------------------------------------------------
0 | layer_type_emb             | Embedding    | 64     | train
1 | event_sampler              | EventSampler | 0      | train
2 | layer_temporal_emb         | Linear       | 64     | train
3 | layer_rnn                  | RNN          | 2.1 K  | train
4 | hidden_to_intensity_logits | Linear       | 33     | train
  | other params               | n/a          | 2      | n/a  
--------------------------------------------------------------------
2.3 K     Trainable params
0         Non-trainable params
2.3 K     Total params
0.009     Total estimated model params size (MB)
5         Modules in train mode
0         Modules in eval mode
SLURM auto-requeueing enabled. Setting signal handlers.
`Trainer.fit` stopped: `max_epochs=400` reached.
