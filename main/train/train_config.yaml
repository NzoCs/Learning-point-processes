pipeline_config_id: runner_config

data:

  taxi:
    data_format: json
    train_dir: easytpp/taxi
    valid_dir: easytpp/taxi
    test_dir: easytpp/taxi
    data_specs:
      num_event_types: 10
      pad_token_id: 10
      padding_side: left

  test:
    data_format: json
    train_dir: NzoCs/test_dataset-temporal-dataset
    valid_dir: NzoCs/test_dataset-temporal-dataset
    test_dir: NzoCs/test_dataset-temporal-dataset
    data_specs:
      num_event_types: 2
      pad_token_id: 2
      padding_side: left
      
  H2expi:
    data_format: json
    train_dir: NzoCs/H2expi-temporal-dataset
    valid_dir: NzoCs/H2expi-temporal-dataset
    test_dir: NzoCs/H2expi-temporal-dataset
    data_specs:
      num_event_types: 2
      pad_token_id: 2
      padding_side: left

  H2expc:
    data_format: json
    train_dir: NzoCs/H2expc-temporal-dataset
    valid_dir: NzoCs/H2expc-temporal-dataset
    test_dir: NzoCs/H2expc-temporal-dataset
    data_specs:
      num_event_types: 2
      pad_token_id: 2
      padding_side: left

  hawkes1:
    data_format: json
    train_dir: NzoCs/hawkes1-temporal-dataset
    valid_dir: NzoCs/hawkes1-temporal-dataset
    test_dir: NzoCs/hawkes1-temporal-dataset
    data_specs:
      num_event_types: 1
      pad_token_id: 1
      padding_side: left

  hawkes2:
    data_format: json
    train_dir: NzoCs/hawkes2-temporal-dataset
    valid_dir: NzoCs/hawkes2-temporal-dataset
    test_dir: NzoCs/hawkes2-temporal-dataset
    data_specs:
      num_event_types: 2
      pad_token_id: 2
      padding_side: left

  self_correcting:
    data_format: json
    train_dir: NzoCs/self_correcting-temporal-dataset
    valid_dir: NzoCs/self_correcting-temporal-dataset
    test_dir: NzoCs/self_correcting-temporal-dataset
    data_specs:
      num_event_types: 1
      pad_token_id: 1
      padding_side: left



NHP_train:

  data_loading_specs:
    batch_size: 64
    num_workers: 4
    
  model_config:
    model_id: NHP
    specs:
      hidden_size: 64
      time_emb_size: 16
      num_layers: 2
    thinning:
      num_exp: 500 # number of i.i.d. Exp(intensity_bound) draws at one time in thinning algorithm
      over_sample_rate: 1.5
      dtime_max: 5
    base_config:
      lr: 0.001
      lr_scheduler: True

  trainer_config:
    stage: train
    max_epochs: 400
    val_freq: 10
    accumulate_grad_batches: 1
    lr: 0.001
    lr_scheduler: True
    logger_config:
      type: tensorboard
      name: logs

RMTPP_train:

  data_loading_specs:
    batch_size: 64
    num_workers: 4
    
  model_config:
    model_id: RMTPP
    specs:
      hidden_size: 32
      time_emb_size: 16
      num_layers: 2
    thinning:
      num_exp: 500 # number of i.i.d. Exp(intensity_bound) draws at one time in thinning algorithm
      over_sample_rate: 1.5
      dtime_max: 5
    base_config:
      lr: 0.001
      lr_scheduler: True

  trainer_config:
    stage: train
    max_epochs: 400
    val_freq: 10
    accumulate_grad_batches: 1
    logger_config:
      type: tensorboard
      name: logs

AttNHP_train:

  data_loading_specs:
    batch_size: 64
    num_workers: 4
    
  model_config:
    model_id: AttNHP
    specs:
      hidden_size: 32
      time_emb_size: 16
      num_layers: 1
      num_heads: 2
    thinning:
      num_exp: 500 # number of i.i.d. Exp(intensity_bound) draws at one time in thinning algorithm
      over_sample_rate: 1.5
      dtime_max: 5

  trainer_config:
    stage: train
    max_epochs: 400
    val_freq: 10
    accumulate_grad_batches: 1
    lr: 0.001
    lr_scheduler: True
    logger_config:
      type: tensorboard
      name: logs

SAHP_train:

  data_loading_specs:
    batch_size: 64
    num_workers: 4
    
  model_config:
    model_id: SAHP
    specs:
      hidden_size: 32
      time_emb_size: 16
      num_layers: 2
      num_heads: 2
    base_config:
      lr: 0.001
      lr_scheduler: True
    thinning:
      num_exp: 500 # number of i.i.d. Exp(intensity_bound) draws at one time in thinning algorithm
      over_sample_rate: 1.5
      dtime_max: 5

  trainer_config:
    stage: train
    max_epochs: 400
    val_freq: 10
    accumulate_grad_batches: 1
    logger_config:
      type: tensorboard
      name: logs

THP_train:

  data_loading_specs:
    batch_size: 64
    num_workers: 4
    
  model_config:
    model_id: THP
    specs:
      hidden_size: 64
      time_emb_size: 16
      num_layers: 2
      num_heads: 2
    base_config:
      lr: 0.001
      lr_scheduler: True
    thinning:
      num_exp: 500
      over_sample_rate: 1.5
      dtime_max: 5

  trainer_config:
    stage: train
    max_epochs: 400
    val_freq: 10
    accumulate_grad_batches: 1
    logger_config:
      type: tensorboard
      name: logs

FullyNN_train:

  data_loading_specs:
    batch_size: 64
    num_workers: 4
    
  model_config:
    model_id: FullyNN
    specs:
      hidden_size: 32
      time_emb_size: 16
      num_layers: 2
    base_config:
      lr: 0.001
      lr_scheduler: True
    thinning:
      num_exp: 500 # number of i.i.d. Exp(intensity_bound) draws at one time in thinning algorithm
      over_sample_rate: 1.5
      dtime_max: 5
      
  trainer_config:
    stage: train
    max_epochs: 400
    val_freq: 10
    accumulate_grad_batches: 1
    logger_config:
      type: tensorboard
      name: logs

IntensityFree_train:

  data_loading_specs:
    batch_size: 64
    num_workers: 4
    
  model_config:
    model_id: IntensityFree
    specs:
      hidden_size: 32
      time_emb_size: 16
      num_layers: 2
    thinning:
      num_exp: 500 # number of i.i.d. Exp(intensity_bound) draws at one time in thinning algorithm
      over_sample_rate: 1.5
      dtime_max: 5
    base_config:
      lr: 0.001
      lr_scheduler: True
      
  trainer_config:
    stage: train
    max_epochs: 400
    val_freq: 10
    accumulate_grad_batches: 1
    logger_config:
      type: tensorboard
      name: logs


ODETPP_train:

  data_loading_specs:
    batch_size: 64
    num_workers: 4
    
  model_config:
    model_id: ODETPP
    specs:
      hidden_size: 32
      time_emb_size: 16
      num_layers: 2
    thinning:
      num_exp: 500
      over_sample_rate: 1.5
      dtime_max: 5
    base_config:
      lr: 0.001
      lr_scheduler: True
      
      
  trainer_config:
    stage: train
    max_epochs: 400
    val_freq: 10
    accumulate_grad_batches: 1
    logger_config:
      type: tensorboard
      name: logs