{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e83fbafa",
   "metadata": {},
   "source": [
    "# EasyTPP - Data Generation & Benchmarks\n",
    "\n",
    "This notebook demonstrates how to use EasyTPP for:\n",
    "- Generating synthetic data with different simulators\n",
    "- Performing benchmarks with different baselines\n",
    "- Analyzing and comparing results\n",
    "\n",
    "## 📋 Contents\n",
    "\n",
    "1. [Setup and imports](#setup)\n",
    "2. [Synthetic data generation](#generation)\n",
    "3. [Benchmarks and baselines](#benchmarks)\n",
    "4. [Comparative analysis](#analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b410680",
   "metadata": {},
   "source": [
    "## 1. Setup and imports {#setup}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81059f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Add project root directory to PYTHONPATH\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# EasyTPP imports\n",
    "from easy_tpp.data.generation import HawkesSimulator, SelfCorrecting\n",
    "from easy_tpp.config_factory import DataConfig\n",
    "from easy_tpp.evaluation.benchmarks.mean_bench import MeanInterTimeBenchmark\n",
    "from easy_tpp.evaluation.benchmarks.sample_distrib_mark_bench import MarkDistributionBenchmark\n",
    "from easy_tpp.evaluation.benchmarks.sample_distrib_intertime_bench import InterTimeDistributionBenchmark\n",
    "\n",
    "print(\"✅ Modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd30679",
   "metadata": {},
   "source": [
    "## 2. Synthetic data generation {#generation}\n",
    "\n",
    "### Bivariate Hawkes Process\n",
    "\n",
    "Let's generate data with a 2-dimensional Hawkes process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6994b818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate Hawkes process configuration\n",
    "params_hawkes = {\n",
    "    \"mu\": [0.2, 0.15],                    # Base intensities\n",
    "    \"alpha\": [[0.4, 0.1], [0.2, 0.3]],   # Excitation matrix\n",
    "    \"beta\": [[2, 1], [1.5, 2.5]]         # Decay matrix\n",
    "}\n",
    "\n",
    "print(\"🎲 Hawkes process configuration:\")\n",
    "print(f\"   Base intensities (μ): {params_hawkes['mu']}\")\n",
    "print(f\"   Excitation matrix (α): {params_hawkes['alpha']}\")\n",
    "print(f\"   Decay matrix (β): {params_hawkes['beta']}\")\n",
    "\n",
    "# Create simulator\n",
    "hawkes_simulator = HawkesSimulator(\n",
    "    mu=params_hawkes[\"mu\"],\n",
    "    alpha=params_hawkes[\"alpha\"],\n",
    "    beta=params_hawkes[\"beta\"],\n",
    "    dim_process=2,\n",
    "    start_time=0,\n",
    "    end_time=100\n",
    ")\n",
    "\n",
    "print(\"\\n🚀 Generating Hawkes data...\")\n",
    "hawkes_simulator.generate_and_save(\n",
    "    output_dir='./synthetic_hawkes',\n",
    "    num_simulations=50,\n",
    "    splits={'train': 0.6, 'test': 0.2, 'dev': 0.2}\n",
    ")\n",
    "\n",
    "print(\"✅ Hawkes data generated in './synthetic_hawkes'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f43fbc1",
   "metadata": {},
   "source": [
    "### Self-Correcting Process\n",
    "\n",
    "Let's also generate data with a self-correcting process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ae1c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate self-correcting process\n",
    "self_correcting_simulator = SelfCorrecting(\n",
    "    dim_process=1,\n",
    "    start_time=0,\n",
    "    end_time=200\n",
    ")\n",
    "\n",
    "print(\"🎲 Generating self-correcting data...\")\n",
    "self_correcting_simulator.generate_and_save(\n",
    "    output_dir='./synthetic_self_correcting',\n",
    "    num_simulations=30,\n",
    "    splits={'train': 0.7, 'test': 0.15, 'dev': 0.15}\n",
    ")\n",
    "\n",
    "print(\"✅ Self-correcting data generated in './synthetic_self_correcting'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfa64a6",
   "metadata": {},
   "source": [
    "### Complex Multivariate Hawkes Process\n",
    "\n",
    "Let's create a more complex process with 3 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd364a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex multivariate configuration\n",
    "params_complex = {\n",
    "    \"mu\": [0.1, 0.15, 0.12],\n",
    "    \"alpha\": [\n",
    "        [0.3, 0.1, 0.05],\n",
    "        [0.2, 0.4, 0.15],\n",
    "        [0.1, 0.2, 0.35]\n",
    "    ],\n",
    "    \"beta\": [\n",
    "        [2.5, 1.5, 1.0],\n",
    "        [2.0, 3.0, 1.5],\n",
    "        [1.5, 2.5, 3.5]\n",
    "    ]\n",
    "}\n",
    "\n",
    "complex_simulator = HawkesSimulator(\n",
    "    mu=params_complex[\"mu\"],\n",
    "    alpha=params_complex[\"alpha\"],\n",
    "    beta=params_complex[\"beta\"],\n",
    "    dim_process=3,\n",
    "    start_time=0,\n",
    "    end_time=150\n",
    ")\n",
    "\n",
    "print(\"🎲 Generating 3D Hawkes data...\")\n",
    "complex_simulator.generate_and_save(\n",
    "    output_dir='./synthetic_hawkes_3d',\n",
    "    num_simulations=25,\n",
    "    splits={'train': 0.6, 'test': 0.25, 'dev': 0.15}\n",
    ")\n",
    "\n",
    "print(\"✅ 3D Hawkes data generated in './synthetic_hawkes_3d'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0706f5ec",
   "metadata": {},
   "source": [
    "## 3. Benchmarks and baselines {#benchmarks}\n",
    "\n",
    "Now, let's evaluate different baselines on our synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108be8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for benchmarks on synthetic Hawkes data\n",
    "data_config_hawkes = DataConfig(\n",
    "    dataset_id=\"synthetic_hawkes\",\n",
    "    data_format=\"pickle\",\n",
    "    num_event_types=2,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "print(\"📊 Benchmark configuration:\")\n",
    "print(f\"   Dataset: {data_config_hawkes.dataset_id}\")\n",
    "print(f\"   Event types: {data_config_hawkes.num_event_types}\")\n",
    "print(f\"   Batch size: {data_config_hawkes.batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01a4283",
   "metadata": {},
   "source": [
    "### Benchmark 1: Mean Inter-Event Time Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f157516f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark: Mean prediction\n",
    "mean_benchmark = MeanInterTimeBenchmark(\n",
    "    data_config=data_config_hawkes,\n",
    "    experiment_id=\"mean_hawkes_baseline\",\n",
    "    save_dir=\"./benchmark_results\"\n",
    ")\n",
    "\n",
    "print(\"🎯 Running mean benchmark...\")\n",
    "mean_results = mean_benchmark.evaluate()\n",
    "\n",
    "print(\"📈 Mean benchmark results:\")\n",
    "for metric, value in mean_results.items():\n",
    "    if isinstance(value, (int, float)):\n",
    "        print(f\"   {metric}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"   {metric}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cd1fa9",
   "metadata": {},
   "source": [
    "### Benchmark 2: Event Type Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbce1698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark: Type distribution\n",
    "mark_benchmark = MarkDistributionBenchmark(\n",
    "    data_config=data_config_hawkes,\n",
    "    experiment_id=\"mark_hawkes_baseline\",\n",
    "    save_dir=\"./benchmark_results\"\n",
    ")\n",
    "\n",
    "print(\"🎯 Running type distribution benchmark...\")\n",
    "mark_results = mark_benchmark.evaluate()\n",
    "\n",
    "print(\"📈 Type distribution benchmark results:\")\n",
    "for metric, value in mark_results.items():\n",
    "    if isinstance(value, (int, float)):\n",
    "        print(f\"   {metric}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"   {metric}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af9a35f",
   "metadata": {},
   "source": [
    "### Benchmark 3: Inter-Event Time Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c988c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark: Inter-event time distribution\n",
    "intertime_benchmark = InterTimeDistributionBenchmark(\n",
    "    data_config=data_config_hawkes,\n",
    "    experiment_id=\"intertime_hawkes_baseline\",\n",
    "    save_dir=\"./benchmark_results\"\n",
    ")\n",
    "\n",
    "print(\"🎯 Running inter-time distribution benchmark...\")\n",
    "intertime_results = intertime_benchmark.evaluate()\n",
    "\n",
    "print(\"📈 Inter-time distribution benchmark results:\")\n",
    "for metric, value in intertime_results.items():\n",
    "    if isinstance(value, (int, float)):\n",
    "        print(f\"   {metric}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"   {metric}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcd8f0e",
   "metadata": {},
   "source": [
    "## 4. Comparative analysis {#analysis}\n",
    "\n",
    "### Baseline Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf5e2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect results for comparison\n",
    "all_benchmarks = {\n",
    "    'Mean Inter-Time': mean_results,\n",
    "    'Mark Distribution': mark_results,\n",
    "    'Inter-Time Distribution': intertime_results\n",
    "}\n",
    "\n",
    "print(\"📊 Comparative benchmark summary:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Structured display of results\n",
    "for benchmark_name, results in all_benchmarks.items():\n",
    "    print(f\"\\n🎯 {benchmark_name}:\")\n",
    "    for metric, value in results.items():\n",
    "        if isinstance(value, (int, float)):\n",
    "            print(f\"   {metric:<25}: {value:>10.4f}\")\n",
    "        else:\n",
    "            print(f\"   {metric:<25}: {str(value):>10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdffa125",
   "metadata": {},
   "source": [
    "### Benchmarks on Different Datasets\n",
    "\n",
    "Let's compare performance on different types of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c510cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmarks on different datasets\n",
    "datasets_to_test = [\n",
    "    ('test', 'pickle', 2),\n",
    "    ('synthetic_hawkes', 'pickle', 2),\n",
    "    ('synthetic_hawkes_3d', 'pickle', 3)\n",
    "]\n",
    "\n",
    "comparative_results = {}\n",
    "\n",
    "for dataset_id, data_format, num_types in datasets_to_test:\n",
    "    print(f\"\\n🧪 Testing on {dataset_id}...\")\n",
    "    \n",
    "    try:\n",
    "        # Configuration for this dataset\n",
    "        test_config = DataConfig(\n",
    "            dataset_id=dataset_id,\n",
    "            data_format=data_format,\n",
    "            num_event_types=num_types,\n",
    "            batch_size=16\n",
    "        )\n",
    "        \n",
    "        # Test with mean benchmark\n",
    "        test_benchmark = MeanInterTimeBenchmark(\n",
    "            data_config=test_config,\n",
    "            experiment_id=f\"mean_{dataset_id}\",\n",
    "            save_dir=\"./comparative_results\"\n",
    "        )\n",
    "        \n",
    "        results = test_benchmark.evaluate()\n",
    "        comparative_results[dataset_id] = results\n",
    "        \n",
    "        print(f\"   ✅ Success on {dataset_id}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Error on {dataset_id}: {str(e)[:50]}...\")\n",
    "        comparative_results[dataset_id] = None\n",
    "\n",
    "print(\"\\n📈 Comparative results by dataset:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for dataset, results in comparative_results.items():\n",
    "    print(f\"\\n📊 {dataset}:\")\n",
    "    if results:\n",
    "        for metric, value in results.items():\n",
    "            if isinstance(value, (int, float)):\n",
    "                print(f\"   {metric}: {value:.4f}\")\n",
    "    else:\n",
    "        print(\"   ❌ No results available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff82d52",
   "metadata": {},
   "source": [
    "## 🎉 Conclusion\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "✅ **Synthetic data generation** with different simulators\n",
    "- Bivariate and multivariate Hawkes processes\n",
    "- Self-correcting process\n",
    "- Flexible parameter configuration\n",
    "\n",
    "✅ **Evaluation with robust baselines**\n",
    "- Mean inter-event time prediction\n",
    "- Event type distribution\n",
    "- Inter-event time distribution\n",
    "\n",
    "✅ **Comparative analysis** on different datasets\n",
    "- Systematic performance comparison\n",
    "- Evaluation on real and synthetic data\n",
    "\n",
    "### 🚀 Possible applications:\n",
    "\n",
    "- **Model validation**: Use these baselines as reference points\n",
    "- **Ablation studies**: Understand the impact of different components\n",
    "- **Data generation**: Create datasets to test new algorithms\n",
    "- **Exploratory analysis**: Understand data characteristics"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
