{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "380fc504",
   "metadata": {},
   "source": [
    "# EasyTPP - Getting Started Guide\n",
    "\n",
    "This notebook presents the main features of the **EasyTPP** (Easy Temporal Point Processes) library with practical examples.\n",
    "\n",
    "## ğŸ¯ Notebook Objectives\n",
    "\n",
    "- Understand the basic concepts of temporal point processes\n",
    "- Learn to configure and train models\n",
    "- Explore the different types of data and available models\n",
    "- Visualize and analyze results\n",
    "\n",
    "## ğŸ“š Table of Contents\n",
    "\n",
    "1. [Environment Setup](#1-configuration)\n",
    "2. [Basic Concepts](#2-concepts)\n",
    "3. [Data Loading and Preparation](#3-data-loading-and-preparation)\n",
    "4. [Model Configuration and Training](#4-model-configuration-and-training)\n",
    "5. [Evaluation and Metrics](#5-evaluation-and-metrics)\n",
    "6. [Distribution analysis](#6-advanced-examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09a9e71",
   "metadata": {},
   "source": [
    "## 1. Environment Setup {#1-configuration}\n",
    "\n",
    "Let's start by importing the necessary modules and setting up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d560867c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… EasyTPP imported successfully!\n",
      "ğŸ“ Project directory: c:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Add the project root directory to PYTHONPATH\n",
    "ROOT = Path().absolute().parent\n",
    "\n",
    "CONFIGS = ROOT / \"configs\" / \"test_runner_config.yaml\"\n",
    "\n",
    "# EasyTPP imports (use the new builders and runner manager)\n",
    "from easy_tpp.configs.config_builder import RunnerConfigBuilder, DataConfigBuilder\n",
    "from easy_tpp.runners import RunnerManager\n",
    "from easy_tpp.configs.config_factory import config_factory, ConfigType\n",
    "\n",
    "print(\"âœ… EasyTPP imported successfully!\")\n",
    "print(f\"ğŸ“ Project directory: {ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b812fe",
   "metadata": {},
   "source": [
    "## 2. Basic Concepts {#2-concepts}\n",
    "\n",
    "### What is a Temporal Point Process?\n",
    "\n",
    "A **Temporal Point Process** (TPP) is a sequence of events that occur over time. Each event is characterized by:\n",
    "\n",
    "- **Occurrence time**: When the event happens\n",
    "- **Event type**: What category of event (optional)\n",
    "\n",
    "### Application examples:\n",
    "\n",
    "- ğŸ¥ **Medical**: Patient arrivals at a hospital\n",
    "- ğŸ’° **Finance**: Stock market transactions\n",
    "- ğŸŒ **Geophysics**: Earthquakes\n",
    "- ğŸ“± **Social Networks**: User posts\n",
    "\n",
    "### Models available in EasyTPP:\n",
    "\n",
    "- **NHP** (Neural Hawkes Process): Hawkes processes with neural networks\n",
    "- **THP** (Transformer Hawkes Process): Based on Transformer architecture\n",
    "- **RMTPP** (Recurrent Marked Temporal Point Process): Based on RNNs\n",
    "- **AttNHP** (Attentive Neural Hawkes Process): With attention mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55403dc1",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preparation {#3-donnees}\n",
    "\n",
    "EasyTPP supports multiple data formats. Let's see how to load and prepare data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc56858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easy_tpp.data.preprocess import TPPDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9f78f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Data configuration created:\n",
      "   Dataset: test\n",
      "   Format: json\n",
      "   Event types: 2\n",
      "   Batch size: 32\n",
      "   Number of workers: 1\n",
      "   Padding side: left\n"
     ]
    }
   ],
   "source": [
    "# Data configuration with proper nested structure using builders\n",
    "builder = DataConfigBuilder()\n",
    "# If you have a YAML, use builder.load_from_yaml(yaml_path, data_config_path)\n",
    "# Here we set fields programmatically to keep the example self-contained\n",
    "builder.set_field(\"train_dir\", \"NzoCs/test_dataset\")\n",
    "builder.set_field(\"valid_dir\", \"NzoCs/test_dataset\")\n",
    "builder.set_field(\"test_dir\", \"NzoCs/test_dataset\")\n",
    "builder.set_field(\"dataset_id\", \"test\")\n",
    "builder.set_field(\"data_format\", \"json\")\n",
    "# nested specs and loading specs can be plain dicts or config instances\n",
    "builder.set_field(\"data_loading_specs\", {\"batch_size\": 32, \"num_workers\": 1, \"shuffle\": True})\n",
    "builder.set_field(\"data_specs\", {\"num_event_types\": 2, \"padding_side\": \"left\", \"truncation_side\": \"left\"})\n",
    "\n",
    "data_config = builder.get_config_dict()\n",
    "\n",
    "print(\"ğŸ“Š Data configuration created via builder:\")\n",
    "print(f\"   Dataset: {data_config['dataset_id']}\")\n",
    "print(f\"   Format: {data_config['data_format']}\")\n",
    "print(f\"   Event types: {data_config['data_specs']['num_event_types']}\")\n",
    "print(f\"   Batch size: {data_config['data_loading_specs']['batch_size']}\")\n",
    "print(f\"   Number of workers: {data_config['data_loading_specs']['num_workers']}\")\n",
    "print(f\"   Padding side: {data_config['data_specs']['padding_side']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7900d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Alternative DataConfig created from dictionary:\n",
      "   Dataset: test\n",
      "   Format: json\n",
      "   Event types: 2\n",
      "   Batch size: 32\n"
     ]
    }
   ],
   "source": [
    "# Alternative: Create DataConfig using DataConfigBuilder.from_dict or .build()\n",
    "from easy_tpp.configs import DataConfig\n",
    "\n",
    "data_config_dict = {\n",
    "    \"train_dir\": \"NzoCs/test_dataset\",\n",
    "    \"valid_dir\": \"NzoCs/test_dataset\",\n",
    "    \"test_dir\": \"NzoCs/test_dataset\",\n",
    "    \"dataset_id\": \"test\",\n",
    "    \"data_format\": \"json\",\n",
    "    \"data_loading_specs\": {\n",
    "        \"batch_size\": 32,\n",
    "        \"num_workers\": 1,\n",
    "        \"shuffle\": True\n",
    "    },\n",
    "    \"data_specs\": {\n",
    "        \"num_event_types\": 2,\n",
    "        \"padding_side\": \"left\",\n",
    "        \"truncation_side\": \"left\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Use DataConfig.from_dict for direct class creation, or builders + build() to get Config instances\n",
    "# Example using builder.build():\n",
    "builder = DataConfigBuilder()\n",
    "builder.from_dict(data_config_dict, \"dummy\")  # \"dummy\" path not used when passing dict\n",
    "# build returns a DataConfig instance\n",
    "try:\n",
    "    data_config_instance = builder.build()\n",
    "    print(\"ğŸ“Š DataConfig instance created via builder.build()\")\n",
    "    print(f\"   Dataset: {data_config_instance.dataset_id}\")\n",
    "except Exception:\n",
    "    # Fallback to direct from_dict creation\n",
    "    data_config_instance = DataConfig.from_dict(data_config_dict)\n",
    "    print(\"ğŸ“Š DataConfig instance created via DataConfig.from_dict() (fallback)\")\n",
    "\n",
    "print(f\"   Event types: {data_config_instance.data_specs.num_event_types}\")\n",
    "print(f\"   Batch size: {data_config_instance.data_loading_specs.batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "839c8bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2025-09-18 12:58:08,205 - data_loader.py[pid:16224;line:140:setup] - INFO: Setting up data for stage: fit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2025-09-18 12:58:17,257 - data_loader.py[pid:16224;line:149:setup] - INFO: Train dataset created with 6 sequences\u001b[0m\n",
      "\u001b[38;20m2025-09-18 12:58:20,528 - data_loader.py[pid:16224;line:158:setup] - INFO: Validation dataset created with 2 sequences\u001b[0m\n",
      "âœ… Data loaders created successfully!\n",
      "   ğŸ“ˆ Train loader: 1 batches\n",
      "   ğŸ“Š Validation loader: 1 batches\n"
     ]
    }
   ],
   "source": [
    "# Create data module\n",
    "datamodule = TPPDataModule(data_config)\n",
    "datamodule.setup(stage='fit')  # Setup for training and validation\n",
    "\n",
    "# Get data loaders\n",
    "train_loader = datamodule.train_dataloader()\n",
    "val_loader = datamodule.val_dataloader()\n",
    "\n",
    "print(\"âœ… Data loaders created successfully!\")\n",
    "print(f\"   ğŸ“ˆ Train loader: {len(train_loader)} batches\")\n",
    "print(f\"   ğŸ“Š Validation loader: {len(val_loader)} batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add42398",
   "metadata": {},
   "source": [
    "### Data Inspection\n",
    "\n",
    "Let's use the Visualizer to analyze the data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc5e9c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating visualization plots...\n",
      "Inter-event time distribution plot saved to ./analysis_plots\\inter_event_time_dist.png\n",
      "Event type distribution plot saved to ./analysis_plots\\event_type_dist.png\n",
      "Sequence length distribution plot saved to ./analysis_plots\\sequence_length_dist.png\n",
      "All plots generated successfully!\n",
      "Inter-event time distribution plot saved to ./analysis_plots\\inter_event_time_dist.png\n",
      "Event type distribution plot saved to ./analysis_plots\\event_type_dist.png\n",
      "ğŸ“ˆ Analysis plots generated!\n",
      "   Check the './analysis_plots' folder for saved graphs\n"
     ]
    }
   ],
   "source": [
    "from easy_tpp.data.preprocess.visualizer import Visualizer\n",
    "\n",
    "# Create the visualizer\n",
    "visualizer = Visualizer(\n",
    "    data_module=datamodule,\n",
    "    split=\"train\",\n",
    "    save_dir=\"./analysis_plots\"\n",
    ")\n",
    "\n",
    "# Generate visualizations\n",
    "visualizer.show_all_distributions()\n",
    "visualizer.delta_times_distribution()\n",
    "visualizer.event_type_distribution()\n",
    "\n",
    "print(\"ğŸ“ˆ Analysis plots generated!\")\n",
    "print(\"   Check the './analysis_plots' folder for saved graphs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a746ab2",
   "metadata": {},
   "source": [
    "## 4. Model Configuration and Training {#4-entrainement}\n",
    "\n",
    "Now, let's configure and train a Neural Hawkes Process (NHP) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd1aaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ Model configuration:\n",
      "   ğŸ§  Model: NHP\n",
      "   ğŸ“Š Dataset: test\n"
     ]
    }
   ],
   "source": [
    "# Build runner configuration from YAML using RunnerConfigBuilder\n",
    "runner_builder = RunnerConfigBuilder()\n",
    "runner_builder.load_from_yaml(\n",
    "    yaml_file_path=str(CONFIGS),\n",
    "    training_config_path=\"training_configs.quick_test\",\n",
    "    model_config_path=\"model_configs.NHP\",\n",
    "    data_config_path=\"data_configs.test\",\n",
    ")\n",
    "\n",
    "config_dict = runner_builder.get_config_dict()\n",
    "# Use the global factory to create a RunnerConfig (note: model_id passed as extra arg)\n",
    "runner_config = config_factory.create_config(ConfigType.RUNNER, config_dict, model_id=\"NHP\")\n",
    "\n",
    "print(\"âš™ï¸ Runner configuration built via factory + builder\")\n",
    "print(f\"   ğŸ§  Model: NHP\")\n",
    "print(f\"   ğŸ“Š Dataset: test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84658b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31;1m2025-09-18 12:58:49,286 - runner.py[pid:16224;line:39:__init__] - CRITICAL: Runner initialized for model: NHP on dataset: test\u001b[0m\n",
      "ğŸš€ Starting training...\n",
      "   This may take a few minutes depending on your configuration.\n",
      "\u001b[38;20m2025-09-18 12:58:49,289 - runner.py[pid:16224;line:129:run] - INFO: Runner executing phases: ['train']\u001b[0m\n",
      "\u001b[38;20m2025-09-18 12:58:49,290 - runner.py[pid:16224;line:72:train] - INFO: === TRAINING PHASE ===\u001b[0m\n",
      "\u001b[38;20m2025-09-18 12:58:49,298 - model_runner.py[pid:16224;line:116:__init__] - INFO: No valid checkpoint found. Starting from scratch.\u001b[0m\n",
      "\u001b[38;20m2025-09-18 12:58:49,299 - model_runner.py[pid:16224;line:221:train] - INFO: --- Starting Training for Model : NHP on dataset : test ---\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2025-09-18 12:58:49,343 - data_loader.py[pid:16224;line:140:setup] - INFO: Setting up data for stage: fit\u001b[0m\n",
      "\u001b[38;20m2025-09-18 12:58:53,179 - data_loader.py[pid:16224;line:149:setup] - INFO: Train dataset created with 6 sequences\u001b[0m\n",
      "\u001b[38;20m2025-09-18 12:58:56,321 - data_loader.py[pid:16224;line:158:setup] - INFO: Validation dataset created with 2 sequences\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | layer_type_emb  | Embedding        | 192    | train\n",
      "1 | rnn_cell        | ContTimeLSTMCell | 57.8 K | train\n",
      "2 | layer_intensity | Sequential       | 132    | train\n",
      "-------------------------------------------------------------\n",
      "58.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "58.1 K    Total params\n",
      "0.232     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:310: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=5). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.61it/s, v_num=0, train_loss=2.310]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.49it/s, v_num=0, train_loss=2.310]\n",
      "âœ… Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Create runner manager and start training\n",
    "runner = RunnerManager(config=runner_config, output_dir=\"./training_results\")\n",
    "\n",
    "print(\"ğŸš€ Starting training...\")\n",
    "print(\"   This may take a few minutes depending on your configuration.\")\n",
    "\n",
    "# Train the model\n",
    "runner.run(phase=\"train\")\n",
    "\n",
    "print(\"âœ… Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de87b8ef",
   "metadata": {},
   "source": [
    "## 5. Evaluation and Metrics {#5-evaluation}\n",
    "\n",
    "Let's now evaluate the performance of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dcaf902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Evaluating model on test dataset...\n",
      "\u001b[38;20m2025-09-18 13:00:38,842 - runner.py[pid:16224;line:129:run] - INFO: Runner executing phases: ['test']\u001b[0m\n",
      "\u001b[31;1m2025-09-18 13:00:38,859 - runner.py[pid:16224;line:85:test] - CRITICAL: === TESTING PHASE ===\u001b[0m\n",
      "\u001b[38;20m2025-09-18 13:00:38,921 - model_runner.py[pid:16224;line:103:__init__] - INFO: Checkpoint found: loading from ./training_results\\last.ckpt\u001b[0m\n",
      "\u001b[38;20m2025-09-18 13:00:38,928 - model_runner.py[pid:16224;line:114:__init__] - INFO: Loading model from checkpoint: ./training_results\\last.ckpt.\u001b[0m\n",
      "\u001b[38;20m2025-09-18 13:00:38,939 - model_runner.py[pid:16224;line:245:test] - INFO: --- Starting Testing for Model : NHP on dataset : test ---\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2025-09-18 13:00:39,393 - data_loader.py[pid:16224;line:140:setup] - INFO: Setting up data for stage: test\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at ./training_results\\last.ckpt\n",
      "Loaded model weights from the checkpoint at ./training_results\\last.ckpt\n",
      "c:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\">        Test metric        </span>â”ƒ<span style=\"font-weight: bold\">       DataLoader 0        </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">       cross_entropy       </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.49844682216644287    </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">       macro_f1score       </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">     81.37931060791016     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         precision         </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">     81.37931060791016     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">          recall           </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">     81.37931060791016     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    2.0305864810943604     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         time_mae          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    1.7858420610427856     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         time_rmse         </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    2.9778149127960205     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">       type_accuracy       </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">     81.48148345947266     </span>â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m      cross_entropy      \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.49844682216644287   \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m      macro_f1score      \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m    81.37931060791016    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m        precision        \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m    81.37931060791016    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m         recall          \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m    81.37931060791016    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   2.0305864810943604    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m        time_mae         \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   1.7858420610427856    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m        time_rmse        \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   2.9778149127960205    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m      type_accuracy      \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m    81.48148345947266    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2025-09-18 13:01:26,730 - model_runner.py[pid:16224;line:269:test] - INFO: Test results saved to ./training_results\\test_results.json\u001b[0m\n",
      "ğŸ“Š Evaluation results:\n",
      "âœ… Evaluation completed - check logs for detailed metrics\n",
      "ğŸ“Š Evaluation results:\n",
      "âœ… Evaluation completed - check logs for detailed metrics\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on test dataset\n",
    "print(\"ğŸ§ª Evaluating model on test dataset...\")\n",
    "\n",
    "test_results = runner.run(phase=\"test\")\n",
    "\n",
    "print(\"ğŸ“Š Evaluation results:\")\n",
    "if hasattr(runner, 'test_metrics'):\n",
    "    for metric_name, value in runner.test_metrics.items():\n",
    "        print(f\"   {metric_name}: {value:.4f}\")\n",
    "else:\n",
    "    print(\"âœ… Evaluation completed - check logs for detailed metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98613a0c",
   "metadata": {},
   "source": [
    "### Comparison with Baselines\n",
    "\n",
    "Let's compare our model with simple baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843afc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2025-09-18 13:01:34,021 - data_loader.py[pid:16224;line:140:setup] - INFO: Setting up data for stage: test\u001b[0m\n",
      "ğŸ“Š Baseline benchmark (mean):\n",
      "\u001b[38;20m2025-09-18 13:01:37,589 - base_bench.py[pid:16224;line:147:evaluate] - INFO: Starting mean_inter_time benchmark evaluation...\u001b[0m\n",
      "\u001b[38;20m2025-09-18 13:01:37,590 - mean_bench.py[pid:16224;line:51:_prepare_benchmark] - INFO: Computing mean inter-time from training data...\u001b[0m\n",
      "\u001b[38;20m2025-09-18 13:01:51,480 - mean_bench.py[pid:16224;line:74:_prepare_benchmark] - INFO: Computed mean inter-time: 1.506245\u001b[0m\n",
      "\u001b[38;20m2025-09-18 13:02:08,127 - base_bench.py[pid:16224;line:366:_save_results] - INFO: Results saved to: ./benchmark_results\\mean_baseline\\mean_inter_time_results.json\u001b[0m\n",
      "\u001b[38;20m2025-09-18 13:02:08,128 - base_bench.py[pid:16224;line:375:_log_summary] - INFO: mean_inter_time benchmark completed successfully!\u001b[0m\n",
      "\u001b[38;20m2025-09-18 13:02:08,129 - base_bench.py[pid:16224;line:381:_log_summary] - INFO: Time RMSE: 2.772637\u001b[0m\n",
      "\u001b[38;20m2025-09-18 13:02:08,130 - base_bench.py[pid:16224;line:383:_log_summary] - INFO: Time MAE: 1.840395\u001b[0m\n",
      "   Results: {'benchmark_name': 'mean_inter_time', 'dataset_name': 'mean_baseline', 'num_event_types': 2, 'metrics': {'time_rmse_mean': 2.772637367248535, 'time_rmse_std': 0.0, 'time_rmse_min': 2.772637367248535, 'time_rmse_max': 2.772637367248535, 'time_mae_mean': 1.8403947353363037, 'time_mae_std': 0.0, 'time_mae_min': 1.8403947353363037, 'time_mae_max': 1.8403947353363037}, 'num_batches_evaluated': 1, 'mean_inter_time_used': 1.5062450681413924}\n",
      "\u001b[38;20m2025-09-18 13:02:10,034 - data_loader.py[pid:16224;line:140:setup] - INFO: Setting up data for stage: test\u001b[0m\n",
      "\n",
      "ğŸ“Š Type distribution benchmark:\n",
      "\u001b[38;20m2025-09-18 13:02:18,241 - base_bench.py[pid:16224;line:147:evaluate] - INFO: Starting mark_distribution_sampling benchmark evaluation...\u001b[0m\n",
      "\u001b[38;20m2025-09-18 13:02:18,243 - sample_distrib_mark_bench.py[pid:16224;line:55:_prepare_benchmark] - INFO: Collecting event marks from test data...\u001b[0m\n",
      "\u001b[38;20m2025-09-18 13:02:46,354 - sample_distrib_mark_bench.py[pid:16224;line:92:_prepare_benchmark] - INFO: Collected 56 event marks\u001b[0m\n",
      "\u001b[38;20m2025-09-18 13:02:46,365 - sample_distrib_mark_bench.py[pid:16224;line:93:_prepare_benchmark] - INFO: Event type distribution: {0: tensor(0.4464), 1: tensor(0.5536)}\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     16\u001b[39m mark_benchmark = MarkDistributionBenchmark(\n\u001b[32m     17\u001b[39m     data_config=data_config,\n\u001b[32m     18\u001b[39m     experiment_id=\u001b[33m\"\u001b[39m\u001b[33mmark_baseline\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     19\u001b[39m     save_dir=\u001b[33m\"\u001b[39m\u001b[33m./benchmark_results\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     20\u001b[39m )\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mğŸ“Š Type distribution benchmark:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m mark_results = \u001b[43mmark_benchmark\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   Results: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmark_results\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\easy_tpp\\evaluation\\benchmarks\\base_bench.py:155\u001b[39m, in \u001b[36mBaseBenchmark.evaluate\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    152\u001b[39m test_loader = \u001b[38;5;28mself\u001b[39m.data_module.test_dataloader()\n\u001b[32m    153\u001b[39m all_metrics = []\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Convert batch to values for compatibility\u001b[39;49;00m\n\u001b[32m    157\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_values\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Compute metrics based on benchmark mode\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1492\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1489\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1491\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1492\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1493\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1494\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1495\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1454\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1450\u001b[39m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[32m   1451\u001b[39m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[32m   1452\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1453\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1454\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1455\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1456\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1285\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1272\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1273\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1274\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1282\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1283\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1284\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1285\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1286\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1287\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1288\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1289\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1290\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python313\\Lib\\multiprocessing\\queues.py:111\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[32m    110\u001b[39m     timeout = deadline - time.monotonic()\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    112\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._poll():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python313\\Lib\\multiprocessing\\connection.py:257\u001b[39m, in \u001b[36m_ConnectionBase.poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    255\u001b[39m \u001b[38;5;28mself\u001b[39m._check_closed()\n\u001b[32m    256\u001b[39m \u001b[38;5;28mself\u001b[39m._check_readable()\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python313\\Lib\\multiprocessing\\connection.py:346\u001b[39m, in \u001b[36mPipeConnection._poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m    344\u001b[39m             _winapi.PeekNamedPipe(\u001b[38;5;28mself\u001b[39m._handle)[\u001b[32m0\u001b[39m] != \u001b[32m0\u001b[39m):\n\u001b[32m    345\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python313\\Lib\\multiprocessing\\connection.py:1096\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(object_list, timeout)\u001b[39m\n\u001b[32m   1093\u001b[39m                 ready_objects.add(o)\n\u001b[32m   1094\u001b[39m                 timeout = \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1096\u001b[39m     ready_handles = \u001b[43m_exhaustive_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaithandle_to_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1097\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1098\u001b[39m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[32m   1099\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python313\\Lib\\multiprocessing\\connection.py:1028\u001b[39m, in \u001b[36m_exhaustive_wait\u001b[39m\u001b[34m(handles, timeout)\u001b[39m\n\u001b[32m   1026\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[32m   1027\u001b[39m     short_L = L[:\u001b[32m60\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(L) > \u001b[32m60\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m L\n\u001b[32m-> \u001b[39m\u001b[32m1028\u001b[39m     res = \u001b[43m_winapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mWaitForMultipleObjects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshort_L\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1029\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m res == WAIT_TIMEOUT:\n\u001b[32m   1030\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from easy_tpp.evaluation.benchmarks.mean_bench import MeanInterTimeBenchmark\n",
    "from easy_tpp.evaluation.benchmarks.sample_distrib_mark_bench import MarkDistributionBenchmark\n",
    "\n",
    "# Baseline benchmark: mean prediction\n",
    "mean_benchmark = MeanInterTimeBenchmark(\n",
    "    data_config=data_config,\n",
    "    experiment_id=\"mean_baseline\",\n",
    "    save_dir=\"./benchmark_results\"\n",
    ")\n",
    "\n",
    "print(\"ğŸ“Š Baseline benchmark (mean):\")\n",
    "mean_results = mean_benchmark.evaluate()\n",
    "print(f\"   Results: {mean_results}\")\n",
    "\n",
    "# Type distribution benchmark\n",
    "mark_benchmark = MarkDistributionBenchmark(\n",
    "    data_config=data_config,\n",
    "    dataset_name=\"mark_baseline\",\n",
    "    save_dir=\"./benchmark_results\"\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ“Š Type distribution benchmark:\")\n",
    "mark_results = mark_benchmark.evaluate()\n",
    "print(f\"   Results: {mark_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79af9f88",
   "metadata": {},
   "source": [
    "## 6. Advanced Examples {#6-avances}\n",
    "\n",
    "### Synthetic Data Generation\n",
    "\n",
    "EasyTPP allows generating synthetic data to test models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fa8e887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ² Generating synthetic data...\n",
      "GÃ©nÃ©ration de 10 simulations 2D...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulation de 10 processus:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulation de 10 processus: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 73.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Division des donnÃ©es en ensembles train/test/dev...\n",
      "Sauvegarde des donnÃ©es...\n",
      "Toutes les donnÃ©es ont Ã©tÃ© sauvegardÃ©es dans ./synthetic_data\n",
      "âœ… Synthetic data generated in './synthetic_data'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from easy_tpp.data.generation import HawkesSimulator\n",
    "\n",
    "# Hawkes process configuration\n",
    "params = {\n",
    "    \"mu\": [0.1, 0.2],                    # Base intensities\n",
    "    \"alpha\": [[0.3, 0.1], [0.2, 0.4]],  # Excitation matrix\n",
    "    \"beta\": [[2, 1], [1.5, 3]]          # Decay matrix\n",
    "}\n",
    "\n",
    "# Create simulator\n",
    "simulator = HawkesSimulator(\n",
    "    mu=params[\"mu\"],\n",
    "    alpha=params[\"alpha\"],\n",
    "    beta=params[\"beta\"],\n",
    "    dim_process=2,\n",
    "    start_time=0,\n",
    "    end_time=100\n",
    ")\n",
    "\n",
    "print(\"ğŸ² Generating synthetic data...\")\n",
    "\n",
    "# Generate and save\n",
    "simulator.generate_and_save(\n",
    "    output_dir='./synthetic_data',\n",
    "    num_simulations=10,\n",
    "    splits={'train': 0.6, 'test': 0.2, 'dev': 0.2}\n",
    ")\n",
    "\n",
    "print(\"âœ… Synthetic data generated in './synthetic_data'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c842bf",
   "metadata": {},
   "source": [
    "### Multiple Model Comparison\n",
    "\n",
    "Let's compare the performance of different models on the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7f0b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ§  Training model NHP...\n",
      "\u001b[31;1m2025-09-18 03:19:45,632 - runner.py[pid:7980;line:39:__init__] - CRITICAL: Runner initialized for model: NHP on dataset: test\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:19:45,633 - runner.py[pid:7980;line:129:run] - INFO: Runner executing phases: ['train']\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:19:45,634 - runner.py[pid:7980;line:72:train] - INFO: === TRAINING PHASE ===\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:19:45,637 - model_runner.py[pid:7980;line:116:__init__] - INFO: No valid checkpoint found. Starting from scratch.\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:19:45,638 - model_runner.py[pid:7980;line:221:train] - INFO: --- Starting Training for Model : NHP on dataset : test ---\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2025-09-18 03:19:45,665 - data_loader.py[pid:7980;line:140:setup] - INFO: Setting up data for stage: fit\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:19:49,379 - data_loader.py[pid:7980;line:149:setup] - INFO: Train dataset created with 6 sequences\u001b[0m\n",
      "\u001b[38;20m2025-09-18 03:19:54,366 - data_loader.py[pid:7980;line:158:setup] - INFO: Validation dataset created with 2 sequences\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | layer_type_emb  | Embedding        | 192    | train\n",
      "1 | rnn_cell        | ContTimeLSTMCell | 57.8 K | train\n",
      "2 | layer_intensity | Sequential       | 132    | train\n",
      "-------------------------------------------------------------\n",
      "58.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "58.1 K    Total params\n",
      "0.232     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3707: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Multiple model comparison using RunnerConfigBuilder and RunnerManager\n",
    "models_to_compare = ['NHP', 'THP', 'RMTPP']\n",
    "results_comparison = {}\n",
    "\n",
    "for model_name in models_to_compare:\n",
    "    print(f\"\\nğŸ§  Training model {model_name}...\")\n",
    "    try:\n",
    "        # Use builder to load and build runner config for each model\n",
    "        rb = RunnerConfigBuilder()\n",
    "        rb.load_from_yaml(\n",
    "            yaml_file_path=str(CONFIGS),\n",
    "            training_config_path=\"training_configs.quick_test\",\n",
    "            model_config_path=f\"model_configs.{model_name}\",\n",
    "            data_config_path=\"data_configs.test\",\n",
    "        )\n",
    "        config_dict = rb.get_config_dict()\n",
    "        config = config_factory.create_config(ConfigType.RUNNER, config_dict, model_id=model_name)\n",
    "\n",
    "        runner = RunnerManager(config=config, output_dir=f\"./comparison_results/{model_name}\")\n",
    "\n",
    "        # Quick training (fewer epochs for demo)\n",
    "        runner.run(phase=\"train\")\n",
    "        test_results = runner.run(phase=\"test\")\n",
    "\n",
    "        results_comparison[model_name] = \"âœ… Success\"\n",
    "        print(f\"   âœ… {model_name} trained successfully\")\n",
    "\n",
    "    except Exception as e:\n",
    "        results_comparison[model_name] = f\"âŒ Error: {str(e)[:50]}...\"\n",
    "        print(f\"   âŒ Error with {model_name}: {str(e)[:50]}...\")\n",
    "\n",
    "print(\"\\nğŸ“Š Comparison summary:\")\n",
    "for model, result in results_comparison.items():\n",
    "    print(f\"   {model}: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249be884",
   "metadata": {},
   "source": [
    "## 6. Prediction Phase and Distribution Analysis\n",
    "\n",
    "**Why the prediction phase is crucial:**\n",
    "\n",
    "Temporal Point Process (TPP) models don't just serve to calculate performance metrics - their true value lies in their ability to **predict and simulate** new events. These predictions enable:\n",
    "\n",
    "1. **Distribution comparisons** - Analyze whether the model captures temporal patterns well\n",
    "2. **Realistic benchmarks** - Compare model simulations to real data  \n",
    "3. **Qualitative validation** - Visualize differences between predictions and reality\n",
    "4. **Practical applications** - Generate future scenarios for decision-making\n",
    "\n",
    "### 6.1 Complete Pipeline with Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b125ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Complete pipeline with predictions...\n",
      "\u001b[31;1m2025-09-18 13:07:41,698 - runner.py[pid:16224;line:39:__init__] - CRITICAL: Runner initialized for model: NHP on dataset: test\u001b[0m\n",
      "ğŸ”® Generating predictions and distribution comparisons...\n",
      "\u001b[38;20m2025-09-18 13:07:41,699 - runner.py[pid:16224;line:129:run] - INFO: Runner executing phases: ['predict']\u001b[0m\n",
      "\u001b[31;1m2025-09-18 13:07:41,699 - runner.py[pid:16224;line:98:predict] - CRITICAL: === PREDICTION PHASE ===\u001b[0m\n",
      "\u001b[38;20m2025-09-18 13:07:41,703 - model_runner.py[pid:16224;line:116:__init__] - INFO: No valid checkpoint found. Starting from scratch.\u001b[0m\n",
      "\u001b[38;20m2025-09-18 13:07:41,704 - model_runner.py[pid:16224;line:275:predict] - INFO: --- Starting Prediction for Model : NHP on dataset : test ---\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2025-09-18 13:07:41,734 - data_loader.py[pid:16224;line:140:setup] - INFO: Setting up data for stage: predict\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  0.21it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Formatting sequences: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 2975.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to .\\distributions_comparisons\\simulations.json\n",
      "\u001b[38;20m2025-09-18 13:07:59,801 - comparator.py[pid:16224;line:141:create_comparator] - INFO: Using TPPDatasetExtractor for optimized data extraction\u001b[0m\n",
      "\u001b[38;20m2025-09-18 13:07:59,803 - comparator.py[pid:16224;line:68:run_comprehensive_evaluation] - INFO: Starting comprehensive temporal point process evaluation...\u001b[0m\n",
      "\u001b[38;20m2025-09-18 13:07:59,804 - data_extractors.py[pid:16224;line:69:_extract_all_data] - INFO: Extracting ground truth data from TPPDataset with 2 sequences...\u001b[0m\n",
      "\u001b[38;20m2025-09-18 13:07:59,810 - data_extractors.py[pid:16224;line:118:_extract_all_data] - INFO: Successfully processed 2/2 sequences, extracted 56 events\u001b[0m\n",
      "\u001b[38;20m2025-09-18 13:07:59,812 - data_extractors.py[pid:16224;line:277:_extract_all_data] - INFO: Processing simulation data...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2025-09-18 13:08:00,663 - distribution_analyzer.py[pid:16224;line:119:plot_density_comparison] - INFO: Density comparison plot successfully saved to .\\distributions_comparisons\\comparison_inter_event_time_dist.png\u001b[0m\n",
      "\u001b[38;20m2025-09-18 13:08:01,206 - plot_generators.py[pid:16224;line:165:generate_plot] - INFO: Event type distribution comparison plot saved to .\\distributions_comparisons\\comparison_event_type_dist.png\u001b[0m\n",
      "\u001b[38;20m2025-09-18 13:08:01,750 - plot_generators.py[pid:16224;line:257:generate_plot] - INFO: Sequence length distribution comparison plot saved to .\\distributions_comparisons\\comparison_sequence_length_dist.png\u001b[0m\n",
      "\u001b[38;20m2025-09-18 13:08:02,474 - plot_generators.py[pid:16224;line:342:generate_plot] - INFO: Cross-correlation comparison plot saved to .\\distributions_comparisons\\comparison_cross_correlation_moments.png\u001b[0m\n",
      "\u001b[38;20m2025-09-18 13:08:02,475 - comparator.py[pid:16224;line:96:run_comprehensive_evaluation] - INFO: Comprehensive evaluation completed successfully\u001b[0m\n",
      "\u001b[38;20m2025-09-18 13:08:02,476 - model_runner.py[pid:16224;line:303:predict] - INFO: Running comprehensive evaluation of temporal point process distributions...\u001b[0m\n",
      "\u001b[38;20m2025-09-18 13:08:02,476 - comparator.py[pid:16224;line:68:run_comprehensive_evaluation] - INFO: Starting comprehensive temporal point process evaluation...\u001b[0m\n",
      "Predicting DataLoader 0:   0%|          | 0/1 [03:04<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[38;20m2025-09-18 13:08:08,150 - distribution_analyzer.py[pid:16224;line:119:plot_density_comparison] - INFO: Density comparison plot successfully saved to .\\distributions_comparisons\\comparison_inter_event_time_dist.png\u001b[0m\n",
      "\u001b[38;20m2025-09-18 13:08:08,402 - plot_generators.py[pid:16224;line:165:generate_plot] - INFO: Event type distribution comparison plot saved to .\\distributions_comparisons\\comparison_event_type_dist.png\u001b[0m\n",
      "\u001b[38;20m2025-09-18 13:08:08,671 - plot_generators.py[pid:16224;line:257:generate_plot] - INFO: Sequence length distribution comparison plot saved to .\\distributions_comparisons\\comparison_sequence_length_dist.png\u001b[0m\n",
      "\u001b[38;20m2025-09-18 13:08:09,348 - plot_generators.py[pid:16224;line:342:generate_plot] - INFO: Cross-correlation comparison plot saved to .\\distributions_comparisons\\comparison_cross_correlation_moments.png\u001b[0m\n",
      "\u001b[38;20m2025-09-18 13:08:09,349 - comparator.py[pid:16224;line:96:run_comprehensive_evaluation] - INFO: Comprehensive evaluation completed successfully\u001b[0m\n",
      "\u001b[38;20m2025-09-18 13:08:09,350 - model_runner.py[pid:16224;line:307:predict] - INFO: Simulations saved to .\\distributions_comparisons\u001b[0m\n",
      "\u001b[38;20m2025-09-18 13:08:09,351 - model_runner.py[pid:16224;line:309:predict] - INFO: Generating intensity graph...\u001b[0m\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Inference tensors cannot be saved for backward. To work around you can make a clone to get a normal tensor and use it in autograd.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m runner = Runner(config=config, output_dir=\u001b[33m\"\u001b[39m\u001b[33m./prediction_analysis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mğŸ”® Generating predictions and distribution comparisons...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphase\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpredict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… Complete pipeline finished!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mğŸ“Š Results available in:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\easy_tpp\\runners\\runner.py:142\u001b[39m, in \u001b[36mRunner.run\u001b[39m\u001b[34m(self, phase)\u001b[39m\n\u001b[32m    139\u001b[39m     results[current_phase] = \u001b[33m\"\u001b[39m\u001b[33mcompleted\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m current_phase == \u001b[33m\"\u001b[39m\u001b[33mpredict\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m     results[current_phase] = \u001b[33m\"\u001b[39m\u001b[33mcompleted\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\easy_tpp\\runners\\runner.py:100\u001b[39m, in \u001b[36mRunner.predict\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     98\u001b[39m logger.critical(\u001b[33m\"\u001b[39m\u001b[33m=== PREDICTION PHASE ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     99\u001b[39m trainer = \u001b[38;5;28mself\u001b[39m._create_trainer(enable_logging=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# This method doesn't return predictions but saves them\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\easy_tpp\\runners\\model_runner.py:310\u001b[39m, in \u001b[36mTrainer.predict\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    307\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSimulations saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_save_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    309\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mGenerating intensity graph...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mintensity_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_save_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\easy_tpp\\models\\basemodel.py:1218\u001b[39m, in \u001b[36mBaseModel.intensity_graph\u001b[39m\u001b[34m(self, start_time, end_time, precision, plot, save_plot, save_data, save_dir, **kwargs)\u001b[39m\n\u001b[32m   1214\u001b[39m time_deltas_sample = time_deltas.unsqueeze(-\u001b[32m1\u001b[39m) * ratios\n\u001b[32m   1216\u001b[39m \u001b[38;5;66;03m# Calculate intensities on augmented intervals\u001b[39;00m\n\u001b[32m   1217\u001b[39m \u001b[38;5;66;03m# [1, seq_len, precision, num_event_types]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1218\u001b[39m intensities = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_intensities_at_sample_times\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1219\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtime_seq\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# [1, seq_len-1]\u001b[39;49;00m\n\u001b[32m   1220\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtime_delta_seq\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# [1, seq_len-1]\u001b[39;49;00m\n\u001b[32m   1221\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtype_seq\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# [1, seq_len-1]\u001b[39;49;00m\n\u001b[32m   1222\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtime_deltas_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1225\u001b[39m time_diffs = time_seq.diff()\n\u001b[32m   1227\u001b[39m \u001b[38;5;66;03m# Calculate actual time points: [1, seq_len-1, precision]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\easy_tpp\\models\\nhp.py:257\u001b[39m, in \u001b[36mNHP.compute_intensities_at_sample_times\u001b[39m\u001b[34m(self, time_seqs, time_delta_seqs, type_seqs, sample_dtimes, **kwargs)\u001b[39m\n\u001b[32m    254\u001b[39m _input = time_seqs, time_delta_seqs, type_seqs, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    256\u001b[39m \u001b[38;5;66;03m# We will need the right limit at the last given event to decay from and get the left limits for sampling\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m _, right_hiddens = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    259\u001b[39m c_i, c_bar_i, delta_i, o_i = torch.chunk(right_hiddens, \u001b[32m4\u001b[39m, dim=-\u001b[32m1\u001b[39m)\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compute_last_step_only:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\easy_tpp\\models\\nhp.py:140\u001b[39m, in \u001b[36mNHP.forward\u001b[39m\u001b[34m(self, batch)\u001b[39m\n\u001b[32m    137\u001b[39m left_hs = []\n\u001b[32m    138\u001b[39m right_states = []\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m all_event_emb_BNP = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayer_type_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarks_BN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    141\u001b[39m c_t, c_bar_t, delta_t, o_t = \u001b[38;5;28mself\u001b[39m.get_init_state(\n\u001b[32m    142\u001b[39m     B\n\u001b[32m    143\u001b[39m )  \u001b[38;5;66;03m# initialize the right limits\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N):\n\u001b[32m    145\u001b[39m     \u001b[38;5;66;03m# Take last right limit and evolve into left limit; we will discard this value for t0 because dt=0\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:192\u001b[39m, in \u001b[36mEmbedding.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:2546\u001b[39m, in \u001b[36membedding\u001b[39m\u001b[34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[39m\n\u001b[32m   2540\u001b[39m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[32m   2541\u001b[39m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[32m   2542\u001b[39m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[32m   2543\u001b[39m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[32m   2544\u001b[39m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[32m   2545\u001b[39m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[32m-> \u001b[39m\u001b[32m2546\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Inference tensors cannot be saved for backward. To work around you can make a clone to get a normal tensor and use it in autograd."
     ]
    }
   ],
   "source": [
    "# Complete example: train â†’ test â†’ predict using RunnerConfigBuilder and RunnerManager\n",
    "print(\"ğŸ”„ Complete pipeline with predictions...\")\n",
    "\n",
    "# Build runner config\n",
    "rb = RunnerConfigBuilder()\n",
    "rb.load_from_yaml(\n",
    "    yaml_file_path=str(CONFIGS),\n",
    "    training_config_path=\"training_configs.quick_test\",\n",
    "    model_config_path=\"model_configs.NHP\",\n",
    "    data_config_path=\"data_configs.test\",\n",
    ")\n",
    "config_dict = rb.get_config_dict()\n",
    "config = config_factory.create_config(ConfigType.RUNNER, config_dict, model_id=\"NHP\")\n",
    "\n",
    "# Runner manager\n",
    "runner = RunnerManager(config=config, output_dir=\"./prediction_analysis\")\n",
    "\n",
    "print(\"ğŸ”® Generating predictions and distribution comparisons...\")\n",
    "runner.run(phase=\"predict\")\n",
    "\n",
    "print(\"âœ… Complete pipeline finished!\")\n",
    "print(\"ğŸ“Š Results available in:\")\n",
    "print(\"   - Performance metrics\")\n",
    "print(\"   - Model simulations\") \n",
    "print(\"   - Distribution comparisons\")\n",
    "print(\"   - Analysis graphs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aa3b9d",
   "metadata": {},
   "source": [
    "### 6.2 Simplified Alternative: Single Command\n",
    "\n",
    "If you want the complete pipeline all at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca0febb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ultra-simple version: everything in one command\n",
    "# Use RunnerManager (runner variable) already created above\n",
    "runner.run(phase=\"all\")\n",
    "\n",
    "print(\"ğŸ‰ Complete pipeline executed with phase='all'!\")\n",
    "print(\"ğŸ’¡ This command is equivalent to the 3 separate phases above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004da06e",
   "metadata": {},
   "source": [
    "**ğŸ¯ Main objective:** Verify that the model has learned the correct temporal distributions.\n",
    "\n",
    "**ğŸ“Š What the `predict` phase generates:**\n",
    "- **Event simulations** based on the trained model\n",
    "- **Visual comparisons** between real and simulated data\n",
    "- **Statistical analyses** of temporal distributions\n",
    "- **Prediction quality metrics**\n",
    "\n",
    "**âš ï¸ Crucial point:** Without the prediction phase, you only have numerical metrics. With predictions, you can **see** if your model truly understands the temporal dynamics of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27e5ddb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not found: analysis_plots\n",
      "Not found: training_results\n",
      "Not found: benchmark_results\n",
      "Not found: synthetic_data\n",
      "Not found: comparison_results\n",
      "Not found: prediction_analysis\n",
      "Not found: complete_pipeline\n",
      "Deleted: lightning_logs\n",
      "Deleted: checkpoints\n",
      "Deleted: distributions_comparisons\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "folders_to_remove = [\n",
    "    \"analysis_plots\",\n",
    "    \"training_results\",\n",
    "    \"benchmark_results\",\n",
    "    \"synthetic_data\",\n",
    "    \"comparison_results\",\n",
    "    \"prediction_analysis\",\n",
    "    \"complete_pipeline\",\n",
    "    \"lightning_logs\",\n",
    "    \"checkpoints\",\n",
    "    \"distributions_comparisons\"\n",
    "]\n",
    "\n",
    "for folder in folders_to_remove:\n",
    "    if os.path.exists(folder):\n",
    "        shutil.rmtree(folder)\n",
    "        print(f\"Deleted: {folder}\")\n",
    "    else:\n",
    "        print(f\"Not found: {folder}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easy-tpp (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
