{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "380fc504",
   "metadata": {},
   "source": [
    "# EasyTPP - Getting Started Guide\n",
    "\n",
    "This notebook presents the main features of the **EasyTPP** (Easy Temporal Point Processes) library with practical examples.\n",
    "\n",
    "## üéØ Notebook Objectives\n",
    "\n",
    "- Understand the basic concepts of temporal point processes\n",
    "- Learn to configure and train models\n",
    "- Explore the different types of data and available models\n",
    "- Visualize and analyze results\n",
    "\n",
    "## üìö Table of Contents\n",
    "\n",
    "1. [Environment Setup](#1-configuration)\n",
    "2. [Basic Concepts](#2-concepts)\n",
    "3. [Data Loading and Preparation](#3-donnees)\n",
    "4. [Model Configuration and Training](#4-entrainement)\n",
    "5. [Evaluation and Metrics](#5-evaluation)\n",
    "6. [Advanced Examples](#6-avances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09a9e71",
   "metadata": {},
   "source": [
    "## 1. Environment Setup {#1-configuration}\n",
    "\n",
    "Let's start by importing the necessary modules and setting up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d560867c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ EasyTPP imported successfully!\n",
      "üìÅ Project directory: c:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the project root directory to PYTHONPATH\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# EasyTPP imports\n",
    "from easy_tpp.config_factory import RunnerConfig\n",
    "from easy_tpp.utils.yaml_config_utils import parse_runner_yaml_config\n",
    "from easy_tpp.runner import Runner\n",
    "\n",
    "print(\"‚úÖ EasyTPP imported successfully!\")\n",
    "print(f\"üìÅ Project directory: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b812fe",
   "metadata": {},
   "source": [
    "## 2. Basic Concepts {#2-concepts}\n",
    "\n",
    "### What is a Temporal Point Process?\n",
    "\n",
    "A **Temporal Point Process** (TPP) is a sequence of events that occur over time. Each event is characterized by:\n",
    "\n",
    "- **Occurrence time**: When the event happens\n",
    "- **Event type**: What category of event (optional)\n",
    "\n",
    "### Application examples:\n",
    "\n",
    "- üè• **Medical**: Patient arrivals at a hospital\n",
    "- üí∞ **Finance**: Stock market transactions\n",
    "- üåç **Geophysics**: Earthquakes\n",
    "- üì± **Social Networks**: User posts\n",
    "\n",
    "### Models available in EasyTPP:\n",
    "\n",
    "- **NHP** (Neural Hawkes Process): Hawkes processes with neural networks\n",
    "- **THP** (Transformer Hawkes Process): Based on Transformer architecture\n",
    "- **RMTPP** (Recurrent Marked Temporal Point Process): Based on RNNs\n",
    "- **AttNHP** (Attentive Neural Hawkes Process): With attention mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55403dc1",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preparation {#3-donnees}\n",
    "\n",
    "EasyTPP supports multiple data formats. Let's see how to load and prepare data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f9f78f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Data configuration created:\n",
      "   Dataset: test\n",
      "   Format: pickle\n",
      "   Event types: 2\n",
      "   Batch size: 32\n",
      "   Number of workers: 1\n",
      "   Padding side: left\n"
     ]
    }
   ],
   "source": [
    "from easy_tpp.config_factory import DataConfig\n",
    "from easy_tpp.config_factory.data_config import DataLoadingSpecsConfig, TokenizerConfig\n",
    "from easy_tpp.data.preprocess import TPPDataModule\n",
    "\n",
    "# Data configuration with proper nested structure\n",
    "data_config = DataConfig(\n",
    "    source_dir=\"NzoCs/test_dataset\",            # Source directory for data\n",
    "    dataset_id=\"test\",                          # Dataset to use\n",
    "    data_format=\"pickle\",                       # Data format (pickle, json, csv)\n",
    "    data_loading_specs=DataLoadingSpecsConfig(\n",
    "        batch_size=32,                          # Batch size\n",
    "        num_workers=1,                          # Number of workers for data loading\n",
    "        shuffle=True                            # Shuffle data\n",
    "    ),\n",
    "    data_specs=TokenizerConfig(\n",
    "        num_event_types=2,                      # Number of event types\n",
    "        padding_side='left',                    # Padding side\n",
    "        truncation_side='left'                  # Truncation side\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"üìä Data configuration created:\")\n",
    "print(f\"   Dataset: {data_config.dataset_id}\")\n",
    "print(f\"   Format: {data_config.data_format}\")\n",
    "print(f\"   Event types: {data_config.data_specs.num_event_types}\")\n",
    "print(f\"   Batch size: {data_config.data_loading_specs.batch_size}\")\n",
    "print(f\"   Number of workers: {data_config.data_loading_specs.num_workers}\")\n",
    "print(f\"   Padding side: {data_config.data_specs.padding_side}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7900d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Alternative DataConfig created from dictionary:\n",
      "   Dataset: test\n",
      "   Format: pickle\n",
      "   Event types: 2\n",
      "   Batch size: 32\n",
      "\n",
      "‚úÖ Both configs are equivalent: True\n"
     ]
    }
   ],
   "source": [
    "# Alternative: Create DataConfig using from_dict (simpler approach)\n",
    "data_config_dict = {\n",
    "    \"source_dir\": \"NzoCs/test_dataset\",\n",
    "    \"dataset_id\": \"test\",\n",
    "    \"data_format\": \"pickle\",\n",
    "    \"data_loading_specs\": {\n",
    "        \"batch_size\": 32,\n",
    "        \"num_workers\": 1,\n",
    "        \"shuffle\": True\n",
    "    },\n",
    "    \"data_specs\": {\n",
    "        \"num_event_types\": 2,\n",
    "        \"padding_side\": \"left\",\n",
    "        \"truncation_side\": \"left\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create DataConfig from dictionary\n",
    "data_config_alt = DataConfig.from_dict(data_config_dict)\n",
    "\n",
    "print(\"üìä Alternative DataConfig created from dictionary:\")\n",
    "print(f\"   Dataset: {data_config_alt.dataset_id}\")\n",
    "print(f\"   Format: {data_config_alt.data_format}\")\n",
    "print(f\"   Event types: {data_config_alt.data_specs.num_event_types}\")\n",
    "print(f\"   Batch size: {data_config_alt.data_loading_specs.batch_size}\")\n",
    "\n",
    "# Both approaches create equivalent configurations\n",
    "print(f\"\\n‚úÖ Both configs are equivalent: {data_config.dataset_id == data_config_alt.dataset_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "839c8bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\.venv-py312-new\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'endswith'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create data module\u001b[39;00m\n\u001b[32m      2\u001b[39m datamodule = TPPDataModule(data_config)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mdatamodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Get data loaders\u001b[39;00m\n\u001b[32m      6\u001b[39m train_loader = datamodule.train_dataloader()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\easy_tpp\\data\\preprocess\\data_loader.py:138\u001b[39m, in \u001b[36mTPPDataModule.setup\u001b[39m\u001b[34m(self, stage)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stage == \u001b[33m'\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mpredict\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33msimul\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    137\u001b[39m     test_data_dir = \u001b[38;5;28mself\u001b[39m.data_config.get_data_dir(\u001b[33m'\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     \u001b[38;5;28mself\u001b[39m.test_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuild_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtest\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m     \u001b[38;5;28mself\u001b[39m.test_dataset = TPPDataset(\u001b[38;5;28mself\u001b[39m.test_data)\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stage \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m :\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\easy_tpp\\data\\preprocess\\data_loader.py:55\u001b[39m, in \u001b[36mTPPDataModule.build_input\u001b[39m\u001b[34m(self, source_dir, data_format, split)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m :\n\u001b[32m     54\u001b[39m     data_format == \u001b[33m'\u001b[39m\u001b[33mjson\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_input_from_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     57\u001b[39m     logger.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError loading data from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\finance\\projet_recherche\\New_LTPP\\easy_tpp\\data\\preprocess\\data_loader.py:93\u001b[39m, in \u001b[36mTPPDataModule._build_input_from_json\u001b[39m\u001b[34m(self, source_dir, split)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[32m     92\u001b[39m split_mapped = \u001b[33m'\u001b[39m\u001b[33mvalidation\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m split == \u001b[33m'\u001b[39m\u001b[33mdev\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m split\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43msource_dir\u001b[49m\u001b[43m.\u001b[49m\u001b[43mendswith\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m.json\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     94\u001b[39m     data = load_dataset(\u001b[33m'\u001b[39m\u001b[33mjson\u001b[39m\u001b[33m'\u001b[39m, data_files={split_mapped: source_dir}, split=split_mapped)\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m source_dir.startswith(\u001b[33m'\u001b[39m\u001b[33measytpp\u001b[39m\u001b[33m'\u001b[39m):\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'endswith'"
     ]
    }
   ],
   "source": [
    "# Create data module\n",
    "datamodule = TPPDataModule(data_config)\n",
    "datamodule.setup()\n",
    "\n",
    "# Get data loaders\n",
    "train_loader = datamodule.train_dataloader()\n",
    "val_loader = datamodule.val_dataloader()\n",
    "test_loader = datamodule.test_dataloader()\n",
    "\n",
    "print(\"‚úÖ Data loaders created successfully!\")\n",
    "print(f\"   üìà Train loader: {len(train_loader)} batches\")\n",
    "print(f\"   üìä Validation loader: {len(val_loader)} batches\")\n",
    "print(f\"   üß™ Test loader: {len(test_loader)} batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add42398",
   "metadata": {},
   "source": [
    "### Data Inspection\n",
    "\n",
    "Let's use the Visualizer to analyze the data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5e9c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easy_tpp.data.preprocess.visualizer import Visualizer\n",
    "\n",
    "# Create the visualizer\n",
    "visualizer = Visualizer(\n",
    "    data_setup=datamodule,\n",
    "    split=\"train\",\n",
    "    save_dir=\"./analysis_plots\"\n",
    ")\n",
    "\n",
    "# Generate visualizations\n",
    "visualizer.show_all_distributions(save_graph=True, show_graph=False)\n",
    "visualizer.delta_times_distribution(save_graph=True)\n",
    "visualizer.event_type_distribution(save_graph=True)\n",
    "\n",
    "print(\"üìà Analysis plots generated!\")\n",
    "print(\"   Check the './analysis_plots' folder for saved graphs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a746ab2",
   "metadata": {},
   "source": [
    "## 4. Model Configuration and Training {#4-entrainement}\n",
    "\n",
    "Now, let's configure and train a Neural Hawkes Process (NHP) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd1aaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;20m2025-07-12 04:01:25,511 - logger_config.py[pid:18296;line:222:from_dict] - WARNING: Filtered out invalid LoggerConfig keys: {'type', 'name'}\u001b[0m\n",
      "‚öôÔ∏è Model configuration:\n",
      "   üß† Model: NHP\n",
      "   üìä Dataset: test\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RunnerConfig' object has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   üß† Model: NHP\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   üìä Dataset: test\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   üîß Device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'RunnerConfig' object has no attribute 'device'"
     ]
    }
   ],
   "source": [
    "# Load configuration from YAML file\n",
    "config_file = project_root / \"examples\" / \"runner_config.yaml\"\n",
    "runner_dict = parse_runner_yaml_config(str(config_file), \"NHP\", \"test\")\n",
    "\n",
    "# Create configuration\n",
    "config = RunnerConfig.from_dict(runner_dict)\n",
    "\n",
    "print(\"‚öôÔ∏è Model configuration:\")\n",
    "print(f\"   üß† Model: NHP\")\n",
    "print(f\"   üìä Dataset: test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84658b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create runner and start training\n",
    "runner = Runner(config=config, output_dir=\"./training_results\")\n",
    "\n",
    "print(\"üöÄ Starting training...\")\n",
    "print(\"   This may take a few minutes depending on your configuration.\")\n",
    "\n",
    "# Train the model\n",
    "runner.run(phase=\"train\")\n",
    "\n",
    "print(\"‚úÖ Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de87b8ef",
   "metadata": {},
   "source": [
    "## 5. Evaluation and Metrics {#5-evaluation}\n",
    "\n",
    "Let's now evaluate the performance of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcaf902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on test dataset\n",
    "print(\"üß™ Evaluating model on test dataset...\")\n",
    "\n",
    "test_results = runner.run(phase=\"test\")\n",
    "\n",
    "print(\"üìä Evaluation results:\")\n",
    "if hasattr(runner, 'test_metrics'):\n",
    "    for metric_name, value in runner.test_metrics.items():\n",
    "        print(f\"   {metric_name}: {value:.4f}\")\n",
    "else:\n",
    "    print(\"   ‚úÖ Evaluation completed - check logs for detailed metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98613a0c",
   "metadata": {},
   "source": [
    "### Comparison with Baselines\n",
    "\n",
    "Let's compare our model with simple baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843afc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easy_tpp.evaluation.benchmarks.mean_bench import MeanInterTimeBenchmark\n",
    "from easy_tpp.evaluation.benchmarks.sample_distrib_mark_bench import MarkDistributionBenchmark\n",
    "\n",
    "# Baseline benchmark: mean prediction\n",
    "mean_benchmark = MeanInterTimeBenchmark(\n",
    "    data_config=data_config,\n",
    "    experiment_id=\"mean_baseline\",\n",
    "    save_dir=\"./benchmark_results\"\n",
    ")\n",
    "\n",
    "print(\"üìä Baseline benchmark (mean):\")\n",
    "mean_results = mean_benchmark.evaluate()\n",
    "print(f\"   Results: {mean_results}\")\n",
    "\n",
    "# Type distribution benchmark\n",
    "mark_benchmark = MarkDistributionBenchmark(\n",
    "    data_config=data_config,\n",
    "    experiment_id=\"mark_baseline\",\n",
    "    save_dir=\"./benchmark_results\"\n",
    ")\n",
    "\n",
    "print(\"\\nüìä Type distribution benchmark:\")\n",
    "mark_results = mark_benchmark.evaluate()\n",
    "print(f\"   Results: {mark_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79af9f88",
   "metadata": {},
   "source": [
    "## 6. Advanced Examples {#6-avances}\n",
    "\n",
    "### Synthetic Data Generation\n",
    "\n",
    "EasyTPP allows generating synthetic data to test models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa8e887",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easy_tpp.data.generation import HawkesSimulator\n",
    "\n",
    "# Hawkes process configuration\n",
    "params = {\n",
    "    \"mu\": [0.1, 0.2],                    # Base intensities\n",
    "    \"alpha\": [[0.3, 0.1], [0.2, 0.4]],  # Excitation matrix\n",
    "    \"beta\": [[2, 1], [1.5, 3]]          # Decay matrix\n",
    "}\n",
    "\n",
    "# Create simulator\n",
    "simulator = HawkesSimulator(\n",
    "    mu=params[\"mu\"],\n",
    "    alpha=params[\"alpha\"],\n",
    "    beta=params[\"beta\"],\n",
    "    dim_process=2,\n",
    "    start_time=0,\n",
    "    end_time=100\n",
    ")\n",
    "\n",
    "print(\"üé≤ Generating synthetic data...\")\n",
    "\n",
    "# Generate and save\n",
    "simulator.generate_and_save(\n",
    "    output_dir='./synthetic_data',\n",
    "    num_simulations=10,\n",
    "    splits={'train': 0.6, 'test': 0.2, 'dev': 0.2}\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Synthetic data generated in './synthetic_data'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c842bf",
   "metadata": {},
   "source": [
    "### Multiple Model Comparison\n",
    "\n",
    "Let's compare the performance of different models on the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7f0b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of models to compare\n",
    "models_to_compare = ['NHP', 'THP', 'RMTPP']\n",
    "results_comparison = {}\n",
    "\n",
    "for model_name in models_to_compare:\n",
    "    print(f\"\\nüß† Training model {model_name}...\")\n",
    "    \n",
    "    try:\n",
    "        # Configuration for this model\n",
    "        config_file = project_root / \"examples\" / \"runner_config.yaml\"\n",
    "        model_config_dict = parse_runner_yaml_config(str(config_file), model_name, \"test\")\n",
    "        \n",
    "        config = RunnerConfig.from_dict(model_config_dict)\n",
    "        runner = Runner(config=config, output_dir=f\"./comparison_results/{model_name}\")\n",
    "        \n",
    "        # Quick training (fewer epochs for demo)\n",
    "        runner.run(phase=\"train\")\n",
    "        test_results = runner.run(phase=\"test\")\n",
    "        \n",
    "        results_comparison[model_name] = \"‚úÖ Success\"\n",
    "        print(f\"   ‚úÖ {model_name} trained successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        results_comparison[model_name] = f\"‚ùå Error: {str(e)[:50]}...\"\n",
    "        print(f\"   ‚ùå Error with {model_name}: {str(e)[:50]}...\")\n",
    "\n",
    "print(\"\\nüìä Comparison summary:\")\n",
    "for model, result in results_comparison.items():\n",
    "    print(f\"   {model}: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea5c53f",
   "metadata": {},
   "source": [
    "## üéâ Conclusion\n",
    "\n",
    "This notebook has covered the main features of EasyTPP:\n",
    "\n",
    "‚úÖ **Environment setup** and imports\n",
    "\n",
    "‚úÖ **Understanding basic concepts** of TPPs\n",
    "\n",
    "‚úÖ **Data loading and preparation**\n",
    "\n",
    "‚úÖ **Model configuration and training**\n",
    "\n",
    "‚úÖ **Evaluation and comparison** with baselines\n",
    "\n",
    "‚úÖ **Synthetic data generation**\n",
    "\n",
    "‚úÖ **Multiple model comparison**\n",
    "\n",
    "### üöÄ Next Steps\n",
    "\n",
    "- Explore other available models (AttNHP, Transformer-based)\n",
    "- Test with your own data\n",
    "- Adjust hyperparameters to optimize performance\n",
    "- Use advanced analysis tools to understand model behavior\n",
    "\n",
    "### üìö Useful Resources\n",
    "\n",
    "- [EasyTPP Documentation](https://github.com/your-repo/EasyTPP)\n",
    "- [Additional Examples](../examples/)\n",
    "- [Advanced Configuration](../configs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249be884",
   "metadata": {},
   "source": [
    "## 6. Prediction Phase and Distribution Analysis\n",
    "\n",
    "**Why the prediction phase is crucial:**\n",
    "\n",
    "Temporal Point Process (TPP) models don't just serve to calculate performance metrics - their true value lies in their ability to **predict and simulate** new events. These predictions enable:\n",
    "\n",
    "1. **Distribution comparisons** - Analyze whether the model captures temporal patterns well\n",
    "2. **Realistic benchmarks** - Compare model simulations to real data  \n",
    "3. **Qualitative validation** - Visualize differences between predictions and reality\n",
    "4. **Practical applications** - Generate future scenarios for decision-making\n",
    "\n",
    "### 6.1 Complete Pipeline with Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b125ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete example: train ‚Üí test ‚Üí predict\n",
    "print(\"üîÑ Complete pipeline with predictions...\")\n",
    "\n",
    "# Configuration\n",
    "config_dict = parse_runner_yaml_config(\n",
    "    yaml_path=\"../examples/runner_config.yaml\",\n",
    "    experiment_id=\"NHP\", \n",
    "    dataset_id=\"test\"\n",
    ")\n",
    "config = RunnerConfig.from_dict(config_dict)\n",
    "\n",
    "# Runner\n",
    "runner = Runner(config=config, output_dir=\"./prediction_analysis\")\n",
    "\n",
    "# Phase 1: Training\n",
    "print(\"üìö 1. Training the model...\")\n",
    "runner.run(phase=\"train\")\n",
    "\n",
    "# Phase 2: Test/Evaluation  \n",
    "print(\"üß™ 2. Performance evaluation...\")\n",
    "runner.run(phase=\"test\")\n",
    "\n",
    "# Phase 3: Predictions and comparisons (CRUCIAL!)\n",
    "print(\"üîÆ 3. Generating predictions and distribution comparisons...\")\n",
    "runner.run(phase=\"predict\")\n",
    "\n",
    "print(\"‚úÖ Complete pipeline finished!\")\n",
    "print(\"üìä Results available in:\")\n",
    "print(\"   - Performance metrics\")\n",
    "print(\"   - Model simulations\") \n",
    "print(\"   - Distribution comparisons\")\n",
    "print(\"   - Analysis graphs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aa3b9d",
   "metadata": {},
   "source": [
    "### 6.2 Simplified Alternative: Single Command\n",
    "\n",
    "If you want the complete pipeline all at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca0febb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ultra-simple version: everything in one command\n",
    "runner = Runner(config=config, output_dir=\"./complete_pipeline\")\n",
    "\n",
    "# Automatically executes: train ‚Üí test ‚Üí predict\n",
    "runner.run(phase=\"all\")\n",
    "\n",
    "print(\"üéâ Complete pipeline executed with phase='all'!\")\n",
    "print(\"üí° This command is equivalent to the 3 separate phases above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004da06e",
   "metadata": {},
   "source": [
    "### 6.3 Why Predictions Are Essential\n",
    "\n",
    "**üéØ Main objective:** Verify that the model has learned the correct temporal distributions.\n",
    "\n",
    "**üìä What the `predict` phase generates:**\n",
    "- **Event simulations** based on the trained model\n",
    "- **Visual comparisons** between real and simulated data\n",
    "- **Statistical analyses** of temporal distributions\n",
    "- **Prediction quality metrics**\n",
    "\n",
    "**üîç Practical applications:**\n",
    "- **Finance:** Predict trading volume peaks\n",
    "- **Healthcare:** Anticipate epidemics or relapses\n",
    "- **Networks:** Forecast traffic overloads\n",
    "- **Social:** Model information propagation\n",
    "\n",
    "**‚ö†Ô∏è Crucial point:** Without the prediction phase, you only have numerical metrics. With predictions, you can **see** if your model truly understands the temporal dynamics of your data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-py312-new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
