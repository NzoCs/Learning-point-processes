{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "995eb5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3ea8e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "num_mark = 2\n",
    "seq_len = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6984e6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_event_time = torch.zeros(\n",
    "            (batch_size, num_mark), dtype=torch.float32\n",
    "        )\n",
    "last_event_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baf20f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0., 0.],\n",
       "        [0., 1., 1., 0., 1.],\n",
       "        [1., 0., 1., 0., 1.],\n",
       "        [0., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_seq = torch.randint(\n",
    "            0, 2, (batch_size, seq_len), dtype=torch.float32\n",
    "        )\n",
    "event_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e8a3861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4714, 3.1033, 3.2334, 5.0800, 5.5261],\n",
       "        [0.0943, 1.5425, 2.3193, 2.4992, 2.7180],\n",
       "        [0.7317, 0.8511, 1.4375, 1.8325, 3.5591],\n",
       "        [0.1244, 0.5622, 1.8200, 2.2945, 3.5384]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_seq = torch.randn(\n",
    "            (batch_size, seq_len), dtype=torch.float32\n",
    "        ).abs()\n",
    "time_seq = time_seq.cumsum(dim=1)\n",
    "time_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a003ddd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.5261, 3.1033],\n",
       "        [2.4992, 2.7180],\n",
       "        [1.8325, 3.5591],\n",
       "        [0.1244, 3.5384]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for mark in range(num_mark):\n",
    "            mark_mask = (event_seq == mark)  # [batch_size, seq_len]\n",
    "            if mark_mask.any():\n",
    "                # Vectorized operation with efficient masking\n",
    "                masked_times = time_seq.masked_fill(~mark_mask, float(\"-inf\"))\n",
    "                max_times, _ = masked_times.max(dim=1)\n",
    "                valid_mask = (max_times != float(\"-inf\"))\n",
    "                last_event_time[valid_mask, mark] = max_times[valid_mask]\n",
    "last_event_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dcc01f",
   "metadata": {},
   "source": [
    "# Advanced indexing techniques\n",
    "\n",
    "This section shows practical examples of advanced indexing methods in PyTorch for efficient tensor manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9cae051d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_mask:  tensor([ True, False,  True,  True])\n",
      "type_pred: tensor([0, 0, 1]) shape:  torch.Size([3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([5.5261, 1.8325, 3.5384])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_mask = (last_event_time[:, 1]  > 3)\n",
    "print(\"valid_mask: \", valid_mask)\n",
    "type_pred = torch.randint(0, 2, (batch_size,))\n",
    "print(\"type_pred:\", type_pred, \"shape: \", type_pred.shape)\n",
    "last_event_time[valid_mask, type_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b4f258",
   "metadata": {},
   "source": [
    "## Examples of advanced indexing with PyTorch\n",
    "\n",
    "This notebook demonstrates several advanced indexing techniques to manipulate PyTorch tensors effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3684a2",
   "metadata": {},
   "source": [
    "### Quick utilities and printing examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6031dd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenseur original shape: torch.Size([3, 4, 5])\n",
      "Données:\n",
      " tensor([[[ 2.1499,  0.6631,  0.1087, -0.4316,  1.3128],\n",
      "         [ 0.6359,  1.3980,  0.8533,  0.3231, -0.8725],\n",
      "         [ 1.3129,  0.8505, -0.2898,  0.9754,  0.8462],\n",
      "         [-1.1346,  1.1589, -1.8925, -0.6487, -1.6561]],\n",
      "\n",
      "        [[ 0.9511, -1.1479,  0.5666, -1.6383, -1.5595],\n",
      "         [ 0.5956, -0.0333,  0.2996, -0.4183,  1.6169],\n",
      "         [ 0.3581, -1.0088, -1.7175,  0.5518,  1.6188],\n",
      "         [ 1.4274,  2.2002,  0.2962,  0.0888, -0.5887]],\n",
      "\n",
      "        [[ 0.6040, -0.0827, -0.2848, -0.1057, -0.6897],\n",
      "         [ 0.0200, -0.1890,  0.3926,  0.3901, -0.4661],\n",
      "         [ 0.6775, -0.2156,  0.9627,  0.0132,  0.1663],\n",
      "         [-1.5046,  1.9544,  1.2686, -1.6510, -1.8305]]])\n",
      "\n",
      "1. Premier élément (batch 0): torch.Size([4, 5])\n",
      "2. Dernière colonne: torch.Size([3, 4])\n",
      "3. Slice du milieu: torch.Size([3, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "# Create a 3D tensor for examples\n",
    "data = torch.randn(3, 4, 5)\n",
    "print(\"Original tensor shape:\", data.shape)\n",
    "print(\"Data:\\n\", data)\n",
    "\n",
    "# Basic indexing\n",
    "print(\"\\n1. First element (batch 0):\", data[0].shape)\n",
    "print(\"2. Last column:\", data[:, :, -1].shape)\n",
    "print(\"3. Middle slice:\", data[:, 1:3, :].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde7a779",
   "metadata": {},
   "source": [
    "### Demonstration: Tensor shapes and examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2913e564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source tensor:\n",
      " tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n",
      "Indices:\n",
      " tensor([[0, 2],\n",
      "        [1, 3],\n",
      "        [0, 3]])\n",
      "Résultat gather:\n",
      " tensor([[ 1,  3],\n",
      "        [ 6,  8],\n",
      "        [ 9, 12]])\n",
      "\n",
      "Exemple avec événements:\n",
      "Events:\n",
      " tensor([[0, 1, 0, 1, 0],\n",
      "        [1, 0, 0, 1, 1],\n",
      "        [1, 1, 1, 0, 1]])\n",
      "Times:\n",
      " tensor([[0.0917, 1.1058, 2.4856, 3.1408, 4.7153],\n",
      "        [0.3074, 0.8413, 2.3905, 2.6149, 3.0617],\n",
      "        [1.5503, 1.8348, 3.1659, 4.4744, 6.1252]])\n",
      "Derniers indices pour type 1:\n",
      " tensor([[3],\n",
      "        [4],\n",
      "        [4]])\n",
      "Derniers temps pour type 1:\n",
      " tensor([[3.1408],\n",
      "        [3.0617],\n",
      "        [6.1252]])\n"
     ]
    }
   ],
   "source": [
    "# torch.gather selects elements according to indices\n",
    "source = torch.tensor([[1, 2, 3, 4], \n",
    "                       [5, 6, 7, 8], \n",
    "                       [9, 10, 11, 12]])\n",
    "\n",
    "# Indices to select for each row\n",
    "indices = torch.tensor([[0, 2], [1, 3], [0, 3]])\n",
    "\n",
    "print(\"Source tensor:\\n\", source)\n",
    "print(\"Indices:\\n\", indices)\n",
    "\n",
    "# Gather along dim=1 (columns)\n",
    "gathered = torch.gather(source, dim=1, index=indices)\n",
    "print(\"Gather result:\\n\", gathered)\n",
    "\n",
    "# Example with event simulation: select the last event of each type\n",
    "batch_size, seq_len = 3, 5\n",
    "events = torch.randint(0, 2, (batch_size, seq_len))\n",
    "times = torch.randn(batch_size, seq_len).abs().cumsum(dim=1)\n",
    "\n",
    "print(\"\\nEvent example:\")\n",
    "print(\"Events:\\n\", events)\n",
    "print(\"Times:\\n\", times)\n",
    "\n",
    "# Find last index of event type 1 for each batch\n",
    "last_indices = []\n",
    "for b in range(batch_size):\n",
    "    mask = events[b] == 1\n",
    "    if mask.any():\n",
    "        last_idx = torch.where(mask)[0][-1]\n",
    "    else:\n",
    "        last_idx = torch.tensor(0)  # fallback\n",
    "    last_indices.append(last_idx)\n",
    "\n",
    "last_indices = torch.stack(last_indices).unsqueeze(1)\n",
    "print(\"Last indices for type 1:\\n\", last_indices)\n",
    "\n",
    "# Use gather to retrieve corresponding times\n",
    "last_times = torch.gather(times, dim=1, index=last_indices)\n",
    "print(\"Last times for type 1:\\n\", last_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81946dee",
   "metadata": {},
   "source": [
    "### Selecting the last event index for a given type\n",
    "\n",
    "This example finds the index of the last occurrence of a specific event type within each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfda8128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeurs:\n",
      " tensor([[ 1.4011,  1.5079, -1.0909,  0.4197,  0.3895,  0.5238],\n",
      "        [-2.1130,  0.4523, -0.9354, -1.7169, -0.6213, -0.8477],\n",
      "        [-0.8427,  0.7809,  0.7720, -1.2123,  1.2467,  0.7433],\n",
      "        [-0.5526,  2.0318, -0.9890, -2.5797,  0.3550, -0.7316]])\n",
      "\n",
      "Masque positif:\n",
      " tensor([[ True,  True, False,  True,  True,  True],\n",
      "        [False,  True, False, False, False, False],\n",
      "        [False,  True,  True, False,  True,  True],\n",
      "        [False,  True, False, False,  True, False]])\n",
      "Valeurs positives: tensor([1.4011, 1.5079, 0.4197, 0.3895, 0.5238, 0.4523, 0.7809, 0.7720, 1.2467,\n",
      "        0.7433]) ...\n",
      "\n",
      "Valeurs avec négatifs remplacés par 0:\n",
      " tensor([[1.4011, 1.5079, 0.0000, 0.4197, 0.3895, 0.5238],\n",
      "        [0.0000, 0.4523, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.7809, 0.7720, 0.0000, 1.2467, 0.7433],\n",
      "        [0.0000, 2.0318, 0.0000, 0.0000, 0.3550, 0.0000]])\n",
      "\n",
      "Valeurs entre 0 et 1: tensor([0.4197, 0.3895, 0.5238, 0.4523, 0.7809, 0.7720, 0.7433, 0.3550])\n",
      "\n",
      "Masque de padding (True = padding):\n",
      "tensor([[False, False, False,  True,  True],\n",
      "        [False, False, False, False, False],\n",
      "        [False, False,  True,  True,  True],\n",
      "        [False, False, False, False,  True]])\n",
      "Données avec padding masqué:\n",
      " tensor([[-0.4380, -0.8599, -0.0952,    -inf,    -inf],\n",
      "        [-1.2057, -1.5206,  0.1903, -0.0626, -0.8769],\n",
      "        [ 1.5990, -1.6312,    -inf,    -inf,    -inf],\n",
      "        [ 0.6191, -0.0372,  1.6390, -0.0213,    -inf]])\n"
     ]
    }
   ],
   "source": [
    "# Boolean masks for filtering and conditional selection\n",
    "values = torch.randn(4, 6)\n",
    "print(\"Values:\\n\", values)\n",
    "\n",
    "# Mask for positive values\n",
    "positive_mask = values > 0\n",
    "print(\"\\nPositive mask:\\n\", positive_mask)\n",
    "\n",
    "# Select only positive values (returns a 1D tensor)\n",
    "positive_values = values[positive_mask]\n",
    "print(\"Positive values:\", positive_values[:10], \"...\")  # Partial display\n",
    "\n",
    "# Use masked_fill to replace values\n",
    "values_filled = values.masked_fill(values < 0, 0.0)\n",
    "print(\"\\nValues with negatives replaced by 0:\\n\", values_filled)\n",
    "\n",
    "# masked_select for more complex filtering\n",
    "mask_complex = (values > 0) & (values < 1)\n",
    "selected = values.masked_select(mask_complex)\n",
    "print(\"\\nValues between 0 and 1:\", selected)\n",
    "\n",
    "# Practical example: mask paddings in a sequence\n",
    "seq_len = torch.tensor([3, 5, 2, 4])  # Actual lengths for each sequence\n",
    "max_len = 5\n",
    "batch_size = seq_len.size(0)\n",
    "\n",
    "# Create a padding mask\n",
    "padding_mask = torch.arange(max_len).unsqueeze(0) >= seq_len.unsqueeze(1)\n",
    "print(f\"\\nPadding mask (True = padding):\\n{padding_mask}\")\n",
    "\n",
    "# Apply mask to data\n",
    "sequence_data = torch.randn(batch_size, max_len)\n",
    "masked_data = sequence_data.masked_fill(padding_mask, float('-inf'))\n",
    "print(\"Data with padding masked:\\n\", masked_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d0592c",
   "metadata": {},
   "source": [
    "## 4. Indexation avec torch.index_select et torch.take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44820990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice originale:\n",
      " tensor([[ 1.4924, -1.5938, -0.9453,  1.2735,  0.4558,  0.8859],\n",
      "        [-0.3927,  0.4843,  0.2566, -0.1102, -1.2561,  0.9141],\n",
      "        [ 0.6275,  0.5636,  1.0326, -0.5624,  0.0315,  1.9188],\n",
      "        [-0.3732, -0.0578,  0.3002,  2.2216, -0.0849, -0.6441]])\n",
      "\n",
      "Lignes sélectionnées [0, 2, 3]:\n",
      " tensor([[ 1.4924, -1.5938, -0.9453,  1.2735,  0.4558,  0.8859],\n",
      "        [ 0.6275,  0.5636,  1.0326, -0.5624,  0.0315,  1.9188],\n",
      "        [-0.3732, -0.0578,  0.3002,  2.2216, -0.0849, -0.6441]])\n",
      "\n",
      "Colonnes sélectionnées [1, 3, 5]:\n",
      " tensor([[-1.5938,  1.2735,  0.8859],\n",
      "        [ 0.4843, -0.1102,  0.9141],\n",
      "        [ 0.5636, -0.5624,  1.9188],\n",
      "        [-0.0578,  2.2216, -0.6441]])\n",
      "\n",
      "Tenseur plat:\n",
      " tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "Éléments pris aux positions [0, 5, 7, 11]: tensor([ 0,  5,  7, 11])\n",
      "\n",
      "Embeddings sélectionnés shape: torch.Size([2, 4, 128])\n",
      "Premier embedding du premier batch: tensor([ 1.5345, -0.7401,  0.4479,  0.8496,  0.0639])\n"
     ]
    }
   ],
   "source": [
    "# torch.index_select: select slices along a dimension\n",
    "matrix = torch.randn(4, 6)\n",
    "print(\"Original matrix:\\n\", matrix)\n",
    "\n",
    "# Select specific rows\n",
    "row_indices = torch.tensor([0, 2, 3])\n",
    "selected_rows = torch.index_select(matrix, dim=0, index=row_indices)\n",
    "print(\"\\nSelected rows [0, 2, 3]:\\n\", selected_rows)\n",
    "\n",
    "# Select specific columns\n",
    "col_indices = torch.tensor([1, 3, 5])\n",
    "selected_cols = torch.index_select(matrix, dim=1, index=col_indices)\n",
    "print(\"\\nSelected columns [1, 3, 5]:\\n\", selected_cols)\n",
    "\n",
    "# torch.take treats the tensor as a flat array\n",
    "flat_tensor = torch.arange(12).reshape(3, 4)\n",
    "print(\"\\nFlat tensor:\\n\", flat_tensor)\n",
    "\n",
    "# Absolute position indices\n",
    "indices = torch.tensor([0, 5, 7, 11])\n",
    "taken = torch.take(flat_tensor, indices)\n",
    "print(\"Elements at positions [0, 5, 7, 11]:\", taken)\n",
    "\n",
    "# Practical example: select embeddings\n",
    "vocab_size, embedding_dim = 1000, 128\n",
    "embeddings = torch.randn(vocab_size, embedding_dim)\n",
    "\n",
    "# Word index sequences\n",
    "word_indices = torch.tensor([[1, 5, 23, 7], [45, 2, 8, 12]])\n",
    "batch_size, seq_length = word_indices.shape\n",
    "\n",
    "# Select corresponding embeddings\n",
    "selected_embeddings = torch.index_select(embeddings, dim=0, \n",
    "                                        index=word_indices.flatten())\n",
    "selected_embeddings = selected_embeddings.view(batch_size, seq_length, embedding_dim)\n",
    "\n",
    "print(f\"\\nSelected embeddings shape: {selected_embeddings.shape}\")\n",
    "print(\"First embedding of the first batch:\", selected_embeddings[0, 0, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ed3330",
   "metadata": {},
   "source": [
    "### Boolean masks for filtering and conditional selection\n",
    "\n",
    "Use boolean masks to filter values or select subsets without explicit Python loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1207acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenseur 3D shape: torch.Size([2, 3, 4])\n",
      "Données:\n",
      " tensor([[[ 1.2225,  0.0716,  0.3245, -0.3487],\n",
      "         [-1.2330,  0.8190,  0.9548,  1.0756],\n",
      "         [ 0.3341,  0.4133, -0.0394,  0.3766]],\n",
      "\n",
      "        [[ 0.6936, -0.5983, -0.5106,  0.8924],\n",
      "         [ 0.6499,  0.7171, -0.9614,  0.5521],\n",
      "         [-0.2948,  0.6610, -0.2536, -0.1455]]])\n",
      "\n",
      "Éléments sélectionnés: tensor([-1.2330,  0.6610,  0.3245,  0.5521])\n",
      "Range batch: tensor([0, 1])\n",
      "\n",
      "Max values shape: torch.Size([2, 3])\n",
      "Max values:\n",
      " tensor([[1.2225, 1.0756, 0.4133],\n",
      "        [0.8924, 0.7171, 0.6610]])\n",
      "Max indices:\n",
      " tensor([[0, 3, 1],\n",
      "        [3, 1, 1]])\n",
      "\n",
      "Valeurs récupérées (vérification):\n",
      " tensor([[1.2225, 1.0756, 0.4133],\n",
      "        [0.8924, 0.7171, 0.6610]])\n",
      "Égalité: True\n"
     ]
    }
   ],
   "source": [
    "# Indexing with multiple dimensions at once\n",
    "batch_size, num_classes, seq_len = 2, 3, 4\n",
    "tensor_3d = torch.randn(batch_size, num_classes, seq_len)\n",
    "print(\"3D tensor shape:\", tensor_3d.shape)\n",
    "print(\"Data:\\n\", tensor_3d)\n",
    "\n",
    "# Fancy indexing with tensors\n",
    "batch_idx = torch.tensor([0, 1, 0, 1])  # batch indices\n",
    "class_idx = torch.tensor([1, 2, 0, 1])  # class indices\n",
    "seq_idx = torch.tensor([0, 1, 2, 3])    # sequence indices\n",
    "\n",
    "# Select specific elements\n",
    "selected_elements = tensor_3d[batch_idx, class_idx, seq_idx]\n",
    "print(\"\\nSelected elements:\", selected_elements)\n",
    "\n",
    "# Use arange for indexing\n",
    "batch_range = torch.arange(batch_size)\n",
    "print(f\"Batch range: {batch_range}\")\n",
    "\n",
    "# Get max per batch/class across sequence length\n",
    "max_values, max_indices = tensor_3d.max(dim=2)  # max over seq_len\n",
    "print(f\"\\nMax values shape: {max_values.shape}\")\n",
    "print(\"Max values:\\n\", max_values)\n",
    "print(\"Max indices:\\n\", max_indices)\n",
    "\n",
    "# Use indices to retrieve original values\n",
    "batch_expanded = batch_range.unsqueeze(1).expand(-1, num_classes)\n",
    "class_expanded = torch.arange(num_classes).unsqueeze(0).expand(batch_size, -1)\n",
    "\n",
    "recovered_values = tensor_3d[batch_expanded, class_expanded, max_indices]\n",
    "print(\"\\nRecovered values (verification):\\n\", recovered_values)\n",
    "print(\"Equality:\", torch.allclose(max_values, recovered_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd714a5a",
   "metadata": {},
   "source": [
    "### Practical example: masking padding in sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b2ae49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types d'événements:\n",
      " tensor([[1, 3, 1, 2, 2, 3, 3, 3],\n",
      "        [3, 1, 3, 1, 2, 0, 3, 0],\n",
      "        [2, 1, 3, 2, 1, 2, 0, 1]])\n",
      "Temps d'événements:\n",
      " tensor([[1.0120, 1.7871, 3.0567, 4.7263, 5.7100, 6.1736, 6.5166, 6.6035],\n",
      "        [0.2779, 0.9679, 4.2464, 4.7372, 4.9811, 7.8192, 8.9795, 9.7267],\n",
      "        [0.2971, 1.2268, 2.4551, 2.5715, 4.0258, 4.2429, 5.2187, 5.3796]])\n",
      "\n",
      "Événements valides (avec masque):\n",
      " tensor([[1, 3, 1, 2, 2, 0, 0, 0],\n",
      "        [3, 1, 3, 1, 2, 0, 3, 0],\n",
      "        [2, 1, 3, 2, 1, 2, 0, 0]])\n",
      "Temps valides:\n",
      " tensor([[1.0120, 1.7871, 3.0567, 4.7263, 5.7100, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2779, 0.9679, 4.2464, 4.7372, 4.9811, 7.8192, 8.9795, 0.0000],\n",
      "        [0.2971, 1.2268, 2.4551, 2.5715, 4.0258, 4.2429, 0.0000, 0.0000]])\n",
      "\n",
      "Derniers temps par type d'événement:\n",
      " tensor([[0.0000, 3.0567, 5.7100, 1.7871],\n",
      "        [7.8192, 4.7372, 4.9811, 8.9795],\n",
      "        [0.0000, 4.0258, 4.2429, 2.4551]])\n",
      "\n",
      "Version vectorisée:\n",
      " tensor([[0.0000, 3.0567, 5.7100, 1.7871],\n",
      "        [7.8192, 4.7372, 4.9811, 8.9795],\n",
      "        [0.0000, 4.0258, 4.2429, 2.4551]])\n",
      "Égalité avec version naive: True\n"
     ]
    }
   ],
   "source": [
    "# Practical applications for point processes\n",
    "batch_size, max_seq_len, num_event_types = 3, 8, 4\n",
    "\n",
    "# Simulate events with variable lengths\n",
    "seq_lengths = torch.tensor([5, 7, 6])\n",
    "event_types = torch.randint(0, num_event_types, (batch_size, max_seq_len))\n",
    "event_times = torch.randn(batch_size, max_seq_len).abs().cumsum(dim=1)\n",
    "\n",
    "print(\"Event types:\\n\", event_types)\n",
    "print(\"Event times:\\n\", event_times)\n",
    "\n",
    "# 1. Mask padding events\n",
    "padding_mask = torch.arange(max_seq_len).unsqueeze(0) < seq_lengths.unsqueeze(1)\n",
    "valid_events = event_types * padding_mask.long()  # 0 for paddings\n",
    "valid_times = event_times.masked_fill(~padding_mask, 0.0)\n",
    "\n",
    "print(\"\\nValid events (with mask):\\n\", valid_events)\n",
    "print(\"Valid times:\\n\", valid_times)\n",
    "\n",
    "# 2. Find last event of each type for each sequence\n",
    "last_event_times = torch.zeros(batch_size, num_event_types)\n",
    "\n",
    "for batch_idx in range(batch_size):\n",
    "    for event_type in range(num_event_types):\n",
    "        # Mask for this event type in this sequence\n",
    "        type_mask = (event_types[batch_idx] == event_type) & padding_mask[batch_idx]\n",
    "        \n",
    "        if type_mask.any():\n",
    "            # Find the index of the last event of this type\n",
    "            last_idx = torch.where(type_mask)[0][-1]\n",
    "            last_event_times[batch_idx, event_type] = event_times[batch_idx, last_idx]\n",
    "\n",
    "print(\"\\nLast times per event type:\\n\", last_event_times)\n",
    "\n",
    "# 3. More efficient vectorized version\n",
    "def get_last_event_times_vectorized(event_types, event_times, padding_mask, num_event_types):\n",
    "    batch_size, seq_len = event_types.shape\n",
    "    last_times = torch.zeros(batch_size, num_event_types)\n",
    "    \n",
    "    for event_type in range(num_event_types):\n",
    "        # Mask for this event type\n",
    "        type_mask = (event_types == event_type) & padding_mask\n",
    "        \n",
    "        # Create a tensor with -inf where there are no events of this type\n",
    "        masked_times = event_times.masked_fill(~type_mask, float('-inf'))\n",
    "        \n",
    "        # Take the maximum (last time) per batch\n",
    "        max_times, _ = masked_times.max(dim=1)\n",
    "        \n",
    "        # Replace -inf by 0 where there was no event of that type\n",
    "        valid_mask = max_times != float('-inf')\n",
    "        last_times[valid_mask, event_type] = max_times[valid_mask]\n",
    "    \n",
    "    return last_times\n",
    "\n",
    "last_times_vec = get_last_event_times_vectorized(event_types, event_times, padding_mask, num_event_types)\n",
    "print(\"\\nVectorized version:\\n\", last_times_vec)\n",
    "print(\"Equality with naive version:\", torch.allclose(last_event_times, last_times_vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6f29dc",
   "metadata": {},
   "source": [
    "### Applied examples for point processes\n",
    "\n",
    "Examples applying the indexing techniques to temporal point processes (TPPs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38551b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps vectorisé: 0.0014s\n",
      "Shape résultat: torch.Size([100, 100])\n",
      "\n",
      "Valeurs à grouper par bins: tensor([ 0.9677,  0.8307, -0.6004, -0.0969, -0.9670])\n",
      "Indices de bins: tensor([2, 3, 2, 9, 3])\n",
      "Sommes par bin:\n",
      " tensor([[ 2.1389e+00,  0.0000e+00,  4.1902e+00,  1.9977e-03,  1.0681e+00,\n",
      "          2.3102e-01, -7.2568e-01,  5.6631e-01,  0.0000e+00, -1.8103e-01],\n",
      "        [ 0.0000e+00,  2.7782e+00, -1.4263e+00,  0.0000e+00,  6.3193e-01,\n",
      "          3.1381e+00, -1.1786e-01,  4.7861e-01,  4.2729e-01,  2.0775e+00],\n",
      "        [-2.1165e+00,  1.6351e+00,  4.4144e-01, -5.4236e-01,  5.4693e-01,\n",
      "          0.0000e+00,  4.1478e-01, -1.1112e-01,  3.2264e+00, -3.7155e-01],\n",
      "        [ 1.4515e+00, -1.0545e+00,  8.9650e-01,  2.7579e+00, -1.7292e-01,\n",
      "         -8.0008e-01,  1.1697e-01, -1.7198e+00, -1.1725e+00, -1.5216e-01]])\n",
      "Tenseur original shape: torch.Size([1000, 1000])\n",
      "Reshaped shape: torch.Size([100, 10, 100, 10])\n",
      "Même mémoire: True\n",
      "Final shape: torch.Size([100, 100, 100])\n",
      "\n",
      "Top-10 values shape: torch.Size([5, 10])\n",
      "Top-10 indices shape: torch.Size([5, 10])\n",
      "Top features shape: torch.Size([5, 10, 64])\n",
      "\n",
      "=== Conseils d'optimisation ===\n",
      "1. Utilisez view() au lieu de reshape() quand possible\n",
      "2. Évitez les boucles Python, préférez les opérations vectorisées\n",
      "3. Utilisez scatter/gather pour les opérations groupées\n",
      "4. masked_fill est plus rapide que l'indexation conditionnelle\n",
      "5. topk est optimisé pour la sélection des meilleurs éléments\n"
     ]
    }
   ],
   "source": [
    "# Advanced techniques to optimize performance\n",
    "\n",
    "# 1. Avoid Python loops using broadcasting\n",
    "def naive_distance_matrix(points):\n",
    "    \"\"\"Naive version with loops (SLOW)\"\"\"\n",
    "    n = points.shape[0]\n",
    "    distances = torch.zeros(n, n)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            distances[i, j] = torch.norm(points[i] - points[j])\n",
    "    return distances\n",
    "\n",
    "\n",
    "def vectorized_distance_matrix(points):\n",
    "    \"\"\"Vectorized version (FAST)\"\"\"\n",
    "    # points shape: [n, d]\n",
    "    # Using broadcasting\n",
    "    diff = points.unsqueeze(1) - points.unsqueeze(0)  # [n, n, d]\n",
    "    distances = torch.norm(diff, dim=2)  # [n, n]\n",
    "    return distances\n",
    "\n",
    "# Test with random points\n",
    "points = torch.randn(100, 3)\n",
    "\n",
    "# Timing\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "dist_vectorized = vectorized_distance_matrix(points)\n",
    "time_vectorized = time.time() - start\n",
    "\n",
    "print(f\"Vectorized time: {time_vectorized:.4f}s\")\n",
    "print(f\"Result shape: {dist_vectorized.shape}\")\n",
    "\n",
    "# 2. Efficient indexing with scatter operations\n",
    "batch_size, num_bins = 4, 10\n",
    "values = torch.randn(batch_size, 20)  # 20 values per batch\n",
    "bin_indices = torch.randint(0, num_bins, (batch_size, 20))\n",
    "\n",
    "print(\"\\nValues to bin:\", values[0, :5])\n",
    "print(\"Bin indices:\", bin_indices[0, :5])\n",
    "\n",
    "# Sum values per bin with scatter_add\n",
    "bin_sums = torch.zeros(batch_size, num_bins)\n",
    "bin_sums.scatter_add_(1, bin_indices, values)\n",
    "\n",
    "print(\"Sums per bin:\\n\", bin_sums)\n",
    "\n",
    "# 3. Memory optimization with view and squeeze/unsqueeze\n",
    "large_tensor = torch.randn(1000, 1000)\n",
    "print(f\"Original tensor shape: {large_tensor.shape}\")\n",
    "\n",
    "# View to reshape without copying\n",
    "reshaped = large_tensor.view(100, 10, 100, 10)\n",
    "print(f\"Reshaped shape: {reshaped.shape}\")\n",
    "print(f\"Same memory: {reshaped.data_ptr() == large_tensor.data_ptr()}\")\n",
    "\n",
    "# Permute + contiguous to rearrange efficiently\n",
    "permuted = reshaped.permute(0, 2, 1, 3)  # Change dimension order\n",
    "flattened = permuted.contiguous().view(100, 100, 100)  # Needs contiguous()\n",
    "print(f\"Final shape: {flattened.shape}\")\n",
    "\n",
    "# 4. Indexing with topk for efficient selection\n",
    "scores = torch.randn(5, 1000)  # 5 samples, 1000 features each\n",
    "k = 10\n",
    "\n",
    "# Select top-k scores for each sample\n",
    "top_values, top_indices = torch.topk(scores, k, dim=1)\n",
    "print(f\"\\nTop-{k} values shape: {top_values.shape}\")\n",
    "print(f\"Top-{k} indices shape: {top_indices.shape}\")\n",
    "\n",
    "# Use indices to retrieve other information\n",
    "features = torch.randn(5, 1000, 64)  # Associated features\n",
    "top_features = torch.gather(features, 1, \n",
    "                           top_indices.unsqueeze(-1).expand(-1, -1, 64))\n",
    "print(f\"Top features shape: {top_features.shape}\")\n",
    "\n",
    "print(\"\\n=== Optimization tips ===\")\n",
    "print(\"1. Use view() instead of reshape() when possible\")\n",
    "print(\"2. Avoid Python loops; prefer vectorized operations\")\n",
    "print(\"3. Use scatter/gather for grouped operations\")\n",
    "print(\"4. masked_fill is faster than conditional indexing\")\n",
    "print(\"5. topk is optimized for selecting top elements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3084bd29",
   "metadata": {},
   "source": [
    "## Vectorized version (fast)\n",
    "\n",
    "This section contains an optimized, vectorized implementation and a timing comparison with a naive version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a42e4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenseur de référence (4x5):\n",
      "tensor([[10, 11, 12, 13, 14],\n",
      "        [20, 21, 22, 23, 24],\n",
      "        [30, 31, 32, 33, 34],\n",
      "        [40, 41, 42, 43, 44]])\n",
      "Shape: torch.Size([4, 5])\n",
      "\n",
      "============================================================\n",
      "1. TORCH.GATHER - Indexation flexible par dimension\n",
      "============================================================\n",
      "Indices pour gather:\n",
      "tensor([[1, 3, 0, 4],\n",
      "        [4, 2, 1, 0],\n",
      "        [2, 2, 2, 2],\n",
      "        [0, 1, 2, 3]])\n",
      "Résultat gather (dim=1):\n",
      "tensor([[11, 13, 10, 14],\n",
      "        [24, 22, 21, 20],\n",
      "        [32, 32, 32, 32],\n",
      "        [40, 41, 42, 43]])\n",
      "Shape: torch.Size([4, 4])\n",
      "\n",
      "Caractéristiques de gather:\n",
      "- Préserve le nombre de dimensions\n",
      "- Les indices peuvent être différents pour chaque 'ligne' (batch)\n",
      "- Shape du résultat = shape des indices\n",
      "- Très flexible pour l'indexation par batch\n"
     ]
    }
   ],
   "source": [
    "# Comparaison détaillée entre gather, index_select et take\n",
    "import torch\n",
    "\n",
    "# Créons un tenseur de référence pour tous les exemples\n",
    "data = torch.tensor([\n",
    "    [10, 11, 12, 13, 14],\n",
    "    [20, 21, 22, 23, 24],\n",
    "    [30, 31, 32, 33, 34],\n",
    "    [40, 41, 42, 43, 44]\n",
    "])\n",
    "print(\"Tenseur de référence (4x5):\")\n",
    "print(data)\n",
    "print(\"Shape:\", data.shape)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"1. TORCH.GATHER - Indexation flexible par dimension\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# gather: sélectionne des éléments selon des indices, en préservant la structure\n",
    "indices_gather = torch.tensor([\n",
    "    [1, 3, 0, 4],  # Pour la ligne 0: colonnes 1,3,0,4\n",
    "    [4, 2, 1, 0],  # Pour la ligne 1: colonnes 4,2,1,0  \n",
    "    [2, 2, 2, 2],  # Pour la ligne 2: colonne 2 répétée\n",
    "    [0, 1, 2, 3]   # Pour la ligne 3: colonnes 0,1,2,3\n",
    "])\n",
    "\n",
    "print(\"Indices pour gather:\")\n",
    "print(indices_gather)\n",
    "\n",
    "gathered = torch.gather(data, dim=1, index=indices_gather)\n",
    "print(\"Résultat gather (dim=1):\")\n",
    "print(gathered)\n",
    "print(\"Shape:\", gathered.shape)\n",
    "\n",
    "print(\"\\nCaractéristiques de gather:\")\n",
    "print(\"- Préserve le nombre de dimensions\")\n",
    "print(\"- Les indices peuvent être différents pour chaque 'ligne' (batch)\")\n",
    "print(\"- Shape du résultat = shape des indices\")\n",
    "print(\"- Très flexible pour l'indexation par batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2e661d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "2. TORCH.INDEX_SELECT - Sélection de tranches entières\n",
      "============================================================\n",
      "Sélection de lignes [0, 2, 3]:\n",
      "tensor([[10, 11, 12, 13, 14],\n",
      "        [30, 31, 32, 33, 34],\n",
      "        [40, 41, 42, 43, 44]])\n",
      "Shape: torch.Size([3, 5])\n",
      "\n",
      "Sélection de colonnes [1, 4, 2]:\n",
      "tensor([[11, 14, 12],\n",
      "        [21, 24, 22],\n",
      "        [31, 34, 32],\n",
      "        [41, 44, 42]])\n",
      "Shape: torch.Size([4, 3])\n",
      "\n",
      "Caractéristiques d'index_select:\n",
      "- Sélectionne des tranches COMPLÈTES selon une dimension\n",
      "- Les indices s'appliquent à TOUTES les lignes/colonnes uniformément\n",
      "- Plus simple que gather mais moins flexible\n",
      "- Équivalent au slicing avancé: data[[0,2,3], :] ou data[:, [1,4,2]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"2. TORCH.INDEX_SELECT - Sélection de tranches entières\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# index_select: sélectionne des lignes/colonnes ENTIÈRES selon des indices\n",
    "indices_rows = torch.tensor([0, 2, 3])  # Sélectionner lignes 0, 2, 3\n",
    "selected_rows = torch.index_select(data, dim=0, index=indices_rows)\n",
    "print(\"Sélection de lignes [0, 2, 3]:\")\n",
    "print(selected_rows)\n",
    "print(\"Shape:\", selected_rows.shape)\n",
    "\n",
    "indices_cols = torch.tensor([1, 4, 2])  # Sélectionner colonnes 1, 4, 2  \n",
    "selected_cols = torch.index_select(data, dim=1, index=indices_cols)\n",
    "print(\"\\nSélection de colonnes [1, 4, 2]:\")\n",
    "print(selected_cols)\n",
    "print(\"Shape:\", selected_cols.shape)\n",
    "\n",
    "print(\"\\nCaractéristiques d'index_select:\")\n",
    "print(\"- Sélectionne des tranches COMPLÈTES selon une dimension\")\n",
    "print(\"- Les indices s'appliquent à TOUTES les lignes/colonnes uniformément\")\n",
    "print(\"- Plus simple que gather mais moins flexible\")\n",
    "print(\"- Équivalent au slicing avancé: data[[0,2,3], :] ou data[:, [1,4,2]]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "767dabf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "3. TORCH.TAKE - Indexation en tableau plat\n",
      "============================================================\n",
      "Tenseur aplati conceptuellement:\n",
      "Position:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "Valeur:    [10, 11, 12, 13, 14, 20, 21, 22, 23, 24, 30, 31, 32, 33, 34, 40, 41, 42, 43, 44]\n",
      "\n",
      "Indices take: [0, 5, 7, 12, 19]\n",
      "Résultat take: tensor([10, 20, 22, 32, 44])\n",
      "Shape: torch.Size([5])\n",
      "\n",
      "Vérification manuelle:\n",
      "Index 0 -> position [0, 0] -> valeur 10\n",
      "Index 5 -> position [1, 0] -> valeur 20\n",
      "Index 7 -> position [1, 2] -> valeur 22\n",
      "Index 12 -> position [2, 2] -> valeur 32\n",
      "Index 19 -> position [3, 4] -> valeur 44\n",
      "\n",
      "Caractéristiques de take:\n",
      "- Traite le tenseur comme un tableau 1D (ordre row-major)\n",
      "- Indices en positions absolutes\n",
      "- Résultat toujours 1D\n",
      "- Utile pour indexation sparse ou échantillonnage aléatoire\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"3. TORCH.TAKE - Indexation en tableau plat\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# take: traite le tenseur comme un vecteur plat (1D)\n",
    "print(\"Tenseur aplati conceptuellement:\")\n",
    "flat_view = data.flatten()\n",
    "print(\"Position: \", list(range(len(flat_view))))\n",
    "print(\"Valeur:   \", flat_view.tolist())\n",
    "\n",
    "indices_take = torch.tensor([0, 5, 7, 12, 19])  # Positions absolues dans le tableau plat\n",
    "taken = torch.take(data, indices_take)\n",
    "print(f\"\\nIndices take: {indices_take.tolist()}\")\n",
    "print(\"Résultat take:\", taken)\n",
    "print(\"Shape:\", taken.shape)\n",
    "\n",
    "print(\"\\nVérification manuelle:\")\n",
    "for i, idx in enumerate(indices_take):\n",
    "    row = idx // 5  # Division entière pour trouver la ligne\n",
    "    col = idx % 5   # Modulo pour trouver la colonne\n",
    "    print(f\"Index {idx} -> position [{row}, {col}] -> valeur {data[row, col]}\")\n",
    "\n",
    "print(\"\\nCaractéristiques de take:\")\n",
    "print(\"- Traite le tenseur comme un tableau 1D (ordre row-major)\")\n",
    "print(\"- Indices en positions absolutes\")\n",
    "print(\"- Résultat toujours 1D\")\n",
    "print(\"- Utile pour indexation sparse ou échantillonnage aléatoire\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f914633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "4. COMPARAISON PRATIQUE - Même objectif, approches différentes\n",
      "============================================================\n",
      "OBJECTIF: Sélectionner la 2e et 4e colonne de toutes les lignes\n",
      "\n",
      "1. Avec index_select:\n",
      "tensor([[11, 13],\n",
      "        [21, 23],\n",
      "        [31, 33],\n",
      "        [41, 43]])\n",
      "\n",
      "Indices pour gather (répétés): \n",
      "tensor([[1, 3],\n",
      "        [1, 3],\n",
      "        [1, 3],\n",
      "        [1, 3]])\n",
      "2. Avec gather (équivalent):\n",
      "tensor([[11, 13],\n",
      "        [21, 23],\n",
      "        [31, 33],\n",
      "        [41, 43]])\n",
      "3. Avec take (plus complexe):\n",
      "tensor([[11, 13],\n",
      "        [21, 23],\n",
      "        [31, 33],\n",
      "        [41, 43]])\n",
      "\n",
      "Vérification - tous égaux: True\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"4. COMPARAISON PRATIQUE - Même objectif, approches différentes\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"OBJECTIF: Sélectionner la 2e et 4e colonne de toutes les lignes\\n\")\n",
    "\n",
    "# Méthode 1: avec index_select (LE PLUS SIMPLE)\n",
    "cols_wanted = torch.tensor([1, 3])\n",
    "result_index_select = torch.index_select(data, dim=1, index=cols_wanted)\n",
    "print(\"1. Avec index_select:\")\n",
    "print(result_index_select)\n",
    "\n",
    "# Méthode 2: avec gather (PLUS VERBEUX mais plus flexible)\n",
    "# Il faut répéter les indices pour chaque ligne\n",
    "gather_indices = cols_wanted.unsqueeze(0).expand(data.shape[0], -1)\n",
    "print(f\"\\nIndices pour gather (répétés): \\n{gather_indices}\")\n",
    "result_gather = torch.gather(data, dim=1, index=gather_indices)\n",
    "print(\"2. Avec gather (équivalent):\")\n",
    "print(result_gather)\n",
    "\n",
    "# Méthode 3: avec take (COMPLIQUÉ)\n",
    "# Il faut calculer les positions absolutes\n",
    "take_indices = []\n",
    "for row in range(data.shape[0]):\n",
    "    for col in [1, 3]:  # colonnes 1 et 3\n",
    "        take_indices.append(row * data.shape[1] + col)\n",
    "take_indices = torch.tensor(take_indices)\n",
    "result_take = torch.take(data, take_indices).reshape(data.shape[0], 2)\n",
    "print(\"3. Avec take (plus complexe):\")\n",
    "print(result_take)\n",
    "\n",
    "print(f\"\\nVérification - tous égaux: {torch.equal(result_index_select, result_gather) and torch.equal(result_gather, result_take)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2824066b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "5. CAS D'USAGE TYPIQUES\n",
      "============================================================\n",
      "📌 GATHER - Quand utiliser:\n",
      "✓ Indexation différente par batch (ex: derniers événements)\n",
      "✓ Sélection de éléments selon des critères dynamiques\n",
      "✓ Extraction de valeurs selon des indices calculés\n",
      "✓ Traitement par batch avec indices variables\n",
      "\n",
      "📌 INDEX_SELECT - Quand utiliser:\n",
      "✓ Sélection de lignes/colonnes complètes\n",
      "✓ Sous-échantillonnage uniforme\n",
      "✓ Réorganisation de dimensions\n",
      "✓ Quand tous les batches ont les mêmes indices\n",
      "\n",
      "📌 TAKE - Quand utiliser:\n",
      "✓ Échantillonnage aléatoire de positions\n",
      "✓ Indexation sparse sur tenseurs aplatis\n",
      "✓ Conversion d'indices 2D vers 1D\n",
      "✓ Sélection d'éléments non-structurée\n",
      "\n",
      "============================================================\n",
      "6. EXEMPLE PROCESSUS PONCTUELS\n",
      "============================================================\n",
      "Événements:\n",
      "tensor([[0, 1, 0, 0, 1],\n",
      "        [1, 0, 1, 1, 0],\n",
      "        [1, 0, 0, 1, 0]])\n",
      "Temps:\n",
      "tensor([[1.7946, 2.5892, 3.1408, 4.6366, 4.9139],\n",
      "        [1.1127, 1.3986, 3.1231, 4.1274, 5.9714],\n",
      "        [0.2518, 0.3949, 1.9774, 2.6786, 3.4462]])\n",
      "\n",
      "1. GATHER - 3e temps de chaque batch: tensor([3.1408, 3.1231, 1.9774])\n",
      "2. INDEX_SELECT - positions 2 et 4 pour tous:\n",
      "tensor([[2.5892, 4.6366],\n",
      "        [1.3986, 4.1274],\n",
      "        [0.3949, 2.6786]])\n",
      "3. TAKE - éléments aux positions absolutes [1, 7, 12]: tensor([2.5892, 3.1231, 1.9774])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"5. COMMON USAGE CASES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"📌 GATHER - When to use:\")\n",
    "print(\"✓ Different indexing per batch (e.g., last events)\")\n",
    "print(\"✓ Select elements based on dynamic criteria\")\n",
    "print(\"✓ Extract values using computed indices\")\n",
    "print(\"✓ Batch-wise processing with variable indices\")\n",
    "\n",
    "print(\"\\n📌 INDEX_SELECT - When to use:\")\n",
    "print(\"✓ Select entire rows/columns\")\n",
    "print(\"✓ Uniform subsampling\")\n",
    "print(\"✓ Reorganizing dimensions\")\n",
    "print(\"✓ When all batches share the same indices\")\n",
    "\n",
    "print(\"\\n📌 TAKE - When to use:\")\n",
    "print(\"✓ Random sampling of positions\")\n",
    "print(\"✓ Sparse indexing on flattened tensors\")\n",
    "print(\"✓ Convert 2D indices to 1D\")\n",
    "print(\"✓ Select non-structured elements\")\n",
    "\n",
    "# Practical example for point processes\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"6. POINT PROCESS EXAMPLE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "batch_size, seq_len, num_types = 3, 5, 2\n",
    "events = torch.randint(0, num_types, (batch_size, seq_len))\n",
    "times = torch.randn(batch_size, seq_len).abs().cumsum(dim=1)\n",
    "\n",
    "print(\"Events:\")\n",
    "print(events)\n",
    "print(\"Times:\")\n",
    "print(times)\n",
    "\n",
    "# Case 1: GATHER - Get the time of the 3rd event of each batch\n",
    "indices_3rd = torch.tensor([[2], [2], [2]])  # 3rd position for each batch\n",
    "times_3rd_gather = torch.gather(times, dim=1, index=indices_3rd)\n",
    "print(f\"\\n1. GATHER - 3rd time of each batch: {times_3rd_gather.flatten()}\")\n",
    "\n",
    "# Case 2: INDEX_SELECT - Take the 2nd and 4th times for all batches\n",
    "positions = torch.tensor([1, 3])  # positions 2 and 4\n",
    "times_selected = torch.index_select(times, dim=1, index=positions)\n",
    "print(\"2. INDEX_SELECT - positions 2 and 4 for all:\")\n",
    "print(times_selected)\n",
    "\n",
    "# Case 3: TAKE - Retrieve specific sparse elements\n",
    "sparse_indices = torch.tensor([1, 7, 12])  # absolute positions in the flat array\n",
    "times_sparse = torch.take(times, sparse_indices)\n",
    "print(f\"3. TAKE - elements at absolute positions {sparse_indices.tolist()}: {times_sparse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011d6283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "7. TABLEAU RÉCAPITULATIF\n",
      "============================================================\n",
      "\n",
      "┌─────────────────┬──────────────┬──────────────┬──────────────┐\n",
      "│ Caractéristique │    GATHER    │ INDEX_SELECT │     TAKE     │\n",
      "├─────────────────┼──────────────┼──────────────┼──────────────┤\n",
      "│ Flexibilité     │    Haute     │   Moyenne    │    Faible    │\n",
      "│ Complexité      │   Moyenne    │   Faible     │    Haute     │\n",
      "│ Shape résultat  │ = shape idx  │ Préservée    │  Toujours 1D │\n",
      "│ Indices/batch   │ Différents   │  Identiques  │   Absolus    │\n",
      "│ Dimensions      │ Préservées   │ Dim-1 libre  │  Aplaties    │\n",
      "│ Performance     │   Rapide     │   Rapide     │   Rapide     │\n",
      "│ Cas d'usage     │ Batch varié  │ Slicing++    │ Sparse/1D    │\n",
      "└─────────────────┴──────────────┴──────────────┴──────────────┘\n",
      "\n",
      "🎯 RÈGLE GÉNÉRALE:\n",
      "• Utilisez INDEX_SELECT pour des sélections uniformes simples\n",
      "• Utilisez GATHER pour des sélections par batch variables\n",
      "• Utilisez TAKE pour des indexations 1D ou très spécifiques\n",
      "\n",
      "✨ CONSEIL PERFORMANCE:\n",
      "• Pour des sélections simples: slicing normal [indices] > index_select > gather\n",
      "• Pour des sélections complexes par batch: gather est optimal\n",
      "• Pour des accès sparse: take peut être utile mais souvent il y a mieux\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"7. SUMMARY TABLE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "┌─────────────────┬──────────────┬──────────────┬──────────────┐\n",
    "│ Characteristic  │    GATHER    │ INDEX_SELECT │     TAKE     │\n",
    "├─────────────────┼──────────────┼──────────────┼──────────────┤\n",
    "│ Flexibility     │    High      │   Medium     │    Low       │\n",
    "│ Complexity      │   Medium     │   Low        │    High      │\n",
    "│ Result shape    │ = shape idx  │ Preserved    │  Always 1D   │\n",
    "│ Indices/batch   │ Varying      │  Identical   │   Absolute   │\n",
    "│ Dimensions      │ Preserved    │ Dim-1 free   │  Flattened   │\n",
    "│ Performance     │   Fast       │   Fast       │   Fast       │\n",
    "│ Use cases       │ Batch varied │ Advanced     │ Sparse/1D    │\n",
    "└─────────────────┴──────────────┴──────────────┴──────────────┘\n",
    "\"\"\")\n",
    "\n",
    "print(\"🎯 GENERAL RULE:\")\n",
    "print(\"• Use INDEX_SELECT for simple uniform selections\")\n",
    "print(\"• Use GATHER for batch-variable selections\") \n",
    "print(\"• Use TAKE for 1D or very specific indexing\")\n",
    "\n",
    "print(\"\\n✨ PERFORMANCE TIP:\")\n",
    "print(\"• For simple selections: normal slicing [indices] > index_select > gather\")\n",
    "print(\"• For complex batch-wise selections: gather is optimal\")\n",
    "print(\"• For sparse access: take can be useful but often there's a better approach\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easy-tpp (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
